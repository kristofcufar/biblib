@article{Javh_2017,
   abstract = {This research looks at the possibilities for full-field, non-contact, displacement measurements based on high-speed video analyses. A simplified gradient-based optical flow method, optimised for subpixel harmonic displacements, is used to predict the resolution potential. The simplification assumes an image-gradient linearity, producing a linear relation between the light intensity and the displacement in the direction of the intensity gradient. The simplicity of the method enables each pixel or small subset to be viewed as a sensor. The resolution potential and the effect of noise are explored theoretically and tested in a synthetic experiment, which is followed by a real experiment. The identified displacement can be smaller than a thousandth of a pixel and subpixel displacements are recognisable, even with a high image noise. The resolution and the signal-to-noise ratio are influenced by the dynamic range of the camera, the subset size and the sampling length. Real-world experiments were performed to validate and demonstrate the method using a monochrome high-speed camera. One-dimensional mode shapes of a steel beam are recognisable even at the maximum displacement amplitude of 0.0008 pixel (equal to 0.2 μm) and multiple out-of-plane mode shapes are recognisable from the high-speed video of a vibrating cymbal.},
   author = {Jaka Javh and Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2016.11.009},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Full-field non-contact displacement measurement,Gradient-based optical flow,Modal analysis,Operational displacement shapes,Photogrammetry,Subpixel resolution},
   month = {5},
   pages = {89-99},
   publisher = {Academic Press},
   title = {{The subpixel resolution of optical-flow-based modal analysis}},
   volume = {88},
   year = {2017},
}
@article{Javh_2018_2,
   abstract = {Instantaneous full-field displacement fields can be measured using cameras. In fact, using high-speed cameras full-field spectral information up to a couple of kHz can be measured. The trouble is that high-speed cameras capable of measuring high-resolution fields-of-view at high frame rates prove to be very expensive (from tens to hundreds of thousands of euro per camera). This paper introduces a measurement set-up capable of measuring high-frequency vibrations using slow cameras such as DSLR, mirrorless and others. The high-frequency displacements are measured by harmonically blinking the lights at specified frequencies. This harmonic blinking of the lights modulates the intensity changes of the filmed scene and the camera-image acquisition makes the integration over time, thereby producing full-field Fourier coefficients of the filmed structure's displacements.},
   author = {Jaka Javh and Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2017.07.024},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {DSLR camera,Lucas-Kanade,Modal analysis,Optical flow,Photogrammetry,Variable brightness},
   month = {2},
   pages = {17-27},
   publisher = {Academic Press},
   title = {{Measuring full-field displacement spectral components using photographs taken with a DSLR camera via an analogue Fourier integral}},
   volume = {100},
   year = {2018},
}
@article{Javh_2018_3,
   abstract = {High-speed camera measurements are increasingly being used in modal analysis to instantaneously measure full-field structural responses by extracting the displacement information from images using digital-image-correlation and other optical-flow methods. High-speed cameras capable of filming full frame at high frame rates can be very expensive and produce image resolutions of only approximately 1 mega pixel, which is why this research aims at measuring and identifying the full-field response using cheaper, still-frame cameras with a higher image and intensity resolution, such as digital single-lens reflex (DSLR) and mirrorless cameras. Using spectral optical flow imaging (SOFI) full-field operational shapes can be acquired using still-frame cameras. This study demonstrates the hybrid modal-parameter identification of full-field mode shapes using an accelerometer and a DSLR camera for responses far above the DSLR camera's frame rate (demonstrated up to 1 kHz).},
   author = {Jaka Javh and Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.jsv.2018.07.046},
   issn = {10958568},
   journal = {Journal of Sound and Vibration},
   keywords = {DSLR camera,LSFD,Modal-parameter identification,Optical flow,Photogrammetry,SOFI},
   month = {11},
   pages = {213-220},
   publisher = {Academic Press},
   title = {{Experimental modal analysis on full-field DSLR camera footage using spectral optical flow imaging}},
   volume = {434},
   year = {2018},
}
@article{Howe_2022,
   abstract = {This article focuses on three different ways that we may demean people by seeing them as less than they are, and describes ways we may best avoid doing this. More specifically, I explain how we may not see the physical and emotional issues that plague patients and others. This may be because they choose not to disclose their difficulties to us. We may also err when we see only one aspect of who and how others are. These challenges pose ethical quandaries that involve equity, improved communication with patients, and subjecting ethical principles to empirical study before we adopt them. I explore the means to do these.},
   author = {Edmund G. Howe},
   doi = {10.1145/3355389},
   issn = {10467890},
   issue = {2},
   journal = {The Journal of clinical ethics},
   month = {6},
   pages = {81-91},
   pmid = {35731812},
   publisher = {NLM (Medline)},
   title = {Seeing the Invisible},
   volume = {33},
   year = {2022},
}
@article{Wang_2006,
   abstract = {We present the "Cartoon Animation Filter", a simple filter that takes an arbitrary input motion signal and modulates it in such a way that the output motion is more "alive" or "animated". The filter adds a smoothed, inverted, and (sometimes) time shifted version of the second derivative (the acceleration) of the signal back into the original signal. Almost all parameters of the filter are automated. The user only needs to set the desired strength of the filter. The beauty of the animation filter lies in its simplicity and generality. We apply the filter to motions ranging from hand drawn trajectories, to simple an-imations within PowerPoint presentations, to motion captured DOF curves, to video segmentation results. Experimental results show that the filtered motion exhibits anticipation, follow-through, exaggeration and squash-and-stretch effects which are not present in the original input motion data.},
   author = {Jue Wang and Steven M Drucker and Maneesh Agrawala and Michael F Cohen},
   doi = {10.1145/1179352.1142010},
   journal = {ACM Transactions on Graphics},
   pages = {1169-1173},
   title = {{The Cartoon Animation Filter}},
   volume = {25},
   year = {2006},
}
@article{Chen_2014,
   abstract = {Video cameras offer the unique capability of collecting high density spatial data from a distant scene of interest. They could be employed as remote monitoring or inspection sensors because of their commonplace use, simplicity, and relatively low cost. The difficulty is in interpreting the video data into a usable format, such as displacement, that is familiar to engineers. A methodology called motion magnification, developed for visualizing exaggerated versions of small displacements, is extended to modal identification in structures. Experiments in a laboratory setting on a cantilever beam were performed to verify the method against accelerometer and laser vibrometer measurements. Motion magnification is used for modal analysis of cantilever beams to visualize mode shapes and calculate mode shape curvature as a basis for damage detection. Suggestions for applications of this methodology and challenges in real-world implementations are given.},
   author = {Justin G Chen and Neal Wadhwa and Young-Jin Cha and Frédo Durand and William T Freeman and Oral Buyukozturk},
   doi = {10.1007/978-3-319-04753-9__19},
   journal = {Topics in Modal Analysis I},
   keywords = {Computer vision,High speed video,Modal identification,Mode shape,Standoff condition assessment},
   pages = {191-197},
   title = {Structural Modal Identification Through High Speed Camera Video: Motion Magnification},
   volume = {7},
   year = {2014},
}
@article{Liu_2005,
   abstract = {(a) Input sequence (b) Motion magnified sequence Figure 1: Frames from input and motion magnified output sequence. The algorithm groups the input (a) into motion layers and amplifies the motions of a layer selected by the user. Deformations of the swing support elements are revealed in the motion magnified output sequence (b), magnifying the original motions by a factor of 40. Abstract We present motion magnification, a technique that acts like a microscope for visual motion. It can amplify subtle motions in a video sequence, allowing for visualization of deformations that would otherwise be invisible. To achieve motion magnification, we need to accurately measure visual motions, and group the pixels to be modified. After an initial image registration step, we measure motion by a robust analysis of feature point trajectories, and segment pixels based on similarity of position, color, and motion. A novel measure of motion similarity groups even very small motions according to correlation over time, which often relates to physical cause. An outlier mask marks observations not explained by our layered motion model, and those pixels are simply reproduced on the output from the original registered observations. The motion of any selected layer may be magnified by a user-specified amount; texture synthesis fills-in unseen "holes" revealed by the amplified motions. The resulting motion-magnified images can reveal or emphasize small motions in the original sequence, as we demonstrate with deformations in load-bearing structures, subtle motions or balancing corrections of people, and "rigid" structures bending under hand pressure.},
   author = {Ce Liu and Antonio Torralba and William T Freeman and Frédo Durand and Edward H Adelson},
   doi = {10.1145/1073204.1073223},
   issue = {3},
   journal = {ACM Transactions on Graphics},
   keywords = {computer vision,motion processing,video pro-cessing,video-based rendering},
   pages = {519-526},
   title = {{Motion Magnification}},
   volume = {24},
   year = {2005},
}
@article{Siebert_2009,
   abstract = {Digital speckle correlation techniques have already been successfully proven to be an accurate displacement analysis tool for a wide range of applications. With the use of two cameras, three dimensional measurements of contours and displacements can be carried out. With a simple setup it opens a wide range of applications. Rapid new developments in the field of digital imaging and computer technology opens further applications for these measurement methods to high speed deformation and strain analysis, e.g. in the fields of material testing, fracture mechanics, advanced materials and component testing. The high resolution of the deformation measurements in space and time opens a wide range of applications for vibration analysis of objects. Since the system determines the absolute position and displacements of the object in space, it is capable of measuring high amplitudes and even objects with rigid body movements. The absolute resolution depends on the field of view and is scalable. Calibration of the optical setup is a crucial point which will be discussed in detail. Examples of the analysis of harmonic vibration and transient events from material research and industrial applications are presented. The results show typical features of the system. © 2009 IOP Publishing Ltd.},
   author = {Thorsten Siebert and Rob Wood and Karsten Splitthof},
   doi = {10.1088/1742-6596/181/1/012064},
   issn = {17426596},
   issue = {1},
   journal = {Journal of Physics: Conference Series},
   pages = {012064},
   publisher = {Institute of Physics Publishing},
   title = {{High speed image correlation for vibration analysis}},
   volume = {181},
   year = {2009},
}
@article{Kamble_2007,
   abstract = {Thispaper reviews computational techniques to efficiently represent, analyse and visualise both short-term and long-term temporal variation in video and image sequences. This paper reveals temporal variation in videos that are imperceptible to the naked eye. The method takes a standard video sequence as an input, and applies spatial decomposition, followed by temporal filtering to the frames which is called "Eulerian Video Magnification". The resulting signal is then amplified to reveal the hidden information. Paper contains four techniques which are: 1.Linear approximation method, 2.Phase based video processing, 3. Riesz pyramid for fast phase based video processing and 4.Enhanced Eulerian video magnification. Using above methods, one is able to amplify and visualize small motions and temporal colour changes. KEYWORDS: Spatio-temporal analysis, Eulerian motion, phase based video magnification, image wrapping and motion mapping. I. INTRODUCTION The motions which are too small in amplitude, below human visual spatio-temporal sensitivity are explanatory. The variations which are invisible for human eye can be useful to extract important information. e.g. respiratory motion, the human skin colour varies with blood circulation can be employed to extract pulse rate[1][2]; high speed videos such as small eye movement, engines vibration, long term physical processes such as melting of glacier, growth of plants can reveal biological and physical changes[3]. The motions with low spatial amplitude are hard to see for human, can be amplified to divulge the mechanical behaviour [4]. The video motion magnification is useful in the field of medical and scientific application, for contactless vital-sign monitoring applications in health care, pulse rate measurement, in photography to retouch the time lapse video, in mechanical systems to monitor vibration of system or to analyse structural integrity of building, bridges, and railroads and in search and rescue operations. The method Eulerian video magnification (EVM) is used to disclose the temporal variation or invisible signals in videos which are difficult to see with naked eye and display them. The EVM is a combination of spatial and temporal filtering to reveal the subtle temporal changes in videos. The input, standard video sequence, is spatial decomposed and followed by temporal filtering and the resulting signal is then amplified with some amplification factor and reveals small motions. The EVM is inspired by Eulerian approach which deals with fluid motion properties such as pressure and velocity over time and space.},
   author = {Kranti Kamble and Ashwin Kamble and Nitin Jagtap and R A Patil and Ankit Bhurane and M Tech Student},
   doi = {10.15680/ijircce.2015.0303142},
   issn = {2320-9798},
   journal = {International Journal of Innovative Research in Computer and Communication Engineering (An ISO},
   title = {A Review: Eulerian Video Motion Magnification},
   volume = {3297},
   year = {2007},
}
@article{Molina_2018,
   abstract = {High speed video cameras provide valuable information in dynamic events. Mechanical characterisation has been improved by the interpretation of the behaviour in slow-motion visualisations. In modal analysis, videos contribute to the evaluation of mode shapes but, generally, the motion is too subtle to be interpreted. In latest years, image treatment algorithms have been developed to generate a magnified version of the motion that could be interpreted by naked eye. Nevertheless, optical techniques such as Digital Image Correlation (DIC) are able to provide quantitative information of the motion with higher sensitivity than naked eye. For vibration analysis, mode shapes characterisation is one of the most interesting DIC performances. Full-field measurements provide higher spatial density than classical instrumentations or Scanning Laser Doppler Vibrometry. However, the accurateness of DIC is reduced at high frequencies as a consequence of the low displacements and hence it is habitually employed in low frequency spectra. In the current work, the combination of DIC and motion magnification is explored in order to provide numerical information in magnified videos and perform DIC mode shapes characterisation at unprecedented high frequencies through increasing the amplitude of displacements.},
   author = {A. J. Molina-Viedma and L. Felipe-Sesé and E. López-Alba and F. Díaz},
   doi = {10.1016/j.ymssp.2017.09.019},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {High Speed Digital Image Correlation,Mode shapes,Motion magnification,Operational Deflection Shapes},
   month = {3},
   pages = {245-261},
   publisher = {Academic Press},
   title = {{High frequency mode shapes characterisation using Digital Image Correlation and phase-based motion magnification}},
   volume = {102},
   year = {2018},
}
@inproceedings{Wadhwa2014,
   abstract = {We present a new compact image pyramid representation , the Riesz pyramid, that can be used for real-time phase-based motion magnification. Our new representation is less overcomplete than even the smallest two orientation , octave-bandwidth complex steerable pyramid, and can be implemented using compact, efficient linear filters in the spatial domain. Motion-magnified videos produced with this new representation are of comparable quality to those produced with the complex steerable pyramid. When used with phase-based video magnification, the Riesz pyramid phase-shifts image features along only their dominant orientation rather than every orientation like the complex steerable pyramid.},
   author = {Neal Wadhwa and Michael Rubinstein and Frédo Durand and William T. Freeman},
   journal = {IEEE International Conference on Computational Photography},
   pages = {1-10},
   title = {Riesz Pyramids for Fast Phase-Based Video Magnification},
   url = {http://people.csail.mit.edu/nwadhwa/riesz-pyramid},
   year = {2014},
}
@article{Machynia_2021,
   abstract = {Much information can be derived from operational deflection shapes of vibrating structures and the magnification of their motion. However, the acquisition of deflection shapes usually requires a manual definition of an object’s points of interest, while general motion magnification is computa-tionally inefficient. We propose easy extraction of operational deflection shapes straight from vision data by analyzing and processing optical flow information from the video and then, based on these graphs, morphing source data to magnify the shape of deflection. We introduce several processing routines for automatic masking of the optical flow data and frame-wise information fusion. The method is tested based on data acquired both in numerical simulations and real-life experiments in which cantilever beams were subjected to excitation around their natural frequencies.},
   author = {Adam Machynia and Ziemowit Dworakowski and Kajetan Dziedziech and Paweł Zdziebko and Jarosław Konieczny and Krzysztof Holak},
   doi = {10.3390/s21248351},
   issn = {14248220},
   issue = {24},
   journal = {Sensors},
   keywords = {Cantilever beam,Image segmentation,Modal analysis,Motion magnification,Optical flow},
   month = {12},
   publisher = {MDPI},
   title = {Operational deflection shapes magnification and visualization using optical-flow-based image processing},
   volume = {21},
   year = {2021},
}
@article{Wang_2013,
   abstract = {Recent advances in measurement techniques such as digital image correlation, automated photoelasticity, electronic speckle pattern interferometry and thermoelastic stress analysis allow full-field maps (images) of displacement or strain to be obtained easily. This generally results in the acquisition of large volumes of highly redundant data. Fortunately, image decomposition offers feasible techniques for data condensation while retaining essential information. This permits data processing such as the validation of computational models, modal testing or structural damage assessment efficiently and in a straightforward way. The selection, or construction, of decomposition bases (kernel) functions is essential to data reduction and has been shown to produce features, or attributes, of the full-field image that are effective in reproducing the measured information, succinct in condensation and robust to measurement noise. Among the most popular kernel functions are the orthogonal Fourier series, wavelets and Legendre polynomials, which are defined on continuous rectangular domains, and Zernike polynomials and Fourier-Mellin functions, which are defined on continuous circular domains. The discrete orthogonal polynomials include Tchebichef, Krawtchouk and Hahn functions that are directly applicable to digital images and avoid the approximate numerical integration that becomes necessary with the sampling of continuous kernel functions. In practice, full-field measurements of the engineering components are usually non-planar within irregular domains - neither rectangular nor circular, so that the classical kernel functions are not immediately applicable. To address this problem, a complete methodology is described, consisting of (1) surface parameterisation for the mapping of three-dimensional surfaces to two-dimensional planar domains, (2) Gram-Schmidt orthogonalisation for the construction of orthogonal kernel functions on arbitrary domains and (3) reconstruction of localised image features, such as regions of high strain gradient, by a windowing technique. Application of this methodology is demonstrated in a series of illustrative examples. © 2012 IMechE.},
   author = {Weizhuo Wang and John E. Mottershead},
   doi = {10.1177/0309324712460485},
   issn = {03093247},
   issue = {1},
   journal = {Journal of Strain Analysis for Engineering Design},
   keywords = {Digital image correlation,Full-field measurement,Image moment descriptors,Shape features},
   month = {1},
   pages = {16-35},
   title = {Adaptive moment descriptors for full-field strain and displacement measurements},
   volume = {48},
   year = {2013},
}
@article{Wei_2006,
   abstract = {Based on the smoothing spline approximation, in this paper we propose a regularization method for computing high order numerical derivatives from one-dimensional noisy data. The convergence rates under two different choices of the regularization parameter are obtained. Numerical examples show that the proposed method is effective and stable. © 2005 Elsevier Inc. All rights reserved.},
   author = {T. Wei and M. Li},
   doi = {10.1016/j.amc.2005.09.018},
   issn = {00963003},
   issue = {2},
   journal = {Applied Mathematics and Computation},
   keywords = {Numerical derivatives,Radial basis function,Tikhonov regularization},
   month = {4},
   pages = {1744-1759},
   title = {High order numerical derivatives for one-dimensional scattered noisy data},
   volume = {175},
   year = {2006},
}
@article{Avril_2008,
   abstract = {In this study, the issue of reconstructing strain fields from corrupted full-field displacement data is addressed. Two approaches are proposed, a global one based on Finite Element Approximation (FEA) and a local one based on Diffuse Approximation (DA). Both approaches are compared on a case study which is supposed difficult (open-hole tensile test). DA provides more stable results, but is more CPU time consuming. Eventually, it is proposed to monitor locally the filtering effect of both approaches, the prospects being an impending improvement of the reconstruction for both approaches. © 2008 Lavoisier, Paris.},
   author = {Stéphane Avril and Pierre Feissel and Fabrice Pierron and Pierre Villon},
   doi = {10.3166/REMN.17.857-868},
   issn = {19585829},
   issue = {5-7},
   journal = {European Journal of Computational Mechanics},
   keywords = {Full-field measurements,Measurement uncertainty,Numerical differentiation},
   pages = {857-868},
   publisher = {Lavoisier},
   title = {Estimation of the strain field from full-field displacement noisy data: Comparing finite elements global least squares and polynomial diffuse approximation},
   volume = {17},
   year = {2008},
}
@article{Bai_2020,
   abstract = {Undermatched shape functions have always been the primary source of systematic errors for non-uniform deformation measurement in digital image correlation, especially for large curvature displacement. All the other errors arising from grey-level interpolation, subset size, and speckle pattern are overwhelmed by the systematic errors due to undermatched shape functions. The effect of the first-order shape functions on polynomials is analyzed, and based on this analysis, a novel and easy to implement displacement post-processing algorithm is proposed to compensate the systematic errors. The direct digital image correlation displacement result is processed by multiple filters with the same window size as the subset, and the resulting data is employed to recover the actual displacement field. Theoretically, the proposed method is capable of recovering the original continuous displacement function of any order with no bias. The numerical results of elementary function and simulated images show that the proposed algorithm is effective in correcting the displacement systematic bias and improving the subpixel accuracy of digital image correlation. Finally, the algorithm is applied to the displacement measurement of shear band.},
   author = {Pengxiang Bai and Yongmin Xu and Feipeng Zhu and Dong Lei},
   doi = {10.1016/j.optlaseng.2019.105907},
   issn = {01438166},
   journal = {Optics and Lasers in Engineering},
   keywords = {Digital image correlation,Multiple filter,Systematic errors,Undermatched shape function},
   month = {3},
   publisher = {Elsevier Ltd},
   title = {A novel method to compensate systematic errors due to undermatched shape functions in digital image correlation},
   volume = {126},
   year = {2020},
}
@article{Bohnsack_1997,
   author = {E Bohnsack},
   issue = {6},
   journal = {Computers & Structures},
   pages = {1195-1204},
   title = {Continuous Field Approximation of Experimentally Given Data by Finite Elements},
   volume = {63},
   year = {1997},
}
@article{Grediac_2006,
   abstract = {The virtual fields method has been developed for extracting constitutive parameters from full-field measurements provided by optical non-contact techniques for instance. It is based on the principle of virtual work written with some particular virtual fields. This paper can be regarded as a general review summarising some 15 years of developments of this method. The main aspects of the method are first recalled in the case of both linear and non-linear constitutive equations. They are then illustrated by some recent relevant examples. Some studies underway as well as relevant issues to be addressed in the near future are eventually discussed.},
   author = {M Grédiac and F Pierron and S Avril and E Toussaint},
   journal = {Strain},
   keywords = {heterogeneous tests,identification,inverse problem,virtual fields method},
   month = {11},
   pages = {233-253},
   title = {The Virtual Fields Method for Extracting Constitutive Parameters From Full-Field Measurements: a Review},
   volume = {42},
   year = {2006},
}
@book{Gonzalez_2018,
   abstract = {Fourth edition. "For 40 years, Image Processing has been the foundational text for the study of digital image processing. The book is suited for students at the college senior and first-year graduate level with prior background in mathematical analysis, vectors, matrices, probability, statistics, linear systems, and computer programming. As in all earlier editions, the focus of this edition of the book is on fundamentals. The 4th Edition, which celebrates the book's 40th anniversary, is based on an extensive survey of faculty, students, and independent readers in 150 institutions from 30 countries. Their feedback led to expanded or new coverage of topics such as deep learning and deep neural networks, including convolutional neural nets, the scale-invariant feature transform (SIFT), maximally-stable extremal regions (MSERs), graph cuts, k-means clustering and superpixels, active contours (snakes and level sets), and exact histogram matching. Major improvements were made in reorganizing the material on image transforms into a more cohesive presentation, and in the discussion of spatial kernels and spatial filtering. Major revisions and additions were made to examples and homework exercises throughout the book. For the first time, we added MATLAB projects at the end of every chapter, and compiled support packages for you and your teacher containing, solutions, image databases, and sample code."--Amazon.com. Introduction -- Digital image fundamentals -- Intensity transformations and spatial filtering -- Filtering in the frequency domain -- Image restoration and reconstruction -- Wavelet and other image transforms -- Color image processing -- Image compression and watermarking -- Morphological image processing -- Image segmentation I -- Image segmentation II active contours : snakes and level sets -- Feature extraction -- Image pattern classification.},
   author = {Rafael C. Gonzalez and Richard E. (Richard Eugene) Woods},
   city = {Harlow},
   edition = {4},
   isbn = {9780133356724},
   publisher = {Pearson Education Limited},
   title = {{Digital Image Processing}},
   year = {2018},
}
@article{Yang_2017,
   abstract = {Experimental or operational modal analysis traditionally requires physically-attached wired or wireless sensors for vibration measurement of structures. This instrumentation can result in mass-loading on lightweight structures, and is costly and time-consuming to install and maintain on large civil structures, especially for long-term applications (e.g., structural health monitoring) that require significant maintenance for cabling (wired sensors) or periodic replacement of the energy supply (wireless sensors). Moreover, these sensors are typically placed at a limited number of discrete locations, providing low spatial sensing resolution that is hardly sufficient for modal-based damage localization, or model correlation and updating for larger-scale structures. Non-contact measurement methods such as scanning laser vibrometers provide high-resolution sensing capacity without the mass-loading effect; however, they make sequential measurements that require considerable acquisition time. As an alternative non-contact method, digital video cameras are relatively low-cost, agile, and provide high spatial resolution, simultaneous, measurements. Combined with vision based algorithms (e.g., image correlation, optical flow), video camera based measurements have been successfully used for vibration measurements and subsequent modal analysis, based on techniques such as the digital image correlation (DIC) and the point-tracking. However, they typically require speckle pattern or high-contrast markers to be placed on the surface of structures, which poses challenges when the measurement area is large or inaccessible. This work explores advanced computer vision and video processing algorithms to develop a novel video measurement and vision-based operational (output-only) modal analysis method that alleviate the need of structural surface preparation associated with existing vision-based methods and can be implemented in a relatively efficient and autonomous manner with little user supervision and calibration. First a multi-scale image processing method is applied on the frames of the video of a vibrating structure to extract the local pixel phases that encode local structural vibration, establishing a full-field spatiotemporal motion matrix. Then a high-spatial dimensional, yet low-modal-dimensional, over-complete model is used to represent the extracted full-field motion matrix using modal superposition, which is physically connected and manipulated by a family of unsupervised learning models and techniques, respectively. Thus, the proposed method is able to blindly extract modal frequencies, damping ratios, and full-field (as many points as the pixel number of the video frame) mode shapes from line of sight video measurements of the structure. The method is validated by laboratory experiments on a bench-scale building structure and a cantilever beam. Its ability for output (video measurements)-only identification and visualization of the weakly-excited mode is demonstrated and several issues with its implementation are discussed.},
   author = {Yongchao Yang and Charles Dorn and Tyler Mancini and Zachary Talken and Garrett Kenyon and Charles Farrar and David Mascareñas},
   doi = {10.1016/j.ymssp.2016.08.041},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Blind source separation,Motion magnification,Non-contact measurements,Operational modal analysis,Video processing},
   month = {2},
   pages = {567-590},
   publisher = {Academic Press},
   title = {{Blind identification of full-field vibration modes from video measurements with phase-based video motion magnification}},
   volume = {85},
   year = {2017},
}
@inproceedings{Dorini_2009,
   abstract = {Multiscale approaches have been largely considered in several signal processing applications. They play an important role when designing automatic methods to cope with real world measurements where, in most of the cases, there is no prior information about which would be the appropriate scale. The basic idea behind a multiscale analysis is to embed the original signal into a family of derived signals, thus allowing the analysis of different representation levels and, further, the choice of the ones exhibiting the interest features. This paper presents a brief survey of two broadly used multiscale formulations, namely, wavelets and scale-space filtering. We present the basic definitions and some possible applications of these approaches in image processing. © 2009 IEEE.},
   author = {Leyza Baldo Dorini and Neucimar Jerônimo Leite},
   doi = {10.1109/SIBGRAPI-Tutorials.2009.11},
   isbn = {9780769538150},
   journal = {Tutorials of SIBGRAPI 2009 - 22nd Brazilian Symposium on Computer Graphics and Image Processing},
   keywords = {Mathematical morphology,Multiscale image analysis,Scale-space filtering,Wavelets},
   pages = {31-44},
   title = {Multiscale methods for image processing: The wavelet and the scale-space approaches},
   year = {2009},
}
@article{Pan_2011,
   abstract = {In this paper, we report the following important progress recently made in the basic theory and practical implementation of digital image correlation (DIC) for deformation measurement. First, we answer a basic but confusing question to the users of DIC: what is a good speckle pattern for DIC? We present a simple, easy-to-compute yet effective global parameter, called mean intensity gradient, for quality assessment of the entire speckle pattern. Second, we provide an overview of various correlation criteria used in DIC for evaluating the similarity of the reference and deformed subsets, and demonstrate the equivalence of three robust and most widely used correlation criteria, i. e., a zero-mean normalized cross-correlation (ZNCC) criterion, a zero-mean normalized sum of squared difference (ZNSSD) criterion and a parametric zero-mean normalized sum of squared difference (PSSDab) criterion with two additional unknown parameters, which elegantly unifies these correlation criteria for subset-based pattern matching. Third, we describe an iterative least squares (ILS) algorithm for accurate subpixel motion detection, which is proved to be equivalent to the existing Newton-Raphson algorithm, but the principle and implementation of ILS algorithm is more straightforward and easier. Finally, to overcome the two limitations of existing subset-based DIC technique, we introduce a robust and generally applicable reliability-guided DIC technique, in which the calculation path is guided by the ZNCC coefficients of computed points, to determine the genuine full-field deformation of an object with complex shape. © 2010 Society for Experimental Mechanics.},
   author = {B. Pan},
   doi = {10.1007/s11340-010-9418-3},
   issn = {00144851},
   issue = {7},
   journal = {Experimental Mechanics},
   keywords = {Deformation measurement,Digital image correlation,Speckle pattern,Subpixel},
   month = {9},
   pages = {1223-1235},
   title = {Recent Progress in Digital Image Correlation},
   volume = {51},
   year = {2011},
}
@article{Pan_2009,
   abstract = {As a practical and effective tool for quantitative in-plane deformation measurement of a planar object surface, two-dimensional digital image correlation (2D DIC) is now widely accepted and commonly used in the field of experimental mechanics. It directly provides full-field displacements to sub-pixel accuracy and full-field strains by comparing the digital images of a test object surface acquired before and after deformation. In this review, methodologies of the 2D DIC technique for displacement field measurement and strain field estimation are systematically reviewed and discussed. Detailed analyses of the measurement accuracy considering the influences of both experimental conditions and algorithm details are provided. Measures for achieving high accuracy deformation measurement using the 2D DIC technique are also recommended. Since microscale and nanoscale deformation measurement can easily be realized by combining the 2D DIC technique with high-spatial- resolution microscopes, the 2D DIC technique should find more applications in broad areas. © 2009 IOP Publishing Ltd.},
   author = {Bing Pan and Kemao Qian and Huimin Xie and Anand Asundi},
   doi = {10.1088/0957-0233/20/6/062001},
   issn = {13616501},
   issue = {6},
   journal = {Measurement Science and Technology},
   keywords = {Digital image correlation,Displacement/deformation measurement},
   publisher = {Institute of Physics Publishing},
   title = {Two-dimensional digital image correlation for in-plane displacement and strain measurement: A review},
   volume = {20},
   year = {2009},
}
@inproceedings{Pan_2006,
   abstract = {Developments in digital image correlation in the last two decades have made it a popular and effective tool for full-field displacement and strain measurements in experimental mechanics. In digital image correlation, the use of the sub-pixel registration algorithm is regarded as the key technique to improve accuracy. Different types of sub-pixel registration algorithms have been developed. However, little quantitative research has been carried out to compare their performances. This paper investigates three types of the most commonly used sub-pixel displacement registration algorithms in terms of the registration accuracy and the computational efficiency using computer-simulated speckle images. A detailed examination of the performances of each algorithm reveals that the iterative spatial domain cross-correlation algorithm (Newton-Raphson method) is more accurate, but much slower than other algorithms, and is recommended for use in these applications. © 2006 IOP Publishing Ltd.},
   author = {Bing Pan and Hui Min Xie and Bo Qin Xu and Fu Long Dai},
   doi = {10.1088/0957-0233/17/6/045},
   issn = {13616501},
   issue = {6},
   journal = {Measurement Science and Technology},
   keywords = {Curve-fitting,Digital image correlation,Gradient-based algorithm,Newton-Raphson method,Sub-pixel},
   month = {6},
   pages = {1615-1621},
   publisher = {Institute of Physics Publishing},
   title = {Performance of sub-pixel registration algorithms in digital image correlation},
   volume = {17},
   year = {2006},
}
@article{Gadhe:2016,
   author = {Supriya S. Gadhe and R.R Navthar},
   doi = {10.14445/22315381/IJETT-V39P251},
   issn = {22315381},
   issue = {6},
   journal = {International Journal of Engineering Trends and Technology},
   month = {9},
   pages = {306-311},
   title = {Digital Image Correlation Technique for Strain Measurement of Aluminium Plate},
   volume = {39},
   url = {http://www.ijettjournal.org/archive/ijett-v39p251},
   year = {2016},
}
@article{Helfrick_2011,
   abstract = {In the area of modal test/analysis/correlation, significant effort has been expended over the past twenty years in order to make reduced models and to expand test data for correlation and eventual updating of the finite element models. This has been restricted by vibration measurements which are traditionally limited to the location of relatively few applied sensors. Advances in computers and digital imaging technology have allowed 3D digital image correlation (DIC) methods to measure the shape and deformation of a vibrating structure. This technique allows for full-field measurement of structural response, thus providing a wealth of simultaneous test data. This paper presents some preliminary results for the test/analysis/correlation of data measured using the DIC approach along with traditional accelerometers and a scanning laser vibrometer for comparison to a finite element model. The results indicate that all three approaches correlated well with the finite element model and provide validation for the DIC approach for full-field vibration measurement. Some of the advantages and limitations of the technique are presented and discussed. © 2010 Elsevier Ltd.All rights reserved.},
   author = {Mark N. Helfrick and Christopher Niezrecki and Peter Avitabile and Timothy Schmidt},
   doi = {10.1016/j.ymssp.2010.08.013},
   issn = {08883270},
   issue = {3},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Digital image correlation,Full-field measurement,Modal testing,Mode shape correlation,Vibration measurement},
   month = {4},
   pages = {917-927},
   title = {{3D digital image correlation methods for full-field vibration measurement}},
   volume = {25},
   year = {2011},
}
@article{Wang_2012,
   abstract = {The availability of high speed digital cameras has enabled three-dimensional (3D) vibration measurement by stereography and digital image correlation (DIC). The 3D DIC technique provides non-contact full-field measurements on complex surfaces whereas conventional modal testing methods employ point-wise frequency response functions. It is proposed to identify the modal properties by utilising the domain-wise responses captured by a DIC system. This idea will be illustrated by a case study in the form a car bonnet of 3D irregular shape typical of many engineering structures. The full-field measured data are highly redundant, but the application of image processing using functional transformation enables the extraction of a small number of shape features without any significant loss of information from the raw DIC data. The complex bonnet surface on which the displacement responses are measured is essentially a 2-manifold. It is possible to apply surface parameterisation to 'flatten' the 3D surface to form a 2D planar domain. Well-developed image processing techniques are defined on planar domains and used to extract features from the displacement patterns on the surface of a specimen. An adaptive geometric moment descriptor (AGMD), defined on surface parametric space, is able to extract shape features from a series of full-field transient responses under random excitation. Results show the effectiveness of the AGMD and the obtained shape features are demonstrated to be succinct and efficient. Approximately 14 thousand data points of raw DIC measurement are represented by 20 shape feature terms at each time step. Shape-descriptor frequency response functions (SD-FRFs) of the response field and the loading field are derived in the shape feature space. It is seen that the SD-FRF has a similar format to the conventional receptance FRF. The usual modal identification procedure is applied to determine the natural frequencies, damping factors and eigen-shape-feature vectors from the SD-FRF. Natural frequencies and mode shapes from a finite element (FE) model are correlated with the experimental data using the cosine distance between the shape feature vectors with 20 terms. There are numerous benefits of using image decomposition to analyse 3D DIC measured data, including (1) representation of the raw measurement data with efficiency and succinctness; (2) determination of the FRF of any point on the specimen by the use of the full-field shape features; and (3) elimination of DIC measurement noise. Also, the SD-FRF is potentially ideal for cases of field excitation of structures. © 2011 Elsevier Ltd. All rights reserved.},
   author = {Weizhuo Wang and John E. Mottershead and Thorsten Siebert and Andrea Pipino},
   doi = {10.1016/j.ymssp.2011.11.023},
   issn = {08883270},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Digital image correlation,Frequency response function,Full-field measurement,Geometric shape descriptor,Modal identification,Surface parameterisation},
   month = {4},
   pages = {333-347},
   title = {{Frequency response functions of shape features from full-field vibration measurements using digital image correlation}},
   volume = {28},
   year = {2012},
}
@article{Barron_1994,
   abstract = {While different optical flow techniques continue to appear, there has been a lack of quantitative evaluation of existing methods. For a common set of real and synthetic image sequences, we report the results of a number of regularly cited optical flow techniques, including instances of differential, matching, energy-based, and phase-based methods. Our comparisons are primarily empirical, and concentrate on the accuracy, reliability, and density of the velocity measurements; they show that performance can differ significantly among the techniques we implemented. © 1994 Kluwer Academic Publishers.},
   author = {J. L. Barron and D. J. Fleet and S. S. Beauchemin},
   doi = {10.1007/BF01420984},
   issn = {09205691},
   issue = {1},
   journal = {International Journal of Computer Vision},
   month = {2},
   pages = {43-77},
   publisher = {Kluwer Academic Publishers},
   title = {Performance of optical flow techniques},
   volume = {12},
   year = {1994},
}
@article{Lucas_1981,
   author = {Bruce D Lucas and T Kanade},
   city = {San Francisco, CA, USA},
   journal = {7th International Joint Conference on Artificial Intelligence},
   pages = {674-679},
   publisher = {Kaufmann Publishers Inc.},
   title = {{An iterative image registration technique with an application to stereo vision}},
   year = {1981},
}
@article{Horn_1981,
   abstract = {Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantized rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image.},
   author = {Berthold K P Horn and Brian G Schunck},
   doi = {10.1016/0004-3702(81)90024-2},
   journal = {Artificial Intelligence},
   pages = {185-203},
   title = {{Determining Optical Flow}},
   volume = {17},
   year = {1981},
}
@inproceedings{Hartmann_2019,
   author = {Christoph Hartmann and Wolfram Volk},
   isbn = {9781912532094},
   journal = {International Conference on Digital Image & Signal Processing},
   pages = {1-8},
   title = {Digital image correlation and optical flow analysis based on the material texture with application on high-speed deformation measurement in shear cutting},
   url = {http://dx.doi.org/10.17501........................................},
   year = {2019},
}
@inproceedings{Boye_2009,
   abstract = {Research into the use of multiframe superresolution has led to the development of algorithms for providing images with enhanced resolution using several lower resolution copies. An integral component of these algorithms is the determination of the registration of each of the low resolution images to a reference image. Without this information, no resolution enhancement can be attained. We have endeavored to find a suitable method for registering severely undersampled images by comparing several approaches. To test the algorithms, an ideal image is input to a simulated image formation program, creating several undersampled images with known geometric transformations. The registration algorithms are then applied to the set of low resolution images and the estimated registration parameters compared to the actual values. This investigation is limited to monochromatic images (extension to color images is not difficult) and only considers global geometric transformations. Each registration approach will be reviewed and evaluated with respect to the accuracy of the estimated registration parameters as well as the computational complexity required. In addition, the effects of image content, specifically spatial frequency content, as well as the immunity of the registration algorithms to noise will be discussed.},
   author = {R. R. Boye and C. L. Nelson},
   doi = {10.1117/12.810369},
   issn = {0277786X},
   journal = {Computational Imaging VII},
   month = {2},
   pages = {72460X},
   publisher = {SPIE},
   title = {Comparison of subpixel image registration algorithms},
   volume = {7246},
   year = {2009},
}
@article{Slavič_2011,
   abstract = {In the past decade damping-identification methods based on the continuous wavelet transform (CWT) have been shown to be some of the best methods for analyzing the damping of multi-degree-of-freedom systems. The CWT methods have proven themselves to be resistant to noise and able to identify damping at closely spaced natural frequencies. However, with the CWT-based techniques, the CWT needs to be obtained on a two-dimensional, timefrequency grid, and they are, therefore, computationally demanding. Furthermore, the CWT is susceptible to the edge effect, which causes a non-valid identification at the start and the end of the time-series. This study introduces a new method, called the Morlet-wave method, where a finite integral similar to the CWT is used for the identification of the viscous damping. Instead of obtaining the CWT on a two-dimensional grid, the finite integral needs to be calculated at one timefrequency point, only. Then using two different integration parameters, the damping ratio can be identified. A complete mathematical background of the new, Morlet-wave, damping-identification method is given and this results in a root-finding or a closed-form solution. The presented numerical experiments show that the new method has a similar performance to the CWT-based damping-identification methods, while the method is numerically, significantly less demanding, completely avoids the edge effect, and the procedure is straightforward to use. © 2010 Elsevier Ltd. All rights reserved.},
   author = {Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2011.01.008},
   issn = {08883270},
   issue = {5},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Close modes,Continuous wavelet transform,Damping identification,Morlet,Noise,Wave},
   month = {7},
   pages = {1632-1645},
   title = {Damping identification with the Morlet-wave},
   volume = {25},
   year = {2011},
}
@article{Gorjup_2019,
   abstract = {The use of high-speed camera systems in vibration measurements is typically limited to identifying motion, transversal to the optical axis, due to an inherent limitation of 2D imaging systems. Depth information, lost in the imaging process, can be recovered by using the well-established 3D DIC technique, but is still limited to a single face of the object, observed by the stereo pair. In this research a full-field 3D operating-deflection-shape measurement technique, based on frequency-domain triangulation of image-data, is presented. A mathematical model of frequency-domain perspective transformation of small harmonic motion is introduced. This model is used to relate multiview image data to spatial amplitude spectra of the observed displacement. Using the developed method, spatial small harmonic motion of arbitrary-shaped specimen can be identified in the frequency domain using only a single, moving high-speed camera, extending the field-of-view of the established image-based vibration measurement methods.},
   author = {D. Gorjup and J. Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2019.106287},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Digital image correlation,Frequency domain,Full-field displacement measurement,Multiview geometry,Single-camera,Spatial operating-deflection-shapes,Triangulation},
   pages = {106287},
   publisher = {Academic Press},
   title = {{Frequency domain triangulation for full-field 3D operating-deflection-shape identification}},
   volume = {133},
   year = {2019},
}
@article{Wu_2018,
   abstract = {Video magnification reveals important and informative subtle variations in the world. These signals are often combined with large motions which result in significant blurring artifacts and haloes when conventional video magnification approaches are used. To counter these issues, this paper presents an amplitude-based filtering algorithm that can magnify small changes in video in presence of large motions. We seek to understand the amplitude characteristic of small changes and large motions with the goal of extracting accurate signals for visualization. Based on spectrum amplitude filtering, the large motions can be removed while small changes can still be magnified by Eulerian approach. An advantage of this algorithm is that it can handle large motions, whether they are linear or nonlinear. Our experimental results show that the proposed method can amplify subtle variations in the presence of large motion, as well as significantly reduce artifacts. We demonstrate the presented algorithm by comparing to the state-of-the-art and provide subjective and objective evidence for the proposed method.},
   author = {Xiu Wu and Xuezhi Yang and Jing Jin and Zhao Yang},
   doi = {10.3390/s18072312},
   issn = {14248220},
   issue = {7},
   journal = {Sensors (Switzerland)},
   keywords = {Eulerian perspective,Motion processing,Spatio-temporal analysis,Spectrum amplitude,Video magnification},
   month = {7},
   pmid = {30018210},
   publisher = {MDPI AG},
   title = {Amplitude-based filtering for video magnification in presence of large motion},
   volume = {18},
   year = {2018},
}
@article{Fritzen_1998,
   abstract = {The paper examines the problem of detecting the location and extent of structural damage from measured vibration test data. The method is based upon a mathematical model representing the undamaged vibrating structure and a local description of the damage, e.g. a finite element for a cracked beam. The problem of modeling errors and their influence to damage localisation accuracy is discussed and an approach to obtain reliable results in this case is presented. The concept of inverse sensitivity equations is used which can be based on any type of data, e.g. modal data, FRFs, time series, or a combination of these. The resulting inverse problem usually is ill-posed, and therefore special attention is required for an accurate solution. The application to damage detection problems requires the reduction of a large set of damage parameter candidates to a small subset of one or two parameters that actually describes the local change of the system. An orthogonalisation strategy is given to reduce the parameter set. The method is demonstrated through application to laboratory structures in the frequency domain using frequency response functions and in the time domain.},
   author = {C.-P Fritzen and D Jennewein and T Kiefer},
   issue = {1},
   journal = {Mechanical Systems and Signal Processing},
   pages = {163-186},
   title = {Damage Detection based on Model Updating Methods},
   volume = {12},
   year = {1998},
}
@article{Sinha_2002_2,
   abstract = {A new simplified approach to modelling cracks in beams undergoing transverse vibration is presented. The modelling approach uses Euler-Bernoulli beam elements with small modifications to the local flexibility in the vicinity of cracks. This crack model is then used to estimate the crack locations and sizes, by minimizing the difference between the measured and predicted natural frequencies via model updating. The uniqueness of the approach is that the simplified crack model allows the location and damage extent to be estimated directly. The simplified crack model may also be used to generate training data for pattern recognition approaches to health monitoring. The proposed method has been illustrated using the experimental data on beam examples.},
   author = {J. K. Sinha and M. I. Friswell and S. Edwards},
   doi = {10.1006/jsvi.2001.3978},
   issn = {0022460X},
   issue = {1},
   journal = {Journal of Sound and Vibration},
   month = {3},
   pages = {13-38},
   publisher = {Academic Press},
   title = {Simplified models for the location of cracks in beam structures using measured vibration data},
   volume = {251},
   year = {2002},
}
@article{Sinha_2002,
   author = {J. K. Sinha and M.I. Friswell},
   issue = {1},
   journal = {The Shock and Vibration Digest},
   pages = {27-35},
   title = {Model Updating: A Tool for Reliable Modelling, DesignModification and Diagnosis},
   volume = {34},
   year = {2002},
}
@inproceedings{Seitz_2006,
   abstract = {This paper presents a quantitative comparison of several multi-view stereo reconstruction algorithms. Until now, the lack of suitable calibrated multi-view image datasets with known ground truth (3D shape models) has prevented such direct comparisons. In this paper, we first survey multi-view stereo algorithms and compare them qualitatively using a taxonomy that differentiates their key properties. We then describe our process for acquiring and calibrating multi-view image datasets with high-accuracy ground truth and introduce our evaluation methodology. Finally, we present the results of our quantitative comparison of state-of-the-art multi-view stereo reconstruction algorithms on six benchmark datasets. The datasets, evaluation details, and instructions for submitting new models are available online at},
   author = {Steven M Seitz and Brian Curless and James Diebel and Daniel Scharstein and Richard Szeliski},
   journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
   pages = {519-528},
   title = {A Comparison and Evaluation of Multi-View Stereo Reconstruction Algorithms},
   url = {http://vision.middlebury.edu/mview.},
   year = {2006},
}
@thesis{Simeon_2023,
   author = {Felix Simeon Egner},
   title = {Full-field camera measurements for structural and vibro-acoustic system analysis},
   year = {2023},
}
@inproceedings{Wu_2013,
   abstract = {The time complexity of incremental structure from motion (SfM) is often known as O(n 4) with respect to the number of cameras. As bundle adjustment (BA) being significantly improved recently by preconditioned conjugate gradient (PCG), it is worth revisiting how fast incremental SfM is. We introduce a novel BA strategy that provides good balance between speed and accuracy. Through algorithm analysis and extensive experiments, we show that incremental SfM requires only O(n) time on many major steps including BA. Our method maintains high accuracy by regularly re-triangulating the feature matches that initially fail to triangulate. We test our algorithm on large photo collections and long video sequences with various settings, and show that our method offers state of the art performance for large-scale reconstructions. The presented algorithm is available as part of VisualSFM at http://homes.cs.washington.edu/~ccwu/vsfm/. © 2013 IEEE.},
   author = {Changchang Wu},
   doi = {10.1109/3DV.2013.25},
   isbn = {9780769550671},
   journal = {Proceedings - 2013 International Conference on 3D Vision, 3DV 2013},
   keywords = {Structure from Motion,VisualSFM},
   pages = {127-134},
   title = {Towards linear-time incremental structure from motion},
   year = {2013},
}
@article{Westoby_2012,
   abstract = {High-resolution topographic surveying is traditionally associated with high capital and logistical costs, so that data acquisition is often passed on to specialist third party organisations. The high costs of data collection are, for many applications in the earth sciences, exacerbated by the remoteness and inaccessibility of many field sites, rendering cheaper, more portable surveying platforms (i.e. terrestrial laser scanning or GPS) impractical. This paper outlines a revolutionary, low-cost, user-friendly photogrammetric technique for obtaining high-resolution datasets at a range of scales, termed 'Structure-from-Motion' (SfM). Traditional softcopy photogrammetric methods require the 3-D location and pose of the camera(s), or the 3-D location of ground control points to be known to facilitate scene triangulation and reconstruction. In contrast, the SfM method solves the camera pose and scene geometry simultaneously and automatically, using a highly redundant bundle adjustment based on matching features in multiple overlapping, offset images. A comprehensive introduction to the technique is presented, followed by an outline of the methods used to create high-resolution digital elevation models (DEMs) from extensive photosets obtained using a consumer-grade digital camera. As an initial appraisal of the technique, an SfM-derived DEM is compared directly with a similar model obtained using terrestrial laser scanning. This intercomparison reveals that decimetre-scale vertical accuracy can be achieved using SfM even for sites with complex topography and a range of land-covers. Example applications of SfM are presented for three contrasting landforms across a range of scales including; an exposed rocky coastal cliff; a breached moraine-dam complex; and a glacially-sculpted bedrock ridge. The SfM technique represents a major advancement in the field of photogrammetry for geoscience applications. Our results and experiences indicate SfM is an inexpensive, effective, and flexible approach to capturing complex topography. © 2012 Elsevier B.V.},
   author = {M. J. Westoby and J. Brasington and N. F. Glasser and M. J. Hambrey and J. M. Reynolds},
   doi = {10.1016/j.geomorph.2012.08.021},
   issn = {0169555X},
   journal = {Geomorphology},
   keywords = {Close-range photogrammetry,Digital elevation model (DEM),SFMToolkit,Structure-from-Motion (SfM),Terrestrial laser scanning (TLS)},
   month = {12},
   pages = {300-314},
   title = {'Structure-from-Motion' photogrammetry: A low-cost, effective tool for geoscience applications},
   volume = {179},
   year = {2012},
}
@inproceedings{Schonberger_2016,
   abstract = {Incremental Structure-from-Motion is a prevalent strategy for 3D reconstruction from unordered image collections. While incremental reconstruction systems have tremendously advanced in all regards, robustness, accuracy , completeness, and scalability remain the key problems towards building a truly general-purpose pipeline. We propose a new SfM technique that improves upon the state of the art to make a further step towards this ultimate goal. The full reconstruction pipeline is released to the public as an open-source implementation.},
   author = {Johannes L Schönberger and Jan-Michael Frahm},
   journal = {IEEE Conference on Computer Vision and Pattern Recognition},
   pages = {4104-4113},
   title = {Structure-from-Motion Revisited},
   url = {https://github.com/colmap/colmap.},
   year = {2016},
}
@article{Lowe_2004,
   abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a a substantial range of affine distortion , change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
   author = {David G Lowe},
   journal = {International Journal of Computer Vision},
   title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
   year = {2004},
}
@article{Zappa_2014,
   abstract = {Even though digital image correlation (DIC) is a widely used optical full field measurement method, it still needs further performance investigations, when it comes to dynamic conditions. Dealing with a moving target, causes a motion effect (i.e. blurring) on the acquired images. This factor is an important source of uncertainty that needs to be quantified. Therefore, the present study aims to perform a systematic uncertainty assessment of DIC method in general dynamic applications. The study focuses on 2D DIC. In the case of 3D DIC similar problems will arise and therefore, a complete understanding of two dimensional conditions will be of great help to further studies which deal with 3D conditions. The whole work can be divided in to two parts. In the first part, a method to simulate the motion effect on a reference image is proposed to be applied. This method allows simulating the acquired images in a real dynamic test and estimating the measurement uncertainty caused by the motion effect. Using this technique, the uncertainty of DIC measurement is estimated. The second part of the study aimed to validate the simulation technique. Therefore, several tests are conducted by imposing harmonic motion to a target, in different frequencies and amplitudes. The results show good agreement between the experiments and the simulations, proving the introduced technique to be an effective method for motion induced uncertainty estimation. © 2013 Elsevier Ltd.},
   author = {Emanuele Zappa and Paolo Mazzoleni and Ali Matinmanesh},
   doi = {10.1016/j.optlaseng.2013.12.016},
   issn = {01438166},
   journal = {Optics and Lasers in Engineering},
   keywords = {Digital image correlation,Dynamics,Motion simulation,Uncertainty assessment},
   pages = {140-151},
   publisher = {Elsevier Ltd},
   title = {Uncertainty assessment of digital image correlation method in dynamic applications},
   volume = {56},
   year = {2014},
}
@article{Friswell_2002,
   abstract = {There are a number of approaches to the modeling of cracks in beam structures reported in the literature, that fall into three main categories; local stiffness reduction, discrete spring models, and complex models in two or three dimensions. This paper compares the different approaches to crack modeling, and demonstrates that for structural health monitoring using low frequency vibration, simple models of crack flexibility based on beam elements are adequate. This paper also addresses the effect of the excitation for breathing cracks, where the beam stiffness is bilinear, depending on whether the crack is open or closed. Most structural health monitoring methods assume that the structure is behaving linearly, whereas in practice the response will be nonlinear to an extent that varies with the form of the excitation. This paper will demonstrate these effects for a simple beam structure. Copyright © 2002 Sage Publications.},
   author = {M. I. Friswell and J. E.T. Penny},
   doi = {10.1106/145792102028836},
   issn = {14759217},
   issue = {2},
   journal = {Structural Health Monitoring},
   keywords = {Breathing crack,Crack,Finite element modeling,Structural health monitoring,Vibration},
   pages = {139-148},
   title = {Crack modeling for structural health monitoring},
   volume = {1},
   year = {2002},
}
@article{Zaletelj_2022,
   abstract = {Cite as: Klemen Zaletelj, Janko Slavič and Miha Boltežar, Full-field DIC-based model updating for localized parameter identification, Mechanical Systems and Signal Processing, Volume 164, February 2022, https: // doi. Abstract Identifying the local properties of a structure, either to perform structural health monitoring or to fine tune a numerical model, requires the updating of a large number of parameters. With a high spatial density, but a low dynamic range response information, high-speed-camera measurements have the potential to identify a large number of localized parameters. In contrast, accelerometer measurements provide low-spatial-density modal shapes, but a high dynamic range, and introduce the problem of mass loading. In this research , modal shapes from a high-speed camera are used, providing full-field response information about the observed structure and an over-determined optimization problem. Since the high-speed camera has a lower dynamic range than the accelerometer and the signal-to-noise ratio is low where the displacement amplitude is small, location-specific weighting methods were introduced. The numerical and real experiments showed that the accelerom-eter's positioning is important for successful updating, while with a high-speed-camera measurement this is not relevant. This research showed that due to the spatial over-determination, the model updating based on high-speed-camera data, was significantly better than the low-spatial-resolution, accelerometer-based approach.},
   author = {Klemen Zaletelj and Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2021.108287},
   issue = {3},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {DIC,finite-element-model updating,full-field response,localized parameters},
   pages = {108287},
   title = {{Full-field DIC-based model updating for localized parameter identification}},
   volume = {164},
   year = {2022},
}
@article{Witt_2021,
   abstract = {Digital image correlation (DIC) is an established test technique in several fields including quasi-static displacement measurements. Recently there has been growing interest in using DIC to measure structural dynamic response and even extract modal parameters from that information. While high-speed cameras have become more ubiquitous, there are no commercial end-to-end packages for modal analysis based on image data, particularly when combined with traditional data acquisition systems. As such, the practitioner is left to develop several key data processing capabilities, hardware interface equipment, and testing practices themselves. This work highlights several practical aspects that have been encountered while establishing DIC as a viable modal testing capability in a laboratory environment.},
   author = {Bryan L. Witt and Daniel P. Rohe},
   doi = {10.1007/s40799-020-00420-6},
   issn = {17471567},
   issue = {3},
   journal = {Experimental Techniques},
   keywords = {Digital image correlation,High-speed imaging,Modal,Photogrammetry,Practical application},
   month = {6},
   pages = {273-286},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Digital Image Correlation as an Experimental Modal Analysis Capability},
   volume = {45},
   year = {2021},
}
@article{Tomac_2023,
   author = {I. Tomac and J. Slavič},
   doi = {10.1016/j.ymssp.2023.110243},
   issn = {08883270},
   journal = {Mechanical Systems and Signal Processing},
   month = {6},
   pages = {110243},
   title = {Morlet-wave-based modal identification in the time domain},
   volume = {192},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S0888327023001504},
   year = {2023},
}
@article{Marquardt_1963,
   abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.},
   author = {Donald W Marquardt and Donald W Marquardtt},
   issue = {2},
   journal = {Source: Journal of the Society for Industrial and Applied Mathematics},
   pages = {431-441},
   title = {An Algorithm for Least-Squares Estimation of Nonlinear Parameters},
   volume = {11},
   year = {1963},
}
@article{Lin_2020,
   abstract = {Eigenvalue and eigenvector derivatives with respect to system design variables and their applications have been and continue to be one of the core issues in the design, control and identification of practical engineering systems. Many different numerical methods have been developed to compute accurately and efficiently these required derivatives from which, a wide range of successful applications have been established. This paper reviews and examines these methods of computing eigenderivatives for undamped, viscously damped, nonviscously damped, fractional and nonlinear vibration systems, as well as defective systems, for both distinct and repeated eigenvalues. The underlying mathematical relationships among these methods are discussed, together with new theoretical developments. Major important applications of eigenderivatives to finite element model updating, structural design and modification prediction, performance optimization of structures and systems, optimal control system design, damage detection and fault diagnosis, as well as turbine bladed disk vibrations are examined. Existing difficulties are identified and measures are proposed to rectify them. Various examples are given to demonstrate the key theoretical concepts and major practical applications of concern. Potential further research challenges are identified with the purpose of concentrating future research effort in the most fruitful directions.},
   author = {R. M. Lin and J. E. Mottershead and T. Y. Ng},
   doi = {10.1016/j.ymssp.2019.106536},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Applications,Derivatives,Eigenvalues,Eigenvectors,Review,Theory},
   month = {4},
   publisher = {Academic Press},
   title = {A state-of-the-art review on theory and engineering applications of eigenvalue and eigenvector derivatives},
   volume = {138},
   year = {2020},
}
@article{,
   abstract = {Modal analysis using structural responses identified from high-speed cameras is a challenging task. The problem is that the measured displacements are relatively small (typically deep in the sub-pixel range) and submerged in noise due to the low dynamic range of the camera sensor. The typical approach to determining structural responses from high-speed camera data is the digital image correlation (DIC) method, a general, computationally intensive method for identifying displacements. Without knowing the assumptions of the modal analysis, DIC identifies the displacement in the time domain by minimising the difference between two consecutive regions of interest (ROIs). Optical flow is a method based on the change in intensity in a given pixel due to the change in reflection from a moving surface. The displacement is identified from the change in intensity and the spatial gradient of the intensity of the surface. For small, sub-pixel movements, the relationship between intensity change and displacement is linear, which opens up the possibility of performing the modal analysis directly on the pixel intensity measured by the camera. This research applies the recently introduced Morlet-wave modal method and introduces an experimental modal analysis based on a single pixel with optical flow directly from the pixel intensities and the spatial gradient of the intensity. Furthermore, it is shown that the natural frequencies and damping ratios do not require the spatial gradient. The introduced method was successfully applied to the experimental test case where a pixel-based, full-field modal analysis was performed. The influence of averaging the results from multiple pixels in the modal domain 1 is investigated. The introduced direct pixel-based modal analysis provides a robust and numerically efficient way to a full-field modal analysis.},
   author = {I Tomac and J Slavič and D Gorjup},
   keywords = {Morlet-wave,full-field,modal identification,single pixel},
   title = {Single-pixel optical-flow-based experimental modal analysis},
}
@article{Thomas_1975,
   abstract = {This paper presents for the first time a finite element model with nodal degrees of freedom which can satisfy all the forced and natural boundary conditions of a Timoshenko beam. The mass and stiffness matrices of the element are derived from kinetic and strain energies by assigning polynomial expressions for total deflection and bending slope. The superiority of this element is illustrated by comparing the results with those given by various ' ~ investigators using other element models.},
   author = {J Thomas and B A H Abbas},
   issue = {3},
   journal = {Journal of Sound and Vibration},
   pages = {291-299},
   title = {Finite element model for dynamic analysis of Timoshenko beam},
   year = {1975},
}
@article{Guillaume_2003,
   abstract = {The Least-Squares Complex Frequency-domain (LSCF) estimator can be viewed as a frequency-domain implementation of the well-known Least-Squares Complex Exponential (LSCE) estimator. An important advantage of the LSCF estimator is the fact that it produces "fast-stabilizing" stabilization charts. In this contribution, the LSCF estimator will be generalized to a "poly-reference" estimator.},
   author = {Patrick Guillaume and Peter Verboven and Steve Vanlanduit and Herman Van Der Auweraer and Bart Peeters},
   city = {Kissimmee, FL},
   journal = {Proceedings of IMAC},
   publisher = {Society for Experimental Mechanics},
   title = {{A poly-reference implementation of the least-squares complex frequency-domain estimator}},
   volume = {21},
   year = {2003},
}
@article{Brincker_2014,
   abstract = {This paper gives an overview of the main components of operational modal analysis (OMA) and can serve as a tutorial for research oriented OMA applications. The paper gives a short introduction to the modeling of random responses and to the transforms often used in OMA such as the Fourier series, the Fourier integral, the Laplace transform, and the Z-transform. Then the paper introduces the spectral density matrix of the random responses and presents the theoretical solutions for correlation function and spectral density matrix under white noise loading. Some important guidelines for testing are mentioned and the most common techniques for signal processing of the operating signals are presented. The algorithms of some of the commonly used time domain and frequency domain identification techniques are presented and finally some issues are discussed such as mode shape scaling, and mode shape expansion. The different techniques are illustrated on the difficult case of identifying the three first closely spaced modes of the Heritage Court Tower building. © 2014 Rune Brincker.},
   author = {Rune Brincker},
   doi = {10.1155/2014/325839},
   issn = {10709622},
   journal = {Shock and Vibration},
   publisher = {Hindawi Limited},
   title = {Some elements of operational modal analysis},
   volume = {2014},
   year = {2014},
}
@article{Javh_2018,
   abstract = {Vibration measurements using optical full-field systems based on high-speed footage are typically heavily burdened by noise, as the displacement amplitudes of the vibrating structures are often very small (in the range of micrometers, depending on the structure). The modal information is troublesome to measure as the structure's response is close to, or below, the noise level of the camera-based measurement system. This paper demonstrates modal parameter identification for such noisy measurements. It is shown that by using the Least-Squares Complex-Frequency method combined with the Least-Squares Frequency-Domain method, identification at high-frequencies is still possible. By additionally incorporating a more precise sensor to identify the eigenvalues, a hybrid accelerometer/high-speed camera mode shape identification is possible even below the noise floor. An accelerometer measurement is used to identify the eigenvalues, while the camera measurement is used to produce the full-field mode shapes close to 10 kHz. The identified modal parameters improve the quality of the measured modal data and serve as a reduced model of the structure's dynamics.},
   author = {Jaka Javh and Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2017.05.008},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Experimental modal analysis,High-speed camera,LSCF,Modal parameter identification,Mode shape,Noise,Optical flow},
   month = {1},
   pages = {344-351},
   publisher = {Academic Press},
   title = {{High frequency modal identification on noisy high-speed camera data}},
   volume = {98},
   year = {2018},
}
@article{Mottershead_2011,
   abstract = {The sensitivity method is probably the most successful of the many approaches to the problem of updating finite element models of engineering structures based on vibration test data. It has been applied successfully to large-scale industrial problems and proprietary codes are available based on the techniques explained in simple terms in this article. A basic introduction to the most important procedures of computational model updating is provided, including tutorial examples to reinforce the reader's understanding and a large scale model updating example of a helicopter airframe. © 2010 Elsevier Ltd. All rights reserved.},
   author = {John E. Mottershead and Michael Link and Michael I. Friswell},
   doi = {10.1016/j.ymssp.2010.10.012},
   issn = {10961216},
   issue = {7},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Model Updating,Sensitivity Method},
   pages = {2275-2296},
   publisher = {Academic Press},
   title = {The sensitivity method in finite element model updating: A tutorial},
   volume = {25},
   year = {2011},
}
@article{Baker_2005,
   abstract = {Mesh generation has evolved to the point where highly complicated domains can be covered by a variety of mesh types including hexahedral, tetrahedral and overset meshes. The application of these methods to computational aerodynamics has become a routine exercise and numerical predictions over complete aircraft now complement experimental results obtained from wind tunnels. This paper surveys the main developments that have taken place and traces the evolution of mesh generation over the last 35 years. This is followed by an assessement of the accuracy of Navier Stokes codes that are currently in use for predicting the drag of an aircraft at transonic cruise. The relationship between solution accuracy, mesh size and mesh type is examined in some detail and the implications for further research are discussed. © 2005 Elsevier Ltd. All rights reserved.},
   author = {Timothy J. Baker},
   doi = {10.1016/j.paerosci.2005.02.002},
   issn = {03760421},
   issue = {1},
   journal = {Progress in Aerospace Sciences},
   month = {1},
   pages = {29-63},
   title = {Mesh generation: Art or science?},
   volume = {41},
   year = {2005},
}
@article{Lee_1980,
   abstract = {This paper provides a unified discussion of the Delaunay triangulation. Its geometric properties are reviewed and several applications are discussed. Two algorithms are presented for constructing the triangulation over a planar set of Npoints. The first algorithm uses a divide-and-conquer approach. It runs in O(Nlog N) time, which is asymptotically optimal. The second algorithm is iterative and requires O(N 2) time in the worst case. However, its average case performance is comparable to that of the first algorithm.},
   author = {D. Lee and B. Schachter},
   issue = {3},
   journal = {International Journal of Computer and Information Sciences},
   keywords = {Delaunay triangulation,Voronoi tessellation,analysis of algorithms,computational geometry,divide-and-con-quer,triangulation},
   month = {6},
   pages = {219-242},
   title = {Two Algorithms for Constructing a Delaunay Triangulation},
   volume = {9},
   year = {1980},
}
@article{Owen_2000,
   abstract = {A brief survey of some of the fundamental algorithms in unstructured mesh generation is presented. Included is a discussion and categorization of triangle, tetrahedral, quadrilateral and hexahedral mesh generation methods currently in use in academia and industry. Also included is a brief discussion of smoothing, cleanup and refinement algorithms. An informal survey of currently available mesh generation software is also provided comparing some of their main features.},
   author = {Steven J Owen},
   journal = {7th International Meshing Roundtable Conference},
   title = {{A Survey of Unstructured Mesh Generation Technology}},
   year = {2000},
}
@article{Fennema_1979,
   abstract = {A method is described which quantifies the speed and direction of several moving objects in a sequence of digital images. A relationship between the time variation of intensity, the spatial gradient, and velocity has been developed which allows the determination of motion using clustering techniques. This paper describes these relationships, the clustering technique, and provides examples of the technique on real images containing several moving objects.},
   author = {Calude L Fennema and William B Thompson},
   issue = {4},
   journal = {Computer Graphics and Image Processing },
   pages = {301-315},
   title = {Velocity determination in scenes containing several moving objects},
   volume = {9},
   year = {1979},
}
@article{Guillaume_1998,
   abstract = {A multivariable frequency-domain maximum likelihood estimator is proposed to identify the modal parameters together with their confidence intervals. The algorithm has been optimized to reduce the computation time as well as the memory requirements. The solver is robust to errors in the non-parametric noise model and can handle measurements with a large dynamical range.},
   author = {Patrick Guillaume and S Vanlanduit and P Verboven},
   journal = {Proceedings of ISMA 23},
   pages = {16-18},
   title = {{Frequency domain maximum likelihood identification of modal parameters with confidence intervals}},
   year = {1998},
}
@article{Delaunay_1934,
   author = {Boris Delaunay},
   issue = {6},
   journal = {Bulletin de l'Academie des Sciences de l'URSS. Classe des sciences mathematiques et na},
   pages = {793-800},
   title = {{Sur la sphere vide. A la memoire de Georges Voronoi}},
   year = {1934},
}
@article{Edelsbrunner_2000,
   author = {Herbert Edelsbrunner},
   journal = {Acta Numerica},
   pages = {1-81},
   title = {Triangulations and meshes in computational geometry},
   volume = {9},
   year = {2000},
}
@article{Zalik_2005,
   abstract = {This paper introduces a new algorithm for constructing a 2D Delaunay triangulation. It is based on a sweep-line paradigm, which is combined with a local optimization criterion - a characteristic of incremental insertion algorithms. The sweep-line status is represented by a so-called advancing front, which is implemented as a hash-table. Heuristics have been introduced to prevent the construction of tiny triangles, which would probably be legalized. This algorithm has been compared with other popular Delaunay algorithms and it is the fastest algorithm among them. In addition, this algorithm does not use a lot of memory for supporting data structure, it is easy to understand and simple to implement. © 2004 Elsevier Ltd. All rights reserved.},
   author = {Borut Žalik},
   doi = {10.1016/j.cad.2004.10.004},
   issn = {00104485},
   issue = {10},
   journal = {CAD Computer Aided Design},
   keywords = {Computational geometry,Delaunay triangulation,Sweep-line paradigm},
   month = {9},
   pages = {1027-1038},
   title = {An efficient sweep-line Delaunay triangulation algorithm},
   volume = {37},
   year = {2005},
}
@article{Guibas_1985,
   author = {Leonidas Guibas and Jorge Stolfi},
   doi = {https://doi.org/10.1145/282918.282923},
   issue = {2},
   journal = {ACM Transactions on Graphics},
   pages = {74-123},
   title = {{Primitives for the manipulation of general subdivisions and the computation of Voronoi}},
   volume = {4},
   year = {1985},
}
@article{Guibas_1992,
   abstract = {In this paper we give a new randomized incremental algorithm for the construction of planar Voronoi diagrams and Delaunay triangulations. The new algorithm is more "on-line" than earlier similar methods, takes expected time O(n\log n) and space O(n), and is eminently practical to implement. The analysis of the algorithm is also interesting in its own right and can serve as a model for many similar questions in both two and three dimensions. Finally we demonstrate how this approach for constructing Voronoi diagrams obviates the need for building a separate point-location structure for nearest-neighbor queries.},
   author = {Leonidas J Guibas and Donald E Knuth and Micha Sharir},
   journal = {Algorithmica},
   keywords = {Delaunay triangulation,Voronoi diagram,randomized algorithms},
   pages = {381-413},
   title = {Randomized Incremental Construction of Delaunay and Voronoi Diagrams 1},
   volume = {7},
   year = {1992},
}
@article{Lawson_1972,
   author = {Charles L. Lawson},
   issue = {4},
   journal = {Discrete Mathematics},
   pages = {365-372},
   title = {Transforming triangulations},
   volume = {3},
   year = {1972},
}
@article{Douka2003,
   abstract = {In this paper a simple method for crack identification in beam structures based on wavelet analysis is presented. The fundamental vibration mode of a cracked cantilever beam is analyzed using continuous wavelet transform and both the location and size of the crack are estimated. The position of the crack is located by the sudden change in the spatial variation of the transformed response. To estimate the size of the crack, an intensity factor is defined which relates the size of the crack to the coefficients of the wavelet transform. An intensity factor law is established which allows accurate prediction of crack size. The viability of the proposed method is investigated both analytically and experimentally in case of a cantilever beam containing a transverse surface crack. In the light of the results obtained, the advantages and limitations of the proposed method as well as suggestions for future work are presented and discussed. © 2003 Elsevier Science Ltd. All rights reserved.},
   author = {E. Douka and S. Loutridis and A. Trochidis},
   doi = {10.1016/S0020-7683(03)00147-1},
   issn = {00207683},
   issue = {13-14},
   journal = {International Journal of Solids and Structures},
   keywords = {Crack identification,Wavelet transform},
   pages = {3557-3569},
   publisher = {Elsevier Ltd},
   title = {Crack identification in beams using wavelet analysis},
   volume = {40},
   year = {2003},
}
@article{Beauchemin_1995,
   author = {S S Beauchemin and J L Barron},
   issue = {3},
   journal = {ACM Computing Surveys},
   month = {9},
   pages = {433-466},
   title = {The Computation of Optical Flow},
   volume = {24},
   year = {1995},
}
@book{Maia_1997,
   author = {Nuno Manuel Mendes Maia and Julio Martins Montalvao Silva},
   city = {Baldock, United Kingdom},
   publisher = {Research Studies Press},
   title = {{Theoretical and Experimental Modal Analysis}},
   year = {1997},
}
@article{Peeters_2004,
   abstract = {<p>Recently, a new non-iterative frequency-domain parameter estimation method was proposed. It is based on a (weighted) least-squares approach and uses multiple-input-multiple-output frequency response functions as primary data. This so-called “PolyMAX” or polyreference least-squares complex frequency-domain method can be implemented in a very similar way as the industry standard polyreference (time-domain) least-squares complex exponential method: in a first step a stabilisation diagram is constructed containing frequency, damping and participation information. Next, the mode shapes are found in a second least-squares step, based on the user selection of stable poles. One of the specific advantages of the technique lies in the very stable identification of the system poles and participation factors as a function of the specified system order, leading to easy-to-interpret stabilisation diagrams. This implies a potential for automating the method and to apply it to “difficult” estimation cases such as high-order and/or highly damped systems with large modal overlap. Some real-life automotive and aerospace case studies are discussed. PolyMAX is compared with classical methods concerning stability, accuracy of the estimated modal parameters and quality of the frequency response function synthesis.</p>},
   author = {Bart Peeters and Herman Van der Auweraer and Patrick Guillaume and Jan Leuridan},
   doi = {10.1155/2004/523692},
   issn = {1070-9622},
   issue = {3-4},
   journal = {Shock and Vibration},
   pages = {395-409},
   publisher = {IOS Press},
   title = {The PolyMAX Frequency-Domain Method: A New Standard for Modal Parameter Estimation?},
   volume = {11},
   year = {2004},
}
@article{Auweraer_2000,
   abstract = {Most modern modal model estimation algorithms start from the observation that parameters such as resonance frequencies, damping ratios and modal participation factors are "global" for the structure under test and a global model is forced on the available time or frequency domain data. In reality, these data are often slightly to strongly inconsistent. First of all, modal test data are usually acquired in "patches". Mass loading effects, temperature variations etc. make that the data from different patches (or the FRF columns with multiple excitation tests) can show slightly differing resonant frequencies. This may result in important estimation errors when trying to fit a global model through these data. This may lead to major problems in postprocessing the data by modal substructuring or modification analysis. The relevance of these problems is briefly reviewed at the hand of some practical case studies and remedies are evaluated. They include selecting distributed sensor locations, analyzing data patch by patch and recombining them in a global model as well as the use of specific parameter estimation methods. Such methods could also be useful as a smoothing pre-processor for FRF based impedance methods.},
   author = {Herman Van Der Auweraer and Willem Leurs and Peter Mas and L Hermans},
   journal = {Proceedings of SPIE - The International Society for Optical Engineering},
   title = {{Modal Parameter Estimation from Inconsistent Data Sets}},
   volume = {4062},
   year = {2000},
}
@book{DeBerg_2008,
   abstract = {This well-accepted introduction to computational geometry is a textbook for high-level undergraduate and low-level graduate courses. The focus is on algorithms and hence the book is well suited for students in computer science and engineering. Motivation is provided from the application areas: all solutions and techniques from computational geometry are related to particular applications in robotics, graphics, CAD/CAM, and geographic information systems. For students this motivation will be especially welcome. Modern insights in computational geometry are used to provide solutions that are both efficient and easy to understand and implement. All the basic techniques and topics from computational geometry, as well as several more advanced topics, are covered. The book is largely self-contained and can be used for self-study by anyone with a basic background in algorithms. In this third edition, besides revisions to the second edition, new sections discussing Voronoi diagrams of line segments, farthest-point Voronoi diagrams, and realistic input models have been added. © 2008, 2000, 1997 Springer-Verlag Berlin Heidelberg.},
   author = {Mark De Berg and Otfried Cheong and Marc Van Kreveld and Mark Overmars},
   doi = {10.1007/978-3-540-77974-2},
   isbn = {9783540779735},
   journal = {Computational Geometry: Algorithms and Applications},
   pages = {1-386},
   publisher = {Springer Berlin Heidelberg},
   title = {{Computational geometry: Algorithms and applications}},
   year = {2008},
}
@article{Su_1995,
   author = {Peter Su and Robert L. Scot Drysdale},
   journal = {Proceedings of the eleventh annual symposium in Computational geometry},
   pages = {61-70},
   title = {A Comparison of Sequential Delaunay Triangulation Algorithms},
   year = {1995},
}
@computer_program{VTK_2006,
   author = {Will Schroeder and Ken Martin and Bill Lorensen},
   title = {{The Visualization Toolkit (4th ed.)}},
   year = {2006},
}
@inproceedings{Lawson_1977,
   abstract = {This report treats the problem of mathematically definin-, a smooth surface, z = f (x,y), passing through a finite set of given points (xigyipzi, k = 1,...,n). In particular, it is not assumed that the given (x.,y ) values lie in any special pattern such as at the nodes of a rectangular grids i The literature relating to this problem is briefly reviewed. An algorithm is described that first constructs a triangular grid in the (x,y) domain, next estimates first partial derivatives at the nodal points, and finally does interpolation in the triangular cells using a method that gives C l continuity overall. Performance of software implementing this algorithm is discussed. New theoretical results are presented that provide valuable guidance in the develop- ment of algorithms for constructing triangular grids.},
   author = {Charles. L. Lawson},
   doi = {10.1016/b978-0-12-587260-7.50011-x},
   journal = {Mathematical Software},
   pages = {161-194},
   publisher = {Academic Press},
   title = {Software for C1 Surface Interpolation},
   year = {1977},
}
@inproceedings{Nega_1993,
   abstract = {We propose an image motion constraint equation based on a model which allows the brightness of a scene point to vary with time, unlike the case in the brightness constancy model. Using this model, we describe a method for the computation of optical flow and investigate its performance in a variety of conditions involving brightness variations of scene points, due to illumination nonuniformity, light source motion, specular reflection, and/or interreflection. We show that in the application of this method, care must be taken in the estimation of image derivatives using finite difference methods to prevent biases in the solution. We suggest a simple modification to overcome them. Comparison with two other models, including the classical brightness constancy, is made through results from experiments with real images.},
   author = {Shahriar Negahdaripour and Chih Ho Yu},
   doi = {10.1109/iccv.1993.378241},
   isbn = {0818638729},
   journal = {1993 IEEE 4th International Conference on Computer Vision},
   pages = {2-11},
   publisher = {Publ by IEEE},
   title = {A generalized brightness change model for computing optical flow},
   year = {1993},
}
@article{Zaletelj_2023,
   abstract = {Model updating improves the correlation between the response of the real structure and the response of the finite-element (FE) model; however, the selection of the updating parameters (parametrization) is crucial for its success. Using full-field modal shapes, a large number of parameters can be updated, e.g., the Young's moduli of all the finite elements; however, the structural response is not necessarily sensitive to an arbitrary parameter, making the optimization problem ill-conditioned. Additionally, the computation of the full sensitivity matrix is not feasible for relatively large FE models. Not all locations are equally important for model updating; at locations of the highest mechanical loads, more focus is required. In this research, the updating parameters are based on the curvature of the 3D full-field experimental shape, where locations with high curvature are associated with high sensitivity. The assumption is initially researched with the Euler-Bernoulli beam elements and second-order tetrahedrons. The proposed method is investigated on numerical and real experiments, where successful updating was confirmed. With the proposed parametrization and updating approach, a geometrically complex structure is parametrized and the parameters updated without significant user input, generalizing the model-updating procedure.},
   author = {Klemen Zaletelj and Domen Gorjup and Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2022.109927},
   issn = {08883270},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {FE model updating,Interior Point Method,curvature-based parametrization,frequency-domain triangulation},
   month = {3},
   pages = {109927},
   title = {Multi-level curvature-based parametrization and model updating using a 3D full-field response},
   volume = {187},
   year = {2023},
}
@article{Glasbey_1998,
   abstract = {Image warping is a transformation which maps all positions in one image plane to positions in a second plane. It arises in many image analysis problems, whether in order to remove optical distortions introduced by a camera or a particular viewing perspective, to register an image with a map or template, or to align two or more images. The choice of warp is a compromise between a smooth distortion and one which achieves a good match. Smoothness can be ensured by assuming a parametric form for the warp or by constraining it using differential equations. Matching can be specified by points to be brought into alignment, by local measures of correlation between images, or by the coincidence of edges. Parametric and non-parametric approaches to warping, and matching criteria, are reviewd.},
   author = {C. A. Glasbey and K. V. Mardia},
   doi = {10.1080/02664769823151},
   issn = {02664763},
   issue = {2},
   journal = {Journal of Applied Statistics},
   pages = {155-171},
   publisher = {Taylor and Francis Ltd.},
   title = {A review of image-warping methods},
   volume = {25},
   year = {1998},
}
@article{Goshtasby_1986,
   abstract = {A new approach to determination of mapping functions for registration of digital images is presented. Given the coordinates of corresponding control points in two images of the same scene, first the images are divided into triangular regions by triangulating the control points. Then a linear mapping function is obtained by registering each pair of corresponding triangular regions in the images. The overall mapping function is then obtained by piecing together the linear mapping functions. Image registration Geometric distortion Mapping function Triangulation Linear interpolation},
   author = {Ardeshir Goshtasby},
   issue = {6},
   journal = {Pattern Recognition},
   pages = {459-466},
   title = {Piecewise Linear Mapping Functions For Image Registration},
   volume = {19},
   year = {1986},
}
@article{Xiong_2010,
   abstract = {Image registration is the process of precisely overlaying two (or more) images of the same area through geometrically aligning common features (or control points) identified in the images. It mainly consists of four steps: feature detection, feature matching, transformation function estimation and image resampling. Image registration is usually applied in photogrammetry, remote sensing, computer vision, pattern recognition and medical image registration. This article presents a review of image registration techniques. We emphasise on feature point detection and matching. The goal of this article is to provide the readers an overview of such techniques, a perspective on the technical advances and a reference to relevant research. © 2010 Taylor & Francis.},
   author = {Zhen Xiong and Yun Zhang},
   doi = {10.1080/19479831003802790},
   issn = {19479824},
   issue = {2},
   journal = {International Journal of Image and Data Fusion},
   keywords = {Feature detection,Feature matching,Image registration,Image resampling,Transformation function},
   pages = {137-158},
   publisher = {Taylor and Francis Ltd.},
   title = {A critical review of image registration methods},
   volume = {1},
   year = {2010},
}
@book{Friswell_1995,
   author = {M. I. Friswell and J. E. Mottershead},
   city = {Dordrecht},
   doi = {10.1007/978-94-015-8508-8},
   isbn = {978-90-481-4535-5},
   publisher = {Springer Netherlands},
   title = {Finite Element Model Updating in Structural Dynamics},
   year = {1995},
}
@article{Allemang_2003,
   author = {R. J. Allemang},
   issue = {8},
   journal = {Sound and Vibration},
   pages = {14-21},
   title = {The modal assurance criterion - Twenty years of use and abuse},
   volume = {37},
   year = {2003},
}
@article{Allemang_1982,
   abstract = {Multiple, independent modal vector estimates may be generated whenever multiple rows or columns of the frequency response function matrix are available. These independent estimates of the same modal vector need to be processed into a single best estimate of that particular modal vector. The development of the concept of consistency of modal vectors, evaluated through the use of the modal assurance and modal scale factor, is useful in computing a best estimate of the modal vector and useful in understanding the errors among separate estimates of the same modal vector.},
   author = {R. J. Allemang and D. L. Brown},
   journal = {Proceedings of the International Modal Analysis Conference and Exhibit},
   pages = {110-116},
   publisher = {Union Coll},
   title = {Correlation Coefficient For Modal Vector Analysis.},
   year = {1982},
}
@book{Kailath_1980,
   author = {Thomas Kailath},
   city = {Englewood Cliffs, N.J.},
   edition = {1.},
   publisher = {Prentice-Hall, Inc.},
   title = {{Linear Systems}},
   year = {1980},
}
@article{Fox_1968,
   author = {R. L. Fox and M. P. Kapoor},
   doi = {10.2514/3.5008},
   issn = {00011452},
   issue = {12},
   journal = {AIAA Journal},
   pages = {2426-2429},
   title = {Rates of change of eigenvalues and eigenvectors},
   volume = {6},
   year = {1968},
}
@article{Nelson_1976,
   abstract = {A simplified procedure is presented for the determination of the derivatives of eigenvectors of nth order algebraic eigensystems. The method is applicable to symmetric or nonsymmetric systems, and requires knowledge of only one eigenvalue and its associated right and left eigenvectors. In the procedure, the matrix of the original eigensystem of rank (n-1) is modified to convert it to a matrix of rank n, which then is solved directly for a vector which, together with the eigenvector, gives the eigenvector derivative to within an arbitrary constant. The norm of the eigenvector is used to determine this constant and complete the calculation. The method is simple, since the modified n rank matrix is formed without matrix multiplication or extensive manipulation. Since the matrix has the same bandedness as the original eigensystems, it can be treated efficiently using the same banded equation solution algorithms that are used to find the eigenvectors. © 1976 American Institute of Aeronautics and Astronautics, Inc., All rights reserved.},
   author = {Richard B. Nelson},
   doi = {10.2514/3.7211},
   issn = {00011452},
   issue = {9},
   journal = {AIAA Journal},
   pages = {1201-1205},
   title = {Simplified calculation of eigenvector derivatives},
   volume = {14},
   year = {1976},
}
@article{OpenCV,
   author = {G. Bradski},
   journal = {Dr. Dobb's Journal of Software Tools},
   title = {{The OpenCV Library}},
   year = {2000},
}
@article{Welch_1967,
   abstract = {The use of the fast Fourier transform in power spectrum analysis is described. Principal advantages of this method are a reduction in the number of computations and in required core storage, and convenient application in nonstationarity tests. The method involves sectioning the record and averaging modified periodograms of the sections. T INTRODLCTION HIS PAPER outlines a method for the application of the fast Fourier transform algorithm to the estimation of power spectra, which involves sectioning the record, taking modified periodograms of these sections, and averaging these modified periodo-grams. In many instances this method involves fewer computations than other methods. Moreover, it involves the transformation of sequences which are shorter than the whole record which is an advantage when computations are to be performed on a machine with limited core storage. Finally, it directly yields a potential resolution in the time dimension which is useful for testing and measuring nonstationarity. As will be pointed out, it is closely related to the method of complex demodulation described by Bingham, Godfrey, and Tukey.l THE METHOD Let X (j) , j = 0, e. . , N-1 be a sample from a stationary , second-order stochastic sequence. Assume for simplicity that E (X) = 0. Let X (j) have spectral density Pcf), I f \ 5%. We take segments, possibly overlapping, of length L with the starting points of these segments D units apart. Let X,(j),j=O,. .. , L-1 be the first such segment. Then X d j) = X($ j = O ;-. , L-l. Similarly, X d j) = X (j + 0) j = o ,. .. , L-L and finally X&) = X (j + (K-1) D) j = 0,. .. , L-1. We suppose we have K such segments; X l (j) ,. .. , X,($, and that they cover the entire record, Le., that (K-1) D f L = N. This segmenting is illustrated in Fig. 1. The method of estimation is as follows. For each segment of length L we calculate a modified periodo-gram. That is, we select a data window W (j) , j = 0,. . ., L-1, and form the sequences Xl(j)W(j),. .. , X,(j) W (j). We then take the finite Fourier transforms A1(n),. .. , A K (~) of these sequences. Here ~ k (n) =-xk(j) w (j) e-z ~ c i j n l L 1 L-1 L j-0 and i = (-1)1'2. Finally, we obtain the K modified periodograms L U},
   author = {P. Welch},
   doi = {10.1109/TAU.1967.1161901},
   issn = {0018-9278},
   issue = {2},
   journal = {IEEE Transactions on Audio and Electroacoustics},
   month = {6},
   pages = {70-73},
   title = {{The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms}},
   volume = {15},
   year = {1967},
}
@article{PyVista_2019,
   author = {C. Sullivan and Alexander Kaszynski},
   doi = {10.21105/joss.01450},
   issn = {2475-9066},
   issue = {37},
   journal = {Journal of Open Source Software},
   month = {5},
   pages = {1450},
   title = {{PyVista: 3D plotting and mesh analysis through a streamlined interface for the Visualization Toolkit (VTK)}},
   volume = {4},
   year = {2019},
}
@article{Li_2022,
   abstract = {As a non-contact and full-field testing method, high-speed camera-based modal analysis has become a feasible and acknowledged approach. However, extracting small displacements from noisy images has experienced high level of difficulty, especially in high frequency range. This paper proposes a novel adaptive spatial filtering (beamforming) algorithm to extract the displacement signals using high-speed camera. In the proposed algorithm, one pixel is considered as a sensor measuring displacement and a set of pixels are therefore taken as the elements of sensor array. Then, an adaptive spatial filtering acting on this sensor array is proposed. The proposed approach mainly includes three steps. Firstly, a set of pixels are selected to compose a sensor array according to signal to distortion and noise (SINAD). Secondly, a node/antinode searching scheme is proposed based on sinusoid-based piecewise functions, which works as an adaptive filter to match mode shape and enhance modal displacement. Finally, the output of spatial filtering is adopted as the system response for the identification of modal parameters. To validate the performance of the proposed method, simulation and experiment studies are conducted based on measuring the vibration model properties of a free-free beam, which includes a comparison with LK optical flow method and conventional accelerometer-based method. The results show that the SNR of estimated displacement and computational efficiency is significantly improved without using additional sensors. The proposed method paves a way for broadening the applications of using high-speed camera for full-field vibration measurements.},
   author = {Miaoshuo Li and Guojin Feng and Rongfeng Deng and Feng Gao and Fengshou Gu and Andrew D. Ball},
   doi = {10.1016/j.ymssp.2021.108422},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Adaptive spatial filtering,Full-field measurement,High-speed camera,Modal analysis,Sinusoid-based piecewise function},
   month = {3},
   publisher = {Academic Press},
   title = {Structural vibration mode identification from high-speed camera footages using an adaptive spatial filtering approach},
   volume = {166},
   year = {2022},
}
@article{Wu_2012,
   abstract = {<p>Our goal is to reveal temporal variations in videos that are difficult or impossible to see with the naked eye and display them in an indicative manner. Our method, which we call Eulerian Video Magnification, takes a standard video sequence as input, and applies spatial decomposition, followed by temporal filtering to the frames. The resulting signal is then amplified to reveal hidden information. Using our method, we are able to visualize the flow of blood as it fills the face and also to amplify and reveal small motions. Our technique can run in real time to show phenomena occurring at the temporal frequencies selected by the user.</p>},
   author = {Hao-Yu Wu and Michael Rubinstein and Eugene Shih and John Guttag and Frédo Durand and William T. Freeman},
   doi = {10.1145/2185520.2185561},
   issn = {0730-0301},
   issue = {4},
   journal = {ACM Transactions on Graphics},
   keywords = {CR Categories: I47 [Image Processing and Computer Vision]: Scene Analysis-Time-varying Imagery; Keywords: video-based rendering,Eu-lerian motion,motion magnification Links: DL PDF WEB,spatio-temporal analysis},
   month = {8},
   pages = {1-8},
   title = {{Eulerian video magnification for revealing subtle changes in the world}},
   volume = {31},
   year = {2012},
}
@article{Chen_2015,
   abstract = {Video cameras offer the unique capability of collecting high density spatial data from a distant scene of interest. They can be employed as remote monitoring or inspection sensors for structures because of their commonplace availability, simplicity, and potentially low cost. An issue is that video data is difficult to interpret into a format familiar to engineers such as displacement. A methodology called motion magnification has been developed for visualizing exaggerated versions of small displacements with an extension of the methodology to obtain the optical flow to measure displacements. In this paper, these methods are extended to modal identification in structures and the measurement of structural vibrations. Camera-based measurements of displacement are compared against laser vibrometer and accelerometer measurements for verification. The methodology is demonstrated on simple structures, a cantilever beam and a pipe, to identify and visualize the operational deflection shapes. Suggestions for applications of this methodology and challenges in real-world implementation are given.},
   author = {Justin G. Chen and Neal Wadhwa and Young Jin Cha and Frédo Durand and William T. Freeman and Oral Buyukozturk},
   doi = {10.1016/j.jsv.2015.01.024},
   issn = {10958568},
   journal = {Journal of Sound and Vibration},
   month = {6},
   pages = {58-71},
   publisher = {Academic Press},
   title = {{Modal identification of simple structures with high-speed video using motion magnification}},
   volume = {345},
   year = {2015},
}
@article{Wang_2009,
   abstract = {Currently the most widely used method for comparing mode shapes from finite elements and experimental measurements is the modal assurance criterion (MAC), which can be interpreted as the cosine of the angle between the numerical and measured eigenvectors. However, the eigenvectors only contain the displacement of discrete coordinates, so that the MAC index carries no explicit information on shape features. New techniques, based upon the well-developed philosophies of image processing (IP) and pattern recognition (PR) are considered in this paper. The Zernike moment descriptor (ZMD), Fourier descriptor (FD), and wavelet descriptor (WD) are the most popular shape descriptors due to their outstanding properties in IP and PR. These include (1) for the ZMD-rotational invariance, expression and computing efficiency, ease of reconstruction and robustness to noise; (2) for the FD-separation of the global shape and shape-details by low and high frequency components, respectively, invariance under geometric transformation; (3) for the WD-multi-scale representation and local feature detection. Once a shape descriptor has been adopted, the comparison of mode shapes is transformed to a comparison of multidimensional shape feature vectors. Deterministic and statistical methods are presented. The deterministic problem of measuring the degree of similarity between two mode shapes (possibly one from a vibration test and the other from a finite element model) may be carried out using Pearson's correlation. Similar shape feature vectors may be arranged in clusters separated by Euclidian distances in the feature space. In the statistical analysis we are typically concerned with the classification of a test mode shape according to clusters of shape feature vectors obtained from a randomised finite element model. The dimension of the statistical problem may often be reduced by principal component analysis. Then, in addition to the Euclidian distance, the Mahalanobis distance, defining the separation of the test point from the cluster in terms of its standard deviation, becomes an important measure. Bayesian decision theory may be applied to formally minimise the risk of misclassification of the test shape feature vector. In this paper the ZMD is applied to the problem of mode shape recognition for a circular plate. Results show that the ZMD has considerable advantages over the traditional MAC index when identifying the cyclically symmetric mode shapes that occur in axisymmetric structures at identical frequencies. Mode shape recognition of rectangular plates is carried out by the FD. Also, the WD is applied to the problem of recognising the mode shapes in the thin and thick regions of a plate with different thicknesses. It shows the benefit of using the WD to identify mode-shapes having both local and global components. The comparison and classification of mode shapes using IP and PR provides a 'toolkit' to complement the conventional MAC approach. The selection of a particular shape descriptor and classification method will depend upon the problem in hand and the experience of the analyst. © 2009 Elsevier Ltd. All rights reserved.},
   author = {Weizhuo Wang and John E. Mottershead and Cristinel Mares},
   doi = {10.1016/j.jsv.2009.05.024},
   issn = {0022460X},
   issue = {3-5},
   journal = {Journal of Sound and Vibration},
   month = {10},
   pages = {909-938},
   title = {Vibration mode shape recognition using image processing},
   volume = {326},
   year = {2009},
}
@article{Ryall_2002,
   abstract = {It is shown that it is possible to recover the three-dimensional modes of vibration of an oscillating structure through an offline digital photogrammetric approach employing only a single video camera. In addition to the camera, the technique requires a high powered synchronized strobe unit and the careful control of fixed sequential delays between the excitation force, the strobe illumination, and the multiple sequence of camera exposures. The dynamic three-dimensional object point triangulation problem is then reduced to a set of static problems by capturing object shape in a number of different phases at a given number of measurement epochs. For each repeatable oscillation cycle, the vibrating object is imaged from a different camera position. The XYZ object coordinates of the target array at each sampling epoch can, thus, be determined by photogrammetric triangulation using all images corresponding to the same instant of time within the oscillation cycle. The dynamic mode shape is then determined from the triangulated object points at the various phases. The process is illustrated for the determination of modes of vibration for an aircraft wing section. Note that the advantages of using only a single camera are multifold; the system is cheaper, the system is simpler and, thus, more robust in that multiple cameras do not have to be synchronized, and finally the system has the potential to deliver greater accuracy without having an excessively large number of cameras. © 2002 Journal of Aircraft.},
   author = {T. G. Ryall and C. S. Fraser},
   doi = {10.2514/2.2903},
   issn = {00218669},
   issue = {1},
   journal = {Journal of Aircraft},
   month = {12},
   pages = {114-119},
   title = {{Determination of structural modes of vibration using digital photogrammetry}},
   volume = {39},
   year = {2002},
}
@article{Chu_1985,
   author = {T. C. Chu and W. F. Ranson and M. A. Sutton},
   doi = {10.1007/BF02325092},
   issn = {17412765},
   issue = {3},
   journal = {Experimental Mechanics},
   pages = {232-244},
   publisher = {Kluwer Academic Publishers},
   title = {Applications of digital-image-correlation techniques to experimental mechanics},
   volume = {25},
   year = {1985},
}
@article{Baqersad_2017,
   abstract = {In the last few decades, there has been a surge of research in the area of non-contact measurement techniques. Photogrammetry has received considerable attention due to its ability to achieve full-field measurement and its robustness to work in testing environments and on testing articles in which using other measurement techniques may not be practical. More recently, researchers have used this technique to study transient phenomena and to perform measurements on vibrating structures. The current paper reviews the most current trends in the photogrammetry technique (point tracking, digital image correlation, and target-less approaches) and compares the applications of photogrammetry to other measurement techniques used in structural dynamics (e.g. laser Doppler vibrometry and interferometry techniques). The paper does not present the theoretical background of the optical techniques, but instead presents the general principles of each approach and highlights the novel structural dynamic measurement concepts and applications that are enhanced by utilizing optical techniques.},
   author = {Javad Baqersad and Peyman Poozesh and Christopher Niezrecki and Peter Avitabile},
   doi = {10.1016/j.ymssp.2016.02.011},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Digital image correlation,Non-contacting,Point tracking,Structural dynamics,Vibrations,Videogrammetry},
   month = {3},
   pages = {17-34},
   publisher = {Academic Press},
   title = {{Photogrammetry and optical methods in structural dynamics – A review}},
   volume = {86},
   year = {2017},
}
@inproceedings{Sarrafi_2017,
   abstract = {As a specific modern non-contact sensing technology, optical/video information is getting more and more attention employed to interpret structural responses and system status awareness. By means of processing the acquired video, a full-field system information is available which may be applied later to Experimental Modal Analysis (EMA), Structural Health Monitoring (SHM), System Identification (SI), etc., while at the same time, there is no influence to the structural testing such as mass loading and stiffness change. There are numerous technologies to extract the dynamic response of structures from acquired videos. In this paper, several point tracking algorithms are particularly compared, including Lucas-Kanade tracker, Hungarian registration algorithm and particle filter. These computer vision algorithms are implemented to extract the natural frequencies of a lab-scale structure, and the efficiency of each method is investigated regarding the consistency in estimating the natural frequencies and computational time. The recorded video contains external noise caused by lighting change during the experiment, as well as the intrinsic uncertainty on the photosensitive devices. Therefore, the natural frequencies estimated via different algorithms will have different values. An overall comparison between several computer vision algorithms are made in this paper in terms of precision, and computational load.},
   author = {Aral Sarrafi and Peyman Poozesh and Zhu Mao},
   doi = {10.1007/978-3-319-54858-6_29},
   isbn = {9783319548579},
   issn = {21915652},
   journal = {Conference Proceedings of the Society for Experimental Mechanics Series},
   pages = {295-301},
   publisher = {Springer New York LLC},
   title = {{A comparison of computer-vision-based structural dynamics characterizations}},
   volume = {3 Part F2},
   year = {2017},
}
@article{Oslazek_1999,
   abstract = {A new method for the investigation of the dynamic characteristic of bridges has been developed. It is based on the photogrammetric principle; however, the viewing system is equipped with an additional reference system, which decreases the sensitivity to vibrations and an analysis system which enables image analysis. The method is used for monitoring and real-time measurement of the displacement of chosen points at bridge structures. It has applications particularly in the case of the measurement of hard-to-access places on bridges. The instrumentation, methodology and engineering examples of its application are presented.},
   author = {Piotr Olaszek},
   doi = {10.1016/S0263-2241(99)00006-8},
   issn = {02632241},
   issue = {3},
   journal = {Measurement},
   keywords = {Bridge testing,Image analysis,Photogrammetry},
   month = {4},
   pages = {227-236},
   title = {{Investigation of the dynamic characteristic of bridge structures using a computer vision method}},
   volume = {25},
   year = {1999},
}
@article{Warren_2011,
   abstract = {Today, accelerometers and laser Doppler vibrometers are widely accepted as valid measurement tools for structural dynamic measurements. However, limitations of these transducers prevent the accurate measurement of some phenomena. For example, accelerometers typically measure motion at a limited number of discrete points and can mass load a structure. Scanning laser vibrometers have a very wide frequency range and can measure many points without mass-loading, but are sensitive to large displacements and can have lengthy acquisition times due to sequential measurements. Image-based stereo-photogrammetry techniques provide additional measurement capabilities that compliment the current array of measurement systems by providing an alternative that favors high-displacement and low-frequency vibrations typically difficult to measure with accelerometers and laser vibrometers. Within this paper, digital image correlation, three-dimensional (3D) point-tracking, 3D laser vibrometry, and accelerometer measurements are all used to measure the dynamics of a structure to compare each of the techniques. Each approach has its benefits and drawbacks, so comparative measurements are made using these approaches to show some of the strengths and weaknesses of each technique. Additionally, the displacements determined using 3D point-tracking are used to calculate frequency response functions, from which mode shapes are extracted. The image-based frequency response functions (FRFs) are compared to those obtained by collocated accelerometers. Extracted mode shapes are then compared to those of a previously validated finite element model (FEM) of the test structure and are shown to have excellent agreement between the FEM and the conventional measurement approaches when compared using the Modal Assurance Criterion (MAC) and Pseudo-Orthogonality Check (POC). © 2010 Elsevier Ltd. All rights reserved.},
   author = {Christopher Warren and Christopher Niezrecki and Peter Avitabile and Pawan Pingle},
   doi = {10.1016/j.ymssp.2011.01.018},
   issn = {08883270},
   issue = {6},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Digital image correlation,Full-field measurement,Modal testing,Mode shape correlation,Point tracking,Vibration measurement},
   month = {8},
   pages = {2191-2202},
   title = {{Comparison of FRF measurements and mode shapes determined using optically image based, laser, and accelerometer measurements}},
   volume = {25},
   year = {2011},
}
@article{Beberniss2017,
   abstract = {A review of the extensive studies on the feasibility and practicality of utilizing high-speed 3 dimensional digital image correlation (3D-DIC) for various random vibration measurement applications is presented. Demonstrated capabilities include finite element model updating utilizing full-field 3D-DIC static displacements, modal survey natural frequencies, damping, and mode shape results from 3D-DIC are baselined against laser Doppler vibrometry (LDV), a comparison between foil strain gage and 3D-DIC strain, and finally the unique application to a high-speed wind tunnel fluid–structure interaction study. Results show good agreement between 3D-DIC and more traditional vibration measurement techniques. Unfortunately, 3D-DIC vibration measurement is not without its limitations, which are also identified and explored in this study. The out-of-plane sensitivity required for vibration measurement for 3D-DIC is orders of magnitude less than LDV making higher frequency displacements difficult to sense. Furthermore, the digital cameras used to capture the DIC images have no filter to eliminate temporal aliasing of the digitized signal. Ultimately DIC is demonstrated as a valid alternative means to measure structural vibrations while one unique application achieves success where more traditional methods would fail.},
   author = {Timothy J. Beberniss and David A. Ehrhardt},
   doi = {10.1016/j.ymssp.2016.04.014},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Digital image correlation,Laser vibrometry,Modal analysis,Random vibration},
   month = {3},
   pages = {35-48},
   publisher = {Academic Press},
   title = {{High-speed 3D digital image correlation vibration measurement: Recent advancements and noted limitations}},
   volume = {86},
   year = {2017},
}
@article{Sarrafi_2018,
   abstract = {Vibration-based Structural Health Monitoring (SHM) techniques are among the most common approaches for structural damage identification. The presence of damage in structures may be identified by monitoring the changes in dynamic behavior subject to external loading, and is typically performed by using experimental modal analysis (EMA) or operational modal analysis (OMA). These tools for SHM normally require a limited number of physically attached transducers (e.g. accelerometers) in order to record the response of the structure for further analysis. Signal conditioners, wires, wireless receivers and a data acquisition system (DAQ) are also typical components of traditional sensing systems used in vibration-based SHM. However, instrumentation of lightweight structures with contact sensors such as accelerometers may induce mass-loading effects, and for large-scale structures, the instrumentation is labor intensive and time consuming. Achieving high spatial measurement resolution for a large-scale structure is not always feasible while working with traditional contact sensors, and there is also the potential for a lack of reliability associated with fixed contact sensors in outliving the life-span of the host structure. Among the state-of-the-art non-contact measurements, digital video cameras are able to rapidly collect high-density spatial information from structures remotely. In this paper, the subtle motions from recorded video (i.e. a sequence of images) are extracted by means of Phase-based Motion Estimation (PME) and the extracted information is used to conduct damage identification on a 2.3-m long Skystream® wind turbine blade (WTB). The PME and phased-based motion magnification approach estimates the structural motion from the captured sequence of images for both a baseline and damaged test cases on a wind turbine blade. Operational deflection shapes of the test articles are also quantified and compared for the baseline and damaged states. In addition, having proper lighting while working with high-speed cameras can be an issue, therefore image enhancement and contrast manipulation has also been performed to enhance the raw images. Ultimately, the extracted resonant frequencies and operational deflection shapes are used to detect the presence of damage, demonstrating the feasibility of implementing non-contact video measurements to perform realistic structural damage detection.},
   author = {Aral Sarrafi and Zhu Mao and Christopher Niezrecki and Peyman Poozesh},
   doi = {10.1016/j.jsv.2018.01.050},
   issn = {10958568},
   journal = {Journal of Sound and Vibration},
   keywords = {Computer vision,Damage detection,Modal analysis,Phase-based Motion Estimation,Structural health monitoring,Video magnification,Wind turbine blade},
   pages = {300-318},
   publisher = {Academic Press},
   title = {Vibration-based damage detection in wind turbine blades using Phase-based Motion Estimation and motion magnification},
   volume = {421},
   year = {2018},
}
@article{Liu_2022,
   abstract = {The non-contact sensing techniques using image/video processing have flourished in recent years benefited from the rapid development of digital cameras. However, high-fidelity motion extraction from acquired image frames is still challenging. A novel motion estimation method based on phase-domain image processing, named Hilbert phase-based motion estimation, is proposed in this study to identify motions in a more accurate and efficient manner if compared to traditional phase-based motion estimation. The theoretical relationship between phase variation and physical motion is established based on the Hilbert transform; and then in order to reduce the computation cost, the forward and inverse fast Fourier transforms are integrated with the Hilbert transform. Under the proposed framework, phase variations are therefore obtained from the corresponding analytical signal. Furthermore, peak-picking procedure and the Butterworth ideal band-pass filter are employed to decompose the original video to its mono-component signal prior to identifying displacements. The proposed method is verified using a synthetic video containing a bell-shaped surface with randomly assigned motions. The proposed Hilbert phase-based motion estimation approach avoids the influence from manual parameter selection, and the correlation coefficient of the identification results can reach 99.55%. Experimental verification using a simply supported beam is also deployed, and comparison with the state of the art demonstrates the outperformance of the proposed algorithm.},
   author = {G. Liu and M. Z. Li and Z. Mao and Q. S. Yang},
   doi = {10.1016/j.ymssp.2021.108418},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Butterworth ideal band-pass filter,Hilbert transform,Motion extraction,Non-contact sensing,Phase variations,Phase-domain image process},
   pages = {108418},
   publisher = {Academic Press},
   title = {{Structural motion estimation via Hilbert transform enhanced phase-based video processing}},
   volume = {166},
   year = {2022},
}
@article{Wadhwa_2013,
   abstract = {We introduce a technique to manipulate small movements in videos based on an analysis of motion in complex-valued image pyramids. Phase variations of the coefficients of a complex-valued steerable pyramid over time correspond to motion, and can be temporally processed and amplified to reveal imperceptible motions, or attenuated to remove distracting changes. This processing does not involve the computation of optical flow, and in comparison to the previous Eulerian Video Magnification method it supports larger amplification factors and is significantly less sensitive to noise. These improved capabilities broaden the set of applications for motion processing in videos. We demonstrate the advantages of this approach on synthetic and natural video sequences, and explore applications in scientific analysis, visualization and video enhancement. Copyright © ACM 2013.},
   author = {Neal Wadhwa and Michael Rubinstein and Frédo Durand and William T. Freeman},
   doi = {10.1145/2461912.2461966},
   issn = {07300301},
   issue = {4},
   journal = {ACM Transactions on Graphics},
   keywords = {Eulerian motion,Spatio-temporal analysis,Video magnification,Video-based rendering},
   pages = {1-10},
   title = {{Phase-based video motion processing}},
   volume = {32},
   year = {2013},
}
@article{Reu_2017,
   abstract = {We compare laser Doppler vibrometry (LDV) and digital image correlation (DIC) for use in full-field vibration and modal testing. This was done using a simultaneously measured 3D displacement field on a flat 7-in. corner-supported metal plate using pseudorandom excitation via a shaker. We complete a detailed comparison between the techniques and discuss the pros and cons of each. The results show that either technique can be used for quantifying the modal information with the LDV providing better out-of-plane displacement resolution and equivalent in-plane resolution. The strain calculation is considered better in the DIC approach due to the direct tie to the surface displacements. While the LDV does not lose its place as the gold standard for modal testing, DIC has introduced a new and competitive approach that will have significant advantages in certain testing regimes.},
   author = {Phillip L. Reu and Daniel P. Rohe and Laura D. Jacobs},
   doi = {10.1016/j.ymssp.2016.02.006},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {DIC,Digital image correlation,LDV,Laser Doppler vibrometry,Modal,Vibration},
   month = {3},
   pages = {2-16},
   publisher = {Academic Press},
   title = {{Comparison of DIC and LDV for practical vibration and modal measurements}},
   volume = {86},
   year = {2017},
}
@article{Poozesh_2017,
   abstract = {Optically-based vibration measurements can be used to determine the full-field dynamic response of structures without the need of mounted transducers (e.g. accelerometers, strain gages, and LVDTs) that can add cost, have wiring, power signal transmission issues, and may affect the dynamic characteristics by adding mass or stiffness. The three-dimensional digital image correlation (3D DIC) and three-dimensional point tracking (3DPT) methods based on a stereo-vision system can provide the full-field dynamic displacements of a structure with sub-pixel accuracy. However, stereo-photogrammetry systems are limited by camera resolution and intrinsic noise of the acquired images. Moreover, exciting a structure with only a small amount of energy may result in a subtle mechanical response that is not perceptible by observing the raw data of the conventional optical measurement systems (i.e. 3D DIC and 3DPT). Thus, in order to use the optical-sensing techniques to identify dynamic characteristics of a structure at high frequencies, the signal-to-noise ratio (SNR) in the sequence of images captured with a stereo-vision system needs to be improved. Within this paper, phase-based video magnification in conjunction with the stereo-photogrammetry techniques are used to measure the higher-frequency operating shapes of a cantilever beam and a 2.3-m long Skystream 4.7 wind turbine blade. The phase-based motion estimation method uses complex steerable pyramids to decompose the original sequence of images to amplitude and phase at different spatial resolutions (subsampled images). Motion information is conserved within the phase values which can be filtered in the time domain and amplified to detect the subtle motions. The magnified sequence of images using the motion magnification technique are post-processed using 3D DIC or 3DPT to quantify infinitesimal deformations that are not recognizable using only the traditional stereo-photogrammetry methods. The results obtained within this paper reveal the great potential of motion magnification in conjunction with stereo-photogrammetry techniques in detecting small motions of structures and extracting 3D operating shapes from the optically measured data with low SNR. Compared to traditional stereo-photogrammetry, additional modes of the test structures are obtainable by means of combining the phase based motion magnification and conventional image-sensing techniques (i.e. 3D DIC and 3DPT). The proposed methodology could be used to enhance the established procedure to extract more information about the dynamic characteristics of structures (only once effectively calibrated), compared to existing image-sensing techniques and contact measurement sensors.},
   author = {Peyman Poozesh and Aral Sarrafi and Zhu Mao and Peter Avitabile and Christopher Niezrecki},
   doi = {10.1016/j.jsv.2017.06.003},
   issn = {10958568},
   journal = {Journal of Sound and Vibration},
   keywords = {3D point tracking,Digital image correlation,Modal analysis,Motion magnification technique,Phase-based motion estimation,Video magnification},
   month = {10},
   pages = {350-366},
   publisher = {Academic Press},
   title = {{Feasibility of extracting operating shapes using phase-based motion magnification technique and stereo-photogrammetry}},
   volume = {407},
   year = {2017},
}
@article{Valente_2022,
   abstract = {Phase-based motion magnification (PMM) has been widely implemented in the field of vibration and structural health monitoring for its non-invasive nature to reveal hidden system dynamics. The approach has shown success in magnifying subtle structural oscillatory motions for system identification and observation of operating shapes. Although this method has been implemented and is becoming increasingly popular, the amount of physical motion associated with the degree of magnification has yet to be quantified. Within this work, a synthetic simulation containing an oscillating geometry is presented to quantify its magnified pixel displacement. Computer vision techniques including centroid detection and edge-feature tracking via optical flow are adopted to quantify the relation between amplification and true motion. The quantification techniques are also tested and verified on an experimental structure with the use of a high-speed optical sensing system. Motion artifacts distort the integrity of the magnified motion, which can pose problems for accurate quantification. Image enhancement techniques such as the two-dimensional Wiener filter and Total Variation Denoising (TVD) are used to smooth the high-frequency content that is observed following magnification. Associative error concerning a discrete shift of the Gabor wavelet is analytically derived to show the justification of spatial aliasing. An adjusted bound on magnification is presented to display the limitations of the technique, while providing insight into associated error. The results of this work will help to enhance PMM from a qualitative evaluation tool to a quantitative measurement tool of magnified displacements.},
   author = {Nicholas A. Valente and Celso T. do Cabo and Zhu Mao and Christopher Niezrecki},
   doi = {10.1016/j.measurement.2021.110508},
   issn = {02632241},
   journal = {Measurement},
   keywords = {Computer vision,Image processing,Motion extraction,Noncontact sensing,Optical flow,Phase-based motion magnification},
   pages = {110508},
   publisher = {Elsevier B.V.},
   title = {{Quantification of phase-based magnified motion using image enhancement and optical flow techniques}},
   volume = {189},
   year = {2022},
}
@article{Sony_2019,
   abstract = {Advent of computationally efficient smartphones, inexpensive high-resolution cameras, drones, and robotic sensors has brought a new era of next-generation intelligent monitoring systems for civil infrastructure. Vibration-based condition assessment has garnered as a prominent method of evaluating the health of large-scale infrastructure. The use of contact-based sensors for acquiring vibration data becomes uneconomical and tedious due to their instrumentation cost, centralized nature, and densification required to collect sufficient data for system identification of modern complex structures. A need to advance and develop alternative methods for efficient sensing system results in next-generation measurement technology of structural health monitoring. The abundance of handheld smartphones with easily programmable framework has helped in modifying relevant software to acquire vibration data using embedded sensors in the smartphone. The inexpensive cameras have been used to capture images and videos that are utilized to understand the structural behavior with the aid of advanced signal processing techniques. The inaccessible components of structures require noncontact sensors such as unmanned aerial vehicles (UAVs) or so-called drones and mobile sensors to acquire structural data. To the authors' knowledge, this paper first time presents a comprehensive review of a suite of next-generation smart sensing technology that has been developed in recent years within the context of structural health monitoring. The state-of-the-art methods have been presented by conducting a detailed literature review of the recent applications of smartphones, UAVs, cameras, and robotic sensors used in acquiring and analyzing the vibration data for structural condition monitoring and maintenance.},
   author = {Sandeep Sony and Shea Laventure and Ayan Sadhu},
   doi = {10.1002/stc.2321},
   issn = {15452263},
   issue = {3},
   journal = {Structural Control and Health Monitoring},
   keywords = {SHM,UAV,camera,mobile sensors,smartphone,structural condition assessment},
   month = {3},
   publisher = {John Wiley and Sons Ltd},
   title = {A literature review of next-generation smart sensing technology in structural health monitoring},
   volume = {26},
   year = {2019},
}
@article{Wang_2022,
   abstract = {Experimental Modal Analysis (EMA) allows to assess the dynamical properties of a mechanical component or structure by estimating the modal parameters. Whereas EMA is usually based on local accelerometers or laser vibrometer data, in this paper we focus on camera-based EMA as cameras offer full field and contact-less data. However, besides few very specific controlled cases, camera-based EMA is limited by the low frame rate of the camera in comparison to accelerometers and vibrometers. In this paper we propose a novel acquisition scheme that allows to estimate modal parameters above the Nyquist–Shannon limit (i.e., half of the camera frame rate) by employing a random sampling scheme in time in combination with one accelerometer. With this information we reconstruct the Impulse Response Function (IRF) modal model through a nonlinear optimization problem, where the accelerometer ensures a global solution by providing an initial guess of the eigenfrequencies. We investigate numerically the accuracy of the methodology by simulating multiple damped sine waves. Furthermore, we present an experimental validation on a clamped–clamped beam excited by an impact hammer. Thereby, the displacement information is captured by a single camera triggered by random pulses, and computed by Lucas–Kanade (LK) optical flow. The complexity and modal assurance criterion (MAC) of the modes show that all modes whose amplitudes are higher than the noise level are measured successfully with only one excitation hit, where the highest mode, at 218Hz, is measured with a random sampling scheme comparable to 50fps (to reach 218Hz, a regular sampling with 436fps would be required).},
   author = {Yonggang Wang and Felix Simeon Egner and Thijs Willems and Matteo Kirchner and Wim Desmet},
   doi = {10.1016/j.ymssp.2022.108879},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Camera measurements,Experimental modal analysis,Nonlinear optimization,Optical flow,Random sampling},
   pages = {108879},
   publisher = {Academic Press},
   title = {{Camera-based experimental modal analysis with impact excitation: Reaching high frequencies thanks to one accelerometer and random sampling in time}},
   volume = {170},
   year = {2022},
}
@article{Bregar_2021,
   abstract = {The use of a high-speed camera for dynamic measurements is becoming a compelling alternative to accelerometers and laser vibrometers. However, the estimated displacements from a high-speed camera generally exhibit relatively high levels of noise. This noise has proven to be problematic in the high-frequency range, where the amplitudes of the displacements are typically very small. Nevertheless, the mode shapes of the structure can be identified even in the frequency range where the noise is dominant, by using eigenvalues from a Least-Squares Complex Frequency identification on accelerometer measurements. The identified mode shapes from the Least-Squares Frequency-Domain method can then be used to estimate the full-field FRFs. However, the reconstruction of the FRFs from the identified modeshapes is not consistent in the high-frequency range. In this paper a novel methodology is proposed for an improved experimental estimation of full-field FRFs using a dynamic substructuring approach. The recently introduced System Equivalent Model Mixing is used to form a hybrid model from two different experimental models of the same system. The first model is the reconstructed full-field FRFs that contribute the full-field DoF set and the second model is the accelerometer measurements that provide accurate dynamic characteristics. Therefore, no numerical or analytical model is required for the expansion. The experimental case study demonstrates the increased accuracy of the estimated FRFs of the hybrid model, especially in the high-frequency range, when compared to existing methods.},
   author = {Tomaž Bregar and Klemen Zaletelj and Gregor Čepon and Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2020.107263},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Frequency-based substructuring,Full-field FRFs,High-speed camera,Hybrid model,System equivalent model mixing},
   pages = {107263},
   publisher = {Academic Press},
   title = {{Full-field FRF estimation from noisy high-speed-camera data using a dynamic substructuring approach}},
   volume = {150},
   year = {2021},
}
@article{Trebuna_2014,
   abstract = {In this paper a modification of a high-speed correlation system for the purposes of mechanical structures modal parameters estimation is described. Together with hardware modification an original version of a program Modan 3D was created, which is a complex tool for execution of an experimental and operational modal analysis. In the contribution the authors present just some information about a part of the program used for the experimental modal analysis. They describe algorithm required for a calculation of a normal mode indicator function (NMIF), a complex mode indicator function (CMIF), damping ratios as well and visualization of the mode shapes. A functionality of the program was tested during the analysis of two thin steel samples. A reliability of the reached results was verified by means of a system specialized for vibration analysis. © 2014 Elsevier Ltd. All rights reserved.},
   author = {F. Trebuňa and M. Hagara},
   doi = {10.1016/j.measurement.2013.12.038},
   issn = {02632241},
   issue = {1},
   journal = {Measurement: Journal of the International Measurement Confederation},
   keywords = {Digital image correlation,Experimental modal analysis,Modan 3D},
   pages = {78-85},
   publisher = {Elsevier B.V.},
   title = {Experimental modal analysis performed by high-speed digital image correlation system},
   volume = {50},
   year = {2014},
}
@article{Gardonio_2023,
   abstract = {This paper presents the background theory and the experimental implementation of a new approach for the reconstruction of the sound radiation field produced by the flexural vibration of a distributed structure using video image acquisitions. The study is focused on tonal flexural vibration and sound radiation at the first five resonance frequencies of a baffled flat rectangular plate model-structure. The plate is divided into a regular mesh of rectangular elements whose centres are marked with small bullets. The transverse vibrations at the grid of target points are estimated via triangulation from the images acquired with six cameras unevenly spread along half of a circle located, with a small offset, parallel to the surface of the plate. The sound radiation field in free space is then reconstructed from the Rayleigh integral, which is approximated into a finite sum over the mesh of elements. Both the flexural vibration field and the sound radiation field derived from the cameras video acquisitions are contrasted with measurements taken respectively with a laser vibrometer and an array of microphones.},
   author = {P. Gardonio and G. Guernieri and E. Turco and L. Dal Bo and R. Rinaldo and A. Fusiello},
   doi = {10.1016/j.ymssp.2023.110289},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Multi-camera,Multi-view,Photogrammetry,Sound radiation measurement,Vibration measurement},
   pages = {110289},
   publisher = {Academic Press},
   title = {{Reconstruction of the sound radiation field from flexural vibration measurements with multiple cameras}},
   volume = {195},
   year = {2023},
}
@article{Jiang_2023,
   abstract = {Timely and effective inspection ensures safe operation and optimum resource use for infrastructure maintenance and renewal. Robot advances allow rapid collection of inspection image data. However, distinguishing bridge elements from large amounts of image data is challenging. Rivets are critical elements, joining different profiles into components. However, automatic rivet identification has received little attention. This study proposes a rivet identification method based on computer vision and deep learning. A sustainable training framework is presented to build a robust detector. A novel rivet dataset was collected and annotated from a full-size bridge. YOLOv5 is used to extract features and predicate classifications. The model achieved an 88.9% precision, 90.5% recall, and 90.1% F1 score. The accuracy and robustness were evaluated on another riveted bridge under various operational conditions. The rivet detector generally performs well, achieving 85% or even 95% accuracy in most situations. Out-of-focus and object occlusion have the largest negative effect.},
   author = {Tengjiao Jiang and Gunnstein Thomas Frøseth and Anders Rønnquist},
   doi = {10.1016/j.engstruct.2023.115809},
   issn = {18737323},
   journal = {Engineering Structures},
   keywords = {Bridge inspection,Computer vision,Convolutional neural network,Deep learning,Rivet identification},
   month = {5},
   publisher = {Elsevier Ltd},
   title = {A robust bridge rivet identification method using deep learning and computer vision},
   volume = {283},
   year = {2023},
}
@article{Cosco_2022,
   abstract = {This work discusses the possibility of using phase-based motion magnification as a non-destructive inspection tool for defect detection and identification in vibrating panels. Phase-based motion magnification has recently emerged as a potentially disruptive technology in the field of optical methods for vibration engineering. In fact, the method allows to post-process high-speed video recordings in order to magnify small motions happening in a prescribed bandwidth. In particular, our strategy relies on measuring the full-field low-frequency eigen-shapes, and extracting their aberration as resulting from small defects. Effects of defects are usually very localized in space but may appear even at lower frequencies, making the approach particularly suitable for any kind of high-resolution full-field optical technique. Within this work, a novel phase-based processing pipeline for defect detection is described, and a set of preliminary tests is discussed to assess the feasibility and advantages of the methodology. All validations were carried out by means of numerical simulations relying upon a photo-realistic dynamic finite element model of a rectangular plate.},
   author = {F. Cosco and J. Cuenca and W. Desmet and K. Janssens and D. Mundo},
   doi = {10.1016/j.jsv.2022.117196},
   issn = {10958568},
   journal = {Journal of Sound and Vibration},
   keywords = {Damage detection,Full-field measurements,Motion magnification,Non-contact measurements,Video processing},
   pages = {117196},
   publisher = {Academic Press},
   title = {{Towards phase-based defect detection: A feasibility study in vibrating panels}},
   volume = {537},
   year = {2022},
}
@article{Valente_2022_2,
   abstract = {Non-contact optical measurements are commonly used in industrial and research domains to obtain displacement measurements. This can be attributed to their noninvasive advantages over traditional instrumentation approaches. Phase-based motion estimation (PME) and magnification (PMM) are targetless methods that have been utilized recently to extract qualitative data from structures via experimental modal analysis (EMA) and operational modal analysis (OMA). Transforming the motion-magnified sequence of images into quantified operating deflection shape (ODS) vectors is currently being conducted via edge detection. Although effective, these methods require human supervision and interference; such that, accurate characteristics of the structure are guaranteed. Within this study, a new hybrid computer vision approach is introduced to extract the quantified ODS vectors from motion-magnified images with minimal human supervision. The particle filter (PF) point tracking method is utilized to track the desired feature points in the motion-magnified sequence of images. Moreover, the k-means clustering method is employed as an unsupervised learning approach to perform the segmentation of the particles and assign them to specific feature points in the motion-magnified sequence of images. Total variation denoising is used to smooth the motion-magnified artifacts, which improves ODS vector extraction and provides a robust outlier removal. The results show that the cluster centers can be applied to estimate the ODS vectors, and the performance of the proposed methodology is evaluated experimentally on a lab-scale cantilever beam.},
   author = {Nicholas A. Valente and Aral Sarrafi and Zhu Mao and Christopher Niezrecki},
   doi = {10.1016/j.ymssp.2022.109233},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Computer vision,Data clustering,Particle filter,Phase-based video processing,Structural dynamics identification,Total variation denoising,Unsupervised learning},
   publisher = {Academic Press},
   title = {{Streamlined particle filtering of phase-based magnified videos for quantified operational deflection shapes}},
   volume = {177},
   year = {2022},
}
@article{Dabek_2022,
   abstract = {It is a challenge for mining enterprises to diagnose the belt conveyors, which length can be tens of kilometres and the number of idlers reaches several thousand. All of them require inspection, which is infeasible to perform using monitoring sensors, such as accelerometers. The authors proposed a novel method for the rotational speed measurement of idlers based on image data analysis. The relation is assumed of the rotation speed decrease due to internal defects. The procedure of visual data processing is verified on the real conveyor idlers. The remote sensing method can be applied in mobile inspection robots such as UAVs or UGVs as well as for manual camera recordings. The accuracy of the proposed method is 0.13-0.67% error depending on the speed range, which is provided by the standard sampling rates (30-60 FPS) and video resolution (1280 x 720 px). Recommendations are formulated for method implementation in practice.},
   author = {Przemysław Dąbek and Pavlo Krot and Jacek Wodecki and Paweł Zimroz and Jarosław Szrek and Radosław Zimroz},
   doi = {10.1016/j.measurement.2022.111869},
   issn = {02632241},
   journal = {Measurement: Journal of the International Measurement Confederation},
   keywords = {Belt conveyor,Idler,Image analysis,Remote sensing,Rotation speed,Signal processing},
   month = {10},
   publisher = {Elsevier B.V.},
   title = {Measurement of idlers rotation speed in belt conveyors based on image data analysis for diagnostic purposes},
   volume = {202},
   year = {2022},
}
@article{Hu_2023,
   abstract = {The simply supported slab bridge is a typical perfricated reinforced concrete bridge. Under the influence of increasing vehicle loads and natural environmental erosion, the hinge joints between slabs suffer from damage that cannot be easily evaluated, which brings negative effects on the load carrying capacity of bridges. In the present study, a hybrid method for damage detection and condition assessment of hinge joints in hollow slab bridges using physical models and vision-based measurements was proposed. The stiffness reduction of hinge joints is taken as the damage degree and condition level of the inspected hinge joints. An analytical model of a simplified spring-mass system was firstly built to demonstrate the applicability of using the relative displacement ratio as the damage index of hinge joints. The relationship between the relative displacement ratio and the stiffness reduction of hinge joints was then studied thoroughly through a parametric study on finite element models considering different damage levels of hinge joints. Thresholds of the relative displacement ratio were defined to classify the damage states of hinge joints. The damage index of target hinge joints can be calculated from the actual data provided by using computer vision-based multi-camera and multi-point displacement measurements. Lastly, the application of a real-life bridge under normal traffic was demonstrated to verify the feasibility of the quantitative evaluation of the service status of joints in hinged-slab bridges. It indicated that the proposed method could evaluate the damage degree of joints quantitatively, effectively and economically.},
   author = {Hao Hu and Jiji Wang and Chuan Zhi Dong and Jiaqi Chen and Tao Wang},
   doi = {10.1016/j.ymssp.2022.109631},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Computer vision,Condition assessment,Damage detection,Hinge joint,Hollow slab bridges,Relative displacement ratio},
   pages = {109631},
   publisher = {Academic Press},
   title = {{A hybrid method for damage detection and condition assessment of hinge joints in hollow slab bridges using physical models and vision-based measurements}},
   volume = {183},
   year = {2023},
}
@article{Cao_2022,
   abstract = {With the fast development of full-field vibration measurements by combining digital image correlation (DIC) technique with the integrated highspeed camera system, the structural characteristic deflection shapes (CDS's) can be readily captured, which are sensitive for damage localization. Naturally, the mode shapes are preferred due to their higher signal to noise ratio. However, traditional modal analysis methods are inefficient in processing the large volumes of data that acquired by high-speed camera system for mode shape-based damage localization. Moreover, how to extract the damage features and enhance the damage localization results without the baseline-data of the intact state is another challenging issue. To address these problems, a novel damage localization method is proposed by enhancing the mode shape estimation and optimizing the damage feature extraction. Firstly, the dominant singular vector at each interested resonant frequency is individually evaluated as the mode shapes in the proposed time domain decomposition (TDD) method. Moreover, based on the extracted mode shapes, a pseudo-excitation (PE) method is proposed to reveal the damage locations without baseline-data by examining the perturbation of local dynamic equilibrium. To circumvent the effects of measurement noise on PE method, an adaptive denoising technique is proposed based on Gaussian smoothing. Furthermore, the local contiguity and spatial sparsity of the damage-caused features are harnessed by a hierarchical clustering to optimize the damage localization performance via tuning the scale parameter of Gaussian smoothing. Finally, numerical and experimental studies of crack damaged plates are conducted to validate the feasibility and effectiveness of the proposed mode shape estimation and damage localization methods. During the experiment, the full-field vibration measurements are acquired by using an integrated binocular highspeed camera system. In addition, a comparison study based on benchmark data is carried out to demonstrate the performance and reliability of the proposed damage localization method.},
   author = {Shancheng Cao and Haibo Nian and Jinwei Yan and Zhiwen Lu and Chao Xu},
   doi = {10.1016/j.ymssp.2022.109309},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Damage localization,Full-field vibration measurement,Pseudo-excitation method,Time domain decomposition},
   pages = {109309},
   publisher = {Academic Press},
   title = {{Modal analysis and damage localization in plate-type structures via TDD and PE methods based on the data of an integrated highspeed camera system}},
   volume = {178},
   year = {2022},
}
@article{Willems_2023,
   abstract = {A novel approach is presented for the time-domain system identification of structural dynamic components exploiting the high spatial density of vision-based measurements. By using spatially dense measurements, the number of spatial measurement points is much larger than the dimensionality of the underlying dominant dynamics (i.e., the number of measurement points needed to meet observability of the targeted dynamics). This opens up the potential to develop new experimental identification methods that use this spatial overdetermination which were out of reach with conventional discrete sensors. The new approach presented in this paper directly extracts a relatively noise-free, low-order set of dynamic states by projecting the spatially dense time-domain measurements on a low-order dominant deformation motion basis. The basis is constructed by applying an over-complete singular value decomposition on the measurements. These dynamic states together with their numerically calculated first and second order time-derivatives are then used in a two-step identification of the structural dynamic parameters. Here, the structure of the model to identify is based on a-priori physical knowledge of the underlying set of partial differential equations, unlike a purely data-driven method. This approach has the benefits of providing a mathematical formulation that is straightforward to understand and implement and is time-efficient to solve. The presented approach is experimentally validated on a clamped plate as well as on a flexibly suspended plate which requires a correction of the rigid body motion. The identified models have shown to provide an accuracy up to 1 × 10−5 m with respect to the dominant measured motion components in both validation cases.},
   author = {Thijs Willems and Felix Simeon Egner and Yonggang Wang and Matteo Kirchner and Wim Desmet and Frank Naets},
   doi = {10.1016/j.ymssp.2022.109553},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Optical flow,Structural dynamics,System identification,Time-domain identification,Vision-based measurements},
   pages = {109553},
   publisher = {Academic Press},
   title = {{Time-domain model identification of structural dynamics from spatially dense 3D vision-based measurements}},
   volume = {182},
   year = {2023},
}
@article{Tomac_2022,
   abstract = {Monitoring distant structures using a high-speed camera frequently relies on modal parameters. Even with high-dynamic-range sensors (e.g., accelerometers) damping identification is not trivial. With high-speed cameras the dynamic range is relatively small and contaminated with a relatively high level of noise. Image-based techniques have the advantage of providing contact-less full-field structural identification. While the damping is a modal parameter and theoretically not spatially dependent, this study looks at the potential to use the spatial over-determination, provided by the high-speed camera to increase the accuracy of the contact-less damping identification. High-speed cameras provide thousands of measurement locations, and identify the damping with noise-resistant methods like those based on the Continuous Wavelet Transform is numerically demanding. This research is built on the the Morlet Wave Damping Identification method, which is based on the Continuous Wavelet Transform, but is also significantly faster. Finally, the full-field damping parameters were averaged with regard to the identified deflection shapes. The theory is extended with an experiment, where damping is identified for a simple structure at frequencies up to 2.5 kHz. It was found that the proposed method resulted in damping identification that was comparably accurate to the damping identified from high-dynamic-range and low-noise piezoelectric accelerometers. This research confirms that damping can be accurately identified from high-speed-camera measurements, only.},
   author = {I Tomac and J Slavič},
   doi = {10.1016/j.ymssp.2021.108485},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Morlet-wave,damping,full-field,spatial distribution},
   pages = {108485},
   title = {{Damping identification based on a high-speed camera}},
   volume = {166},
   year = {2022},
}
@article{Link_1993,
   abstract = {"Conference on Modern Practice in Stress and Vibration Analysis"--Cover. Sponsored by The Institute of Physics Stress Analysis Group in collaboration with the British Society for Strain Measurement, et al. and held at University of Sheffield, 20-22 April 1993.},
   author = {Michael Link},
   isbn = {185075439X},
   journal = {Proceedings of Conference on "Modern Practise in Stress and Vibration Analysis"},
   pages = {35-52},
   publisher = {Sheffield Academic Press},
   title = {Updating of Analytical Models - Procedures and Experience},
   year = {1993},
}
@article{Lekberg_1980,
   abstract = {Electronic speckle pattern interferometry can provide high-speed, real-time holography for industrial research and inspection. This article discusses its basic principles, modes of operation and applications, and finally tries to assess its future importance for industry With the advent of the holographic recording process a unique technique was created for performing interferometric measurements on non-optical objects: the technique of holographic interferometry (H},
   author = {Ole Lekberg},
   doi = {10.1088/0305-4624/11/1/303},
   journal = {Physics in Technology},
   pages = {16},
   title = {Electronic speckle pattern inteferometry},
   volume = {11},
   year = {1980},
}
@article{Khadka_2020,
   abstract = {With the recent demands for more efficient clean renewable energy sources, wind turbines are designed that have large rotor blade diameters. These large-sized wind turbines need to be periodically monitored to prevent catastrophic failures. This paper aims to develop a practice for obtaining the vibration characteristics of wind turbine blades that can be eventually used for structural health monitoring of these structures. This monitoring technique needs to be robust and non-contact to prevent any interference with the operation of the wind turbine. In this work, a digital image correlation (DIC) system installed on a drone is used as a sensing technique to obtain the dynamic characteristics of rotating wind turbine blades. The DIC uses a stereo-camera system to record the deflections of the blades and provides non-contact measurements. The unmanned aerial vehicle (UAV) enables on-site robust measurements. Furthermore, a dynamic stitching technique is used after DIC measurement to obtain vibration characteristics of the entire blade with high accuracy. The proposed health monitoring technique can be used by engineers for remote structural health monitoring of wind turbines during operation in both offshore and inland wind farms.},
   author = {Ashim Khadka and Benjamin Fick and Arash Afshar and Massoud Tavakoli and Javad Baqersad},
   doi = {10.1016/j.ymssp.2019.106446},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Computer vision,Drone,Photogrammetry,Structural health monitoring,Wind turbine},
   month = {4},
   publisher = {Academic Press},
   title = {{Non-contact vibration monitoring of rotating wind turbines using a semi-autonomous UAV}},
   volume = {138},
   year = {2020},
}
@article{Luo_2023,
   author = {Kui Luo and Xuan Kong and Xiuyan Wang and Tengjiao Jiang and Gunnstein T. Frøseth and Anders Rønnquist},
   doi = {10.1016/j.ymssp.2023.110575},
   issn = {08883270},
   journal = {Mechanical Systems and Signal Processing},
   month = {10},
   pages = {110575},
   publisher = {Elsevier BV},
   title = {{Cable vibration measurement based on broad-band phase-based motion magnification and line tracking algorithm}},
   volume = {200},
   year = {2023},
}

@misc{Xian_2019,
  author = {Ruicheng Xian},
  title = {phase-video},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/rxian/phase-video}},
  commit = {09d3db1}
}

@article{Collier_2022,
   abstract = {In this paper, phase-based optical flow done using the complex steerable pyramid is evaluated to quantify upper and lower bounds of accurate pixel displacement extraction. The objective is to understand how typical image parameters affect these bounds and to determine if phase-based optical flow alone is effective and sufficient to extract vibrations. Across the current literature, phase-based optical flow is largely treated as a pre-processing step for more traditional optical methods, and its ability to extract motions rather than magnify them seems to have been largely overlooked. Rather than compound methodologies, phase-based optical flow is evaluated as a motion extraction tool in its own right in both a synthetic and experimental context. The evaluation provides expected bounds given ideal image parameters as well as a metric to adjust these bounds for a general scenario. Beyond these results, previous evaluations specific to phase-based optical flow are addressed and resulting bounds are compared. Due to dramatic effects caused by the image parameters, rules of thumb specific to this type of processing are also discussed.},
   author = {Sean Collier and Tyler Dare},
   doi = {10.1016/j.jsv.2022.117112},
   issn = {10958568},
   journal = {Journal of Sound and Vibration},
   keywords = {Bound quantification,Motion extraction,Structural acoustics,Sub-pixel motion,Super-pixel motion},
   month = {9},
   publisher = {Academic Press},
   title = {Accuracy of phase-based optical flow for vibration extraction},
   volume = {535},
   year = {2022},
}

@article{Diamond_2017,
   abstract = {As digital cameras become cheaper and faster, new opportunities for measuring structural vibration are unlocked. Measuring vibration through video sequences can provide full field measurements of a structure's motion. Digital image correlation is an established method for measuring structural vibration but requires visual surface preparation of the object being measured. Recently, a new method based on optical flow analysis of video sequences has surfaced that can measure structural vibration without any surface preparation whatsoever. This article presents an experiment to test the accuracy of the new method. The accuracy of the technique is evaluated for several sub-pixel vibration displacement amplitudes. The response is measured by an accelerometer, a laser vibrometer and marker tracking and compared to the optical flow method's results. The results obtained indicate that it is possible to measure vibration amplitudes 450 times smaller than a single image pixel accurately.},
   author = {D. H. Diamond and P. S. Heyns and A. J. Oberholster},
   doi = {10.1016/j.measurement.2016.10.021},
   issn = {02632241},
   journal = {Measurement: Journal of the International Measurement Confederation},
   keywords = {Motion magnification,Optical flow,Optical measurement,Structural dynamics,Vibration measurement},
   month = {1},
   pages = {166-172},
   publisher = {Elsevier B.V.},
   title = {Accuracy evaluation of sub-pixel structural vibration measurements through optical flow analysis of a video sequence},
   volume = {95},
   year = {2017},
}

@book{Szeliski_2010,
   author = {Richard Szeliski},
   city = {London},
   edition = {1},
   isbn = {978-1-84882-935-0},
   publisher = {Springer London},
   title = {{Computer Vision: Algorithms and Applications}},
   year = {2010},
}

@book{Pharr_2016,
   author = {Matt Pharr and Wenzel Jakob and Greg Humphreys},
   edition = {3},
   isbn = {978-0-12-800645-0},
   publisher = {Elsevier Inc.},
   title = {{Physically Based Rendering: From Theory to Implementation}},
   year = {2016},
}

@book{Sutton_2009,
   author = {Michael A. Sutton and Jean-José Orteu and Hubert W. Schreier},
   edition = {1},
   isbn = {978-0-387-78747-3},
   publisher = {Springer New York, NY},
   title = {{Image Correlation for Shape, Motion and Deformation Measurements}},
   year = {2009},
}

@article{Merainani_2024,
   abstract = {Vibration measurements for structural health monitoring (SHM) by operational modal analysis (OMA) are classically obtained from sensors that are embedded in or physically attached to the monitored structure, like accelerometers or strain gauges. However, the setup time of these sensors and their restricted number and space coverage limit their monitoring capabilities. Video image-based sensing methods can overcome these shortcomings. With adequate image processing methods, motion signals are extracted from video image flows, which are then processed by system identification methods to estimate modal parameters. In this way, the pixels in selected regions of interest within the images act as a dense network of contactless sensors distributed over the whole structure. In this paper, the efficiency of this video-based approach is demonstrated with laboratory experiments on a cantilever beam, in particular, by evaluating its capability for detecting weak damages mimicked by slight mass modifications. To this end, the steerable filter-based method (ST), that recovers displacements from local phase, is first extended to overcome its motion limitation of one pixel size. Then, the performance of the improved motion extraction method is compared with two other well-established methods in the context of OMA, where natural frequencies, damping ratios and mode shapes with high spatial resolution are estimated together with their uncertainty bounds using covariance-driven subspace identification. The compared methods are evaluated with the help of reference laser displacement measurements as well as a finite element model of the beam, revealing differences in the accuracy of the estimated mode shapes depending on the chosen method for motion extraction. Finally, aiming to investigate early structural damage detection, experiments are carried out under small structural changes and the results are compared to a reference state with the help of estimated uncertainties. Small but statistically significant changes in the modal parameters are detected, showing the potential of the vision based framework for SHM.},
   author = {Boualem Merainani and Bian Xiong and Vincent Baltazart and Michael Döhler and Jean Dumoulin and Qinghua Zhang},
   doi = {10.1016/j.jsv.2023.117957},
   issn = {10958568},
   journal = {Journal of Sound and Vibration},
   keywords = {Computer vision,Displacement extraction,Operational modal analysis,Structural health monitoring,Uncertainty quantification},
   month = {1},
   publisher = {Academic Press},
   title = {Subspace-based modal identification and uncertainty quantification from video image flows},
   volume = {569},
   year = {2024},
}


@article{pyidi,
   author = {Klemen Zaletelj and Domen Gorjup and Janko Slavič},
   title = {{ladisk/pyidi: Release of the version v.027}},
   year = {2023},
}

@article{Atashipour_2023,
   author = {Seyed Rasoul Atashipour and Javad Baqersad},
   doi = {10.1016/j.jmbbm.2023.106266},
   issn = {17516161},
   journal = {Journal of the Mechanical Behavior of Biomedical Materials},
   month = {3},
   pages = {106266},
   publisher = {Elsevier BV},
   title = {Noninvasive identification of directionally-dependent elastic properties of soft tissues using full-field optical data},
   year = {2023},
}
@article{LoFeudo_2023,
   abstract = {This study proposes to carry out the experimental modal analysis of nonlinear systems under the assumption of almost invariant modal shapes by coupling video analysis from a high speed/resolution camera and extended Kalman filtering. A clamped-clamped beam with a local nonlinearity is considered, and its vibrations are measured by detecting and tracking a large set of (virtual) sensors bonded to the beam outer surface. Specific image processing and video tracking techniques are employed and detailed herein. Then, the instantaneous natural frequencies and modal amplitudes are identified by means of a data assimilation method based on extended Kalman and modal filters. Finally, the proposed method of identification is assessed using a numerical example possessing 3 degrees of freedom and a strong nonlinearity. The performance and limits of the identification process are discussed.},
   author = {Stefania Lo Feudo and Jean Luc Dion and Franck Renaud and Gaëtan Kerschen and Jean Philippe Noël},
   doi = {10.1007/s11071-023-08560-1},
   issn = {1573269X},
   issue = {14},
   journal = {Nonlinear Dynamics},
   keywords = {Extended Kalman filter,Modal filter,Nonlinear vibrations,Video analysis},
   month = {7},
   pages = {13263-13277},
   publisher = {Springer Science and Business Media B.V.},
   title = {Video analysis of nonlinear systems with extended Kalman filtering for modal identification},
   volume = {111},
   year = {2023},
}

@article{Cufar_2024,
   abstract = {If motion, identified using image-based methods, is too small to be seen with the naked eye, motion magnification can be used to help with the visualization. Established motion-magnification methods magnify (typically up to 1000 times) the band-passed content of the image data. Especially at higher frequencies, the amplitudes of measured displacements are often below the noise floor. In this research, a novel method for amplifying vibrations, based on experimental modal analysis (EMA), is introduced. The response of the examined structure to dynamic excitation is measured with a simplified, gradient-based, optical flow method and used to perform a hybrid modal analysis in conjunction with a reference accelerometer response measurement. Such a hybrid approach can: (a) identify structural dynamics significantly in the sub-pixel range, and (b) significantly below the image noise floor. The image of the vibrating structure is subdivided using a planar triangle mesh, which is then warped in accordance with the identified mode shape. A mesh-element-wise affine transformation is performed to obtain an image of the magnified mode shape. In the experimental part, the proposed method achieved magnification factors of approximately 40 thousand times, which is an order of magnitude deeper into noise than available before; additionally, the proposed approach is numerically significantly less demanding. The introduced mode-shape magnification presents an alternative to existing motion-magnification methods for applications where the harmonic displacement information is hidden by image noise.},
   author = {Krištof Čufar and Janko Slavič and Miha Boltežar},
   doi = {10.1016/j.ymssp.2024.111336},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {DIC,Image-based structural identification,Mode-shape magnification,Motion magnification,Optical flow},
   month = {5},
   publisher = {Academic Press},
   title = {Mode-shape magnification in high-speed camera measurements},
   volume = {213},
   year = {2024},
}
@inproceedings{Agarwal_2009,
   author = {S. Agarwal and N. Snavely and I. Simon and S. M. Seitz and R. Szeliski},
   doi = {10.1109/ICCV.2009.5459148},
   isbn = {9781424444199},
   booktitle = {2009 IEEE 12th International Conference on Computer Vision},
   pages = {72-79},
   publisher = {IEEE},
   title = {Building Rome in a Day},
   year = {2009},
}
@inproceedings{Cheng_2014,
   abstract = {Image matching is one of the most challenging stages in 3D reconstruction, which usually occupies half of computational cost and inaccurate matching may lead to failure of reconstruction. Therefore, fast and accurate image matching is very crucial for 3D reconstruction. In this paper, we proposed a Cascade Hashing strategy to speed up the image matching. In order to accelerate the image matching, the proposed Cascade Hashing method is designed to be three-layer structure: hashing lookup, hashing remapping, and hashing ranking. Each layer adopts different measures and filtering strategies, which is demonstrated to be less sensitive to noise. Extensive experiments show that image matching can be accelerated by our approach in hundreds times than brute force matching, even achieves ten times or more than Kd-tree based matching while retaining comparable accuracy.},
   author = {Jian Cheng and Cong Leng and Jiaxiang Wu and Hainan Cui and Hanqing Lu},
   doi = {10.1109/CVPR.2014.8.},
   booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
   pages = {1-8},
   title = {Fast and Accurate Image Matching with Cascade Hashing for 3D Reconstruction},
   year = {2014},
}
@article{Zhang_2000,
   author = {Zhengyou Zhang},
   doi = {10.1109/34.888718},
   journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on pattern analysis and machine intelligence},
   pages = {1330-1334},
   title = {A Flexible New Technique for Camera Calibration},
   volume = {22},
   year = {2000},
}

@article{Marchand_2016,
   abstract = {Augmented reality (AR) allows to seamlessly insert virtual objects in an image sequence. In order to accomplish this goal, it is important that synthetic elements are rendered and aligned in the scene in an accurate and visually acceptable way. The solution of this problem can be related to a pose estimation or, equivalently, a camera localization process. This paper aims at presenting a brief but almost self-contented introduction to the most important approaches dedicated to vision-based camera localization along with a survey of several extension proposed in the recent years. For most of the presented approaches, we also provide links to code of short examples. This should allow readers to easily bridge the gap between theoretical aspects and practical implementations.},
   author = {Eric Marchand and Hideaki Uchiyama and Fabien Spindler},
   doi = {10.1109/TVCG.2015.2513408ï},
   issue = {12},
   journal = {TO APPEAR},
   keywords = {Index Terms-Survey,PnP,SLAM,augmented reality,code examples,homography,keypoint matching,motion estimation,pose estimation,vision-based camera localization},
   pages = {2633-2651},
   title = {Pose Estimation for Augmented Reality: A Hands-On Survey},
   volume = {22},
   url = {https://inria.hal.science/hal-01246370},
   year = {2016},
}
@inproceedings{Griwodz_2021,
   abstract = {This paper introduces the Meshroom software and its underlying 3D computer vision framework AliceVision. This solution provides a photogrammetry pipeline to reconstruct 3D scenes from a set of unordered images. It also features other pipelines for fusing multi-bracketing low dynamic range images into high dynamic range, stitching multiple images into a panorama and estimating the motion of a moving camera. Meshroom's nodal architecture allows the user to customize the different pipelines to adjust them to their domain specific needs. The user can interactively add other processing nodes to modify a pipeline, export intermediate data to analyze the result of the algorithms and easily compare the outputs given by different sets of parameters. The software package is released in open source and relies on open file formats. These features enable researchers to conveniently run the pipelines, access and visualize the data at each step, thus promoting the sharing and the reproducibility of the results.},
   author = {Carsten Griwodz and Simone Gasparini and Lilian Calvet and Pierre Gurdjos and Fabien Castan and Benoit Maujean and Gregoire De Lillo and Yann Lanthony},
   doi = {10.1145/3458305.3478443},
   booktitle = {ACM Multimedia Systems Conference},
   month = {6},
   pages = {241-247},
   publisher = {Association for Computing Machinery (ACM)},
   title = {{AliceVision Meshroom}},
   year = {2021},
}
@article{Matas_2004,
   abstract = {The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5×), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained. © 2004 Elsevier B.V. All rights reserved.},
   author = {J. Matas and O. Chum and M. Urban and T. Pajdla},
   doi = {10.1016/j.imavis.2004.02.006},
   issn = {02628856},
   issue = {10 SPEC. ISS.},
   journal = {Image and Vision Computing},
   keywords = {Distinguished regions,MSER,Maximally stable extremal regions,Robust metric,Wide-baseline stereo},
   month = {9},
   pages = {761-767},
   publisher = {Elsevier Ltd},
   title = {Robust wide-baseline stereo from maximally stable extremal regions},
   volume = {22},
   year = {2004},
}
@inproceedings{Dong_2015,
   abstract = {We introduce a simple modification of local image de-scriptors, such as SIFT, based on pooling gradient orienta-tions across different domain sizes, in addition to spatial locations. The resulting descriptor, which we call DSP-SIFT, outperforms other methods in wide-baseline matching benchmarks, including those based on convolutional neural networks, despite having the same dimension of SIFT and requiring no training.},
   author = {Jingming Dong and Stefano Soatto},
   doi = {10.1109/CVPR.2015.7299145},
   booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   pages = {5097-5106},
   title = {{Domain-Size Pooling in Local Descriptors: DSP-SIFT}},
   year = {2015},
}
@article{Furukawa_2015,
   abstract = {This tutorial presents a hands-on view of the field of multi-view stereo with a focus on practical algorithms. Multi-view stereo algorithms are able to construct highly detailed 3D models from images alone. They take a possibly very large set of images and construct a 3D plausible geometry that explains the images under some reasonable assumptions, the most important being scene rigidity. The tutorial frames the multiview stereo problem as an image/geometry consistency optimization problem. It describes in detail its main two ingredients: robust implementations of photometric consistency measures, and efficient optimization algorithms. It then presents how these main ingredients are used by some of the most successful algorithms, applied into real applications, and deployed as products in the industry. Finally it describes more advanced approaches exploiting domain-specific knowledge such as structural priors, and gives an overview of the remaining challenges and future research directions.},
   author = {Yasutaka Furukawa and Carlos Hernández},
   doi = {10.1561/0600000052},
   issn = {15722759},
   issue = {1-2},
   journal = {Foundations and Trends in Computer Graphics and Vision},
   month = {6},
   pages = {1-148},
   publisher = {Now Publishers Inc},
   title = {Multi-view stereo: A tutorial},
   volume = {9},
   year = {2015},
}
@article{Vlasic_2009,
   abstract = {We describe a system for high-resolution capture of moving 3D geometry, beginning with dynamic normal maps from multiple views. The normal maps are captured using active shape-from-shading (photometric stereo), with a large lighting dome providing a series of novel spherical lighting configurations. To compensate for low-frequency deformation, we perform multi-view matching and thin-plate spline deformation on the initial surfaces obtained by integrating the normal maps. Next, the corrected meshes are merged into a single mesh using a volumetric method. The final output is a set of meshes, which were impossible to produce with previous methods. The meshes exhibit details on the order of a few millimeters, and represent the performance over human-size working volumes at a temporal resolution of 60Hz. © 2009, ACM. All rights reserved.},
   author = {Daniel Vlasic and Pieter Peers and Ilya Baran and Paul Debevec and Jovan Popović and Szymon Rusinkiewicz and Wojciech Matusik},
   doi = {10.1145/1618452.1618520},
   issn = {15577368},
   issue = {5},
   journal = {ACM Transactions on Graphics},
   month = {12},
   pages = {174},
   title = {Dynamic Shape Capture using Multi-View Photometric Stereo},
   volume = {28},
   year = {2009},
}
@article{Remondino_2006,
   abstract = {In this paper the main problems and the available solutions are addressed for the generation of 3D models from terrestrial images. Close range photogrammetry has dealt for many years with manual or automatic image measurements for precise 3D modelling. Nowadays 3D scanners are also becoming a standard source for input data in many application areas, but image-based modelling still remains the most complete, economical, portable, flexible and widely used approach. In this paper the full pipeline is presented for 3D modelling from terrestrial image data, considering the different approaches and analysing all the steps involved.},
   author = {Fabio Remondino and Sabry El-Hakim},
   doi = {10.1111/j.1477-9730.2006.00383.x},
   issue = {115},
   journal = {The Photogrammetric Record},
   keywords = {3D reconstruction,calibration,orientation,visualisation},
   pages = {269-291},
   title = {Image-based 3D Modelling: A Review},
   volume = {21},
   year = {2006},
}
@article{Jebara_1999,
   author = {Tony Jebara and Ali Azarbayejani and Alex Pentland},
   doi = {10.1109/79.768574},
   issue = {3},
   journal = {IEEE Signal Processing Magazine},
   pages = {66-84},
   title = {3D Structure from 2D Motion},
   volume = {16},
   year = {1999},
}
@article{Bianco_2018,
   abstract = {Structure from Motion (SfM) is a pipeline that allows three-dimensional reconstruction starting from a collection of images. A typical SfM pipeline comprises different processing steps each of which tackles a different problem in the reconstruction pipeline. Each step can exploit different algorithms to solve the problem at hand and thus many different SfM pipelines can be built. How to choose the SfM pipeline best suited for a given task is an important question. In this paper we report a comparison of different state-of-the-art SfM pipelines in terms of their ability to reconstruct different scenes. We also propose an evaluation procedure that stresses the SfM pipelines using real dataset acquired with high-end devices as well as realistic synthetic dataset. To this end, we created a plug-in module for the Blender software to support the creation of synthetic datasets and the evaluation of the SfM pipeline. The use of synthetic data allows us to easily have arbitrarily large and diverse datasets with, in theory, infinitely precise ground truth. Our evaluation procedure considers both the reconstruction errors as well as the estimation errors of the camera poses used in the reconstruction.},
   author = {Simone Bianco and Gianluigi Ciocca and Davide Marelli},
   doi = {10.3390/jimaging4080098},
   issn = {2313433X},
   issue = {8},
   journal = {Journal of Imaging},
   keywords = {3D reconstruction,Blender,Evaluation,Structure from Motion (SfM)},
   month = {8},
   publisher = {MDPI},
   title = {Evaluating the performance of structure from motion pipelines},
   volume = {4},
   year = {2018},
}
@article{Weng_1992,
   author = {Juyang Weng and Paul Cohen and Marc Herniou},
   doi = {10.1109/34.159901},
   issue = {10},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   pages = {965-980},
   title = {Camera Calibration with Distortion Models and Accuracy Evaluation},
   volume = {14},
   year = {1992},
}
@article{Liu_2016,
   abstract = {Chessboard corner detection is a necessary procedure of the popular chessboard pattern-based camera calibration technique, in which the inner corners on a two-dimensional chessboard are employed as calibration markers. In this study, an automatic chessboard corner detection algorithm is presented for camera calibration. In authors' method, an initial corner set is first obtained with an improved Hessian corner detector. Then, a novel strategy that utilises both intensity and geometry characteristics of the chessboard pattern is presented to eliminate fake corners from the initial corner set. After that, a simple yet effective approach is adopted to sort the detected corners into a meaningful order. Finally, the sub-pixel location of each corner is calculated. The proposed algorithm only requires a user input of the chessboard size, while all the other parameters can be adaptively calculated with a statistical approach. The experimental results demonstrate that the proposed method has advantages over the popular OpenCV chessboard corner detection method in terms of detection accuracy and computational efficiency. Furthermore, the effectiveness of the proposed method used for camera calibration is also verified in authors' experiments.},
   author = {Yu Liu and Shuping Liu and Yang Cao and Zengfu Wang},
   doi = {10.1049/iet-ipr.2015.0126},
   issn = {17519659},
   issue = {1},
   journal = {IET Image Processing},
   month = {1},
   pages = {16-23},
   publisher = {Institution of Engineering and Technology},
   title = {Automatic chessboard corner detection method},
   volume = {10},
   year = {2016},
}
@article{Dossing_1988,
   abstract = {Operational Deflection Shapes (ODSs) can be measured directly by relatively simple means. They provide very useful information for understanding and evaluating the absolute dynamic behavior of a machine, a component or an entire structure. As understanding makes up most of the path to a possible solution, the visualization of the vibration behavior by Operational Deflection Shapes may guide the engineer to the point of the structure at which to make an optimal modification in order to control noise, control vibration, lessen fatigue, reduce wear or cure related problems. Modification decisions can be supported by one or a few frequency response measurements to check for the existence of resonance conditions. Operational Deflection Shapes can also be predicted from a mathematical model (modal model), assumed boundary conditions , and operating forces if each of these is available. If, however, the objective is to study a particular structure under one or a few specific conditions, a direct measurement is faster , simpler, and more accurate than analytical prediction. No assumptions such as linearity have to be made. The technique suggested in this article uses a two-channel measurement of complex transmissibility between a fixed reference transducer, and a second transducer moved sequentially to all points and directions of interest on the structure. At each frequency of interest the relative magnitudes and phases are extracted from the measurements. The magnitudes and phases when assembled in vectors (one for each frequency) represent the relative ODSs at each particular frequency. An absolute Operational Deflection Shape is obtained by multiplying the relative ODS by the absolute response, measured by the reference transducer. A standard modal analysis software program can be used for data acquisition, extraction and animation of the ODS. It simplifies the data management, interpretation and evaluation of the results. The background and practical aspects of the measurement and analysis technique are discussed, and a number of practical problems are given as examples.},
   author = {Ole Døssing},
   journal = {Sound and Vibration},
   pages = {18-24},
   title = {Structural Stroboscopy-Measurement of Operational Deflection Shapes},
   volume = {1},
   year = {1988},
}
@article{Maia_2001,
   abstract = {The objective of this paper is to give a general panorama of the subject of modal analysis identification techniques, as a detailed explanation is not possible due to the vast amount of available information concerning the many existing methods. Beginning with an introduction, followed by the various types of classification and a short historical note, the reader is led into the subject, although he or she needs much more information to delve deeper into specific details and developments of individual methods. This information is provided in the fundamental works and textbooks we have cited.},
   author = {N. M.M. Maia and J. M.M. Silva},
   doi = {10.1098/rsta.2000.0712},
   issn = {1364503X},
   issue = {1778},
   journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
   keywords = {Identification methods,Modal analysis,Structural dynamics,System identification},
   pages = {29-40},
   publisher = {Royal Society},
   title = {Modal analysis identification techniques},
   volume = {359},
   year = {2001},
}
@article{Richardson_1997,
   abstract = {Mode shapes and operating "deflection" shapes are related to one another. In fact, one is always measured in order to obtain the other. Yet, they are quite different from one another in a number of ways. This article discusses the relationships between modal testing, modal analysis and operating deflection shape measurements.},
   author = {Mark H. Richardson},
   journal = {Sound and Vibration},
   pages = {54-61},
   title = {Is It a Mode Shape, or an Operating Deflection Shape},
   volume = {31},
   year = {1997},
}
@inproceedings{Vold_2000,
   abstract = {In this paper, a new methodology is presented for post-processing non-stationary operating data as a prerequisite for displaying operating deflection shapes on a 3D spatial model of the test machine or structure. The traditional 'transmissibility" measurement, which is a measure of each response normalized by a reference response, is discussed. Then, two new post-processing methods associated with two new types of measurements (the ODS FRF and the ODS Order Track) are introduced, and their use with data typical of realistic testing situations is illustrated.},
   author = {Håvard Vold and Brian Schwarz and Mark Richardson},
   city = {San Antonio, Texas},
   booktitle = {18th Internation Modal Analysis Conference},
   title = {Measuring Operating Deflection Shapes under Non-stationary Conditions},
   year = {2000},
}

@article{Fischler_1981,
   abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/ smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing and analysis conditions. Implementation details and computational examples are also presented.},
   author = {Martin A Fischler and Robert C Bolles},
   doi = {10.1145/358669.358692},
   issue = {6},
   journal = {Communications of the ACM},
   keywords = {361,371,50,81,82,and Phrases: model fitting,automated cartography CR Categories: 360,camera calibration,image matching,location determination,scene analysis},
   pages = {381-395},
   title = {{Graphics and Image Processing Random Sample Consensus: A Paradigm for Model Fitting with Applicatlons to Image Analysis and Automated Cartography}},
   volume = {24},
   year = {1981},
}
@article{Gorjup_2021,
   abstract = {To measure high-frequency 3D vibrations, multi-camera, high-speed imaging hardware is normally required. An alternative using still-frame cameras was recently introduced with the Spectral Optical Flow Imaging (SOFI) method. In this research, the SOFI method is extended to multiview measurements of spatial operating deflection shapes. This is achieved by utilizing harmonically controlled illumination to perform an analogue Fourier transform on image-intensity data in multiple camera views. The obtained multiview displacement spectra are combined with geometrical data to perform frequency-domain triangulation and reconstruct spatial deflection shapes. By introducing additional camera views into the image-based measurement, its field of view is extended and the signal-to-noise ratio of the final result is increased. For linear, time-invariant mechanical structures under stationary excitation, full-field 3D measurements of high-frequency vibrations can be performed using a single still-frame monochrome camera. The proposed method identifies displacements in the frequency domain directly on the camera sensor, resulting in orders-of-magnitude smaller data sizes and post-processing times compared with conventional multiview image-based methods.},
   author = {Domen Gorjup and Janko Slavič and Aleš Babnik and Miha Boltežar},
   doi = {10.1016/j.ymssp.2020.107456},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Frequency domain triangulation,Full-field displacement measurement,Multiview,Single camera,Spectral Optical Flow Imaging,Still camera},
   month = {5},
   publisher = {Academic Press},
   title = {Still-camera multiview Spectral Optical Flow Imaging for 3D operating-deflection-shape identification},
   volume = {152},
   year = {2021},
}

@article{Hirschmuller_2008,
   abstract = {This paper describes the Semi-Global Matching (SGM) stereo method. It uses a pixelwise, Mutual Information based matching cost for compensating radiometric differences of input images. Pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. SGM performs a fast approximation by pathwise optimizations from all directions. The discussion also addresses occlusion detection, subpixel refinement and multi-baseline matching. Additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments and the interpolation of gaps are presented. Finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed.A comparison on standard stereo images shows that SGM is among the currently top-ranked algorithms and is best, if subpixel accuracy is considered. The complexity is linear to the number of pixels and disparity range, which results in a runtime of just 1-2s on typical test images. An in depth evaluation of the Mutual Information based matching cost demonstrates a tolerance against a wide range of radiometric transformations. Finally, examples of reconstructions from huge aerial frame and pushbroom images demonstrate that the presented ideas are working well on practical problems. © 2008 IEEE.},
   author = {Heiko Hirschmüller},
   doi = {10.1109/TPAMI.2007.1166},
   issn = {01628828},
   issue = {2},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   keywords = {Global optimization,Multibaseline,Mutual information,Stereo},
   month = {2},
   pages = {328-341},
   pmid = {18084062},
   title = {{Stereo processing by semiglobal matching and mutual information}},
   volume = {30},
   year = {2008},
}

@inproceedings{Hirschmuller_2005,
   abstract = {This paper considers the objectives of accurate stereo matching, especially at object boundaries, robustness against recording or illumination changes and efficiency of the calculation. These objectives lead to the proposed Semi-Global Matching method that performs pixelwise matching based on Mutual Information and the approximation of a global smoothness constraint. Occlusions are detected and disparities determined with sub-pixel accuracy. Additionally , an extension for multi-baseline stereo images is presented. There are two novel contributions. Firstly, a hierarchical calculation of Mutual Information based matching is shown, which is almost as fast as intensity based matching. Secondly, an approximation of a global cost calculation is proposed that can be performed in a time that is linear to the number of pixels and disparities. The implementation requires just 1 second on typical images.},
   author = {Heiko Hirschmüller},
   doi = {10.1109/CVPR.2005.56},
   booktitle = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
   pages = {807-814},
   title = {{Accurate and Efficient Stereo Processing by Semi-Global Matching and Mutual Information}},
   year = {2005},
}

@article{Hartley_1997,
   abstract = {point of the common perpendicular to the two rays (the midpoint method). Perhaps a better choice would be to In this paper, we consider the problem of finding the position of a point in space given its position in two images taken with divide the common perpendicular in proportion to the cameras with known calibration and pose. This process requires distance from the two camera centers, since this would the intersection of two known rays in space and is commonly more closely equalize the angular error. Nevertheless, this known as triangulation. In the absence of noise, this problem method will not give optimal results, because of various is trivial. When noise is present, the two rays will not generally approximations (for instance, the angles will not be pre-meet, in which case it is necessary to find the best point of cisely equal in the two cases). In the case of projective intersection. This problem is especially critical in affine and reconstruction, or affine reconstruction, however, the cam-projective reconstruction in which there is no meaningful metric era matrices will be known in a projective frame of refer-information about the object space. It is desirable to find a ence, in which concepts such as common perpendicular or triangulation method that is invariant to projective transforma-midpoint (in the projective case) have no sense. In this tions of space. This paper solves that problem by assuming a case, the simple midpoint method here will not work. Gaussian noise model for perturbation of the image coordinates. The importance of a good method for triangulation is The triangulation problem may then be formulated as a least-squares minimization problem. In this paper a noniterative clearly shown by Beardsley et al. who demonstrate that solution is given that finds the global minimum. It is shown the midpoint method gives bad results. In [2, 3] they suggest that in certain configurations, local minima occur, which are an alternative method based on ''quasi-Euclidean'' recon-avoided by the new method. Extensive comparisons of the new struction. In this method, an approximation to the correct method with several other methods show that it consistently Euclidean frame is selected and the midpoint method is gives superior results.},
   author = {Richard I Hartley and Peter Sturm},
   doi = {10.1006/cviu.1997.0547},
   issue = {2},
   journal = {Computer Vision and Image Understanding},
   pages = {146-157},
   title = {Triangulation},
   volume = {68},
   year = {1997},
}
@article{Rades_2010,
   abstract = {Mode Indicator Functions (MIFs) are real-valued frequency-dependent scalars that exhibit local minima or maxima at the modal frequencies of the system. This paper presents an overview of the currently used and some recently developed MIFs , revealing their features and limitations. Eigenvalue or singular value based MIFs use rectangular frequency response function (FRF) matrices calculated in turn at each excitation frequency. Their plots have as many curves as the number of references. Recently developed MIFs do the simultaneous analysis of all FRF information organized in a compound FRF (CFRF) matrix. The left singular vectors or the Q-vectors obtained from the pivoted QLP decomposition of this matrix contain the frequency information and are used to construct MIFs. The number of curves in such a MIF plot is equal to the effective rank of the CFRF matrix. If the number of response coordinates is larger than this rank , a single point excitation can locate even double modes. The condition to use as many input points as the multiplicity of modal frequencies is no more imposed. 1. MIF basic approaches Mode Indicator Functions (MIFs) are calculated using FRFs measured at N o response coordinates , N i input coordinates (N i N o) and N f frequencies. Such data are obtained from either multiple-excitation measurements or multi-reference impact tests. A data set consists of N N o × N i complex FRFs measured at N f discrete frequencies. The primary basis for the selection of input / output locations is the adequate definition of all modes of interest. MIFs have been used to optimize the location of excitation points , for a given set of response measurement points , imposed by the required spatial resolution of mode shapes. The first single curve MIF was developed by Breitbach in 1973 [ 1 ] and the first multi-curve MIF-by Hunt , Vold et al. in 1984 [ 2 ]. FRFs can be analyzed either in turn , at each frequency , or simultaneously at all frequencies. In the first case , the data set can be visualized as a 3D matrix consisting of N f rectangular N o ×N i FRF matrices (Fig. 1). Each horizontal line along the frequency axis represents an H pq FRF measured at a given combination of output / input coordinates. The various MIF versions employ different formulations based on either the singular value decomposition (SVD) of each H No×Ni matrix or an eigenproblem involving the real and imaginary parts of the H (ω f) matrices. Examples are the MMIF [ 2 ] , the CMIF [ 3 ] and the related MRMIF , ImMIF and ReMIF. There are as many curves in a plot as the number of references. A comparison of the eigenvalue-based MIFs is presented in [ 4 ]. Other MIFs that exhibit zero-crossings at the modal frequencies , like the RMIF [ 4 ] , are noise sensitive , hence not widely used. Alternatively , the FRF test data can be arranged in a 2D compound FRF (CFRF) matrix A N f ×NoNi (Fig. 2) encompassing all FRFs. Each column , a j , contains an FRF measured at N f frequencies , for a given combination of the output and input coordinates. Each row contains N o × N i FRF values , all measured at the same frequency. MIFs based on the SVD of the CFRF matrix are plots of its left singular vectors (or combinations of these) versus frequency. Examples are the UMIF [ 5 ] and the CoMIF [ 6 ]. There are as many curves in a plot as the effective rank of the CFRF matrix. MIFs based on the pivoted QLP decomposition of the CFRF matrix are plots of its orthogonal Q-vectors (or combinations of these) versus frequency. Examples are the QRMIF and the QCoMIF [ 7 ]. They are based on projections onto an orthogonal base of the subspace of measured FRFs and outperform the MMIF and CMIF based on reduced or ' incomplete ' data sets .},
   author = {M Rades},
   doi = {10.3233/SAV-2010-0541},
   journal = {Shock and Vibration},
   keywords = {CMIF,CoMIF,MMIF,QCoMIF,QRMIF,UMIF},
   pages = {473-482},
   publisher = {IOS Press},
   title = {Performance of various mode indicator functions},
   volume = {17},
   year = {2010},
}
@inproceedings{Shi_1994,
   abstract = {No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond t o physical points in the world is still hard. W e propose a feature selection criterion that is optimal b y construction because it is based o n how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond t o points in the world. These methods are based o n a new tracking algorithm that extends previous Newton-Raphson style search methods t o work under affine image transformations. W e test performance with several simulations and experiments.},
   author = {Jianbo Shi and Carlo Tomasi},
   city = {Seattle, WA, USA},
   doi = {10.1109/CVPR.1994.323794},
   booktitle = {Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
   pages = {593-600},
   title = {Good Features to Track},
   year = {1994},
}
@misc{Rojas_2010,
   author = {Raúl Rojas},
   title = {Lucas-Kanade in a Nutshell},
   url = {https://www.inf.fu-berlin.de/inst/ag-ki/rojas_home/documents/tutorials/Lucas-Kanade2.pdf},
   year = {2010},
}
@misc{Bigger_2018,
   author = {International Digital Image Correlation Society},
   doi = {10.32720/idics/gpg.ed1/print.format},
   editor = {Elizabeth Jones and Mark Iadicola},
   institution = {International Digital Image Correlation Society},
   month = {10},
   title = {A Good Practices Guide for Digital Image Correlation},
   url = {http://idics.org/guide/},
   year = {2018},
}
@article{Dong_2017,
   abstract = {As a carrier of deformation information, the speckle pattern, or more exactly the random intensity distributions, which could be naturally occurred or artificially fabricated onto test samples’ surface, plays an indispensable role in digital image correlation (DIC). It is now well recognized that the accuracy and precision in DIC measurements not only rely on correlation algorithms, but also depend highly on the quality of the speckle pattern. Considering the huge diversity in test materials, spatial scales and experimental conditions, speckle pattern fabrication could be a challenging issue facing DIC practitioners. To obtain good speckle patterns suitable for DIC measurements, some key issues of fabrication methods and quality assessment of speckle patterns must be well addressed. To this end, this review systematically presents the speckle pattern classification and fabrication techniques for various samples and scales, as well as some typical quality assessment metrics.},
   author = {Y. L. Dong and B. Pan},
   doi = {10.1007/s11340-017-0283-1},
   issn = {17412765},
   issue = {8},
   journal = {Experimental Mechanics},
   keywords = {Deformation measurement,Digital image correlation,Micro/Nano-scale,Speckle pattern},
   month = {10},
   pages = {1161-1181},
   publisher = {Springer New York LLC},
   title = {A Review of Speckle Pattern Fabrication and Assessment for Digital Image Correlation},
   volume = {57},
   year = {2017},
}
@inproceedings{Nister_2006,
   abstract = {A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD's. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.},
   author = {David Nistér and Henrik Stewénius},
   doi = {10.1109/CVPR.2006.264},
   booktitle = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},
   pages = {2161-2168},
   title = {Scalable Recognition with a Vocabulary Tree},
   url = {http://www.vis.uky.edu/∼dnister/http://www.vis.uky.edu/∼stewe/},
   year = {2006},
}
@article{Chang_2022,
   abstract = {Mobile stereo-matching systems have become an important part of many applications, such as automated-driving vehicles and autonomous robots. Accurate stereo-matching methods usually lead to high computational complexity; however, mobile platforms have only limited hardware resources to keep their power consumption low; this makes it difficult to maintain both an acceptable processing speed and accuracy on mobile platforms. To resolve this trade-off, we herein propose a novel acceleration approach for the well-known zero-means normalized cross correlation (ZNCC) matching cost calculation algorithm on a Jetson Tx2 embedded GPU. In our method for accelerating ZNCC, target images are scanned in a zigzag fashion to efficiently reuse one pixel's computation for its neighboring pixels; this reduces the amount of data transmission and increases the utilization of on-chip registers, thus increasing the processing speed. As a result, our method is 2X faster than the traditional image scanning method, and 26% faster than the latest NCC method. By combining this technique with the domain transformation (DT) algorithm, our system show real-time processing speed of 32 fps, on a Jetson Tx2 GPU for 1280x384 pixel images with a maximum disparity of 128. Additionally, the evaluation results on the KITTI 2015 benchmark show that our combined system is more accurate than the same algorithm combined with census by 7.26%, while maintaining almost the same processing speed.},
   author = {Qiong Chang and Aolong Zha and Weimin Wang and Xin Liu and Masaki Onishi and Lei Lei and Meng Joo Er and Tsutomu Maruyama},
   doi = {10.1016/j.sysarc.2021.102366},
   issn = {13837621},
   journal = {Journal of Systems Architecture},
   keywords = {Embedded GPU,Jetson Tx2,Stereo vision,ZNCC,Zigzag scanning},
   month = {2},
   publisher = {Elsevier B.V.},
   title = {Efficient stereo matching on embedded GPUs with zero-means cross correlation},
   volume = {123},
   year = {2022},
}

@inproceedings{Alcantarilla_2013,
   abstract = {We propose a novel and fast multiscale feature detection and description approach that exploits the benefits of nonlinear scale spaces. Previous attempts to detect and describe features in nonlinear scale spaces are highly time consuming due to the computational burden of creating the nonlinear scale space. In this paper we propose to use recent numerical schemes called Fast Explicit Diffusion (FED) embedded in a pyramidal framework to dramatically speed-up feature detection in nonlinear scale spaces. In addition, we introduce a Modified-Local Difference Binary (M-LDB) descriptor that is highly efficient, exploits gradient information from the nonlinear scale space, is scale and rotation invariant and has low storage requirements. We present an extensive evaluation that shows the excellent compromise between speed and performance of our approach compared to state-of-the-art methods such as BRISK, ORB, SURF, SIFT and KAZE.},
   author = {Pablo F. Alcantarilla},
   doi = {10.5244/C.27.13},
   booktitle = {BMVC 2013 - Electronic Proceedings of the British Machine Vision Conference 2013},
   publisher = {British Machine Vision Association, BMVA},
   title = {Fast explicit diffusion for accelerated features in nonlinear scale spaces},
   year = {2013},
}

@article{Niu_2024,
   abstract = {Three-dimensional (3D) reconstruction technology is the key technology to establish and express the objective world by using computer, and it is widely used in real 3D, automatic driving, aerospace, navigation and industrial robot applications. According to different principles, it is mainly divided into methods based on traditional multi-view geometry and methods based on deep learning. This paper introduces the above methods from the perspective of three-dimensional space representation. The feature extraction and stereo matching theory of traditional 3D reconstruction methods are the theoretical basis of 3D reconstruction methods based on deep learning, so the paper focuses on them. With the development of traditional 3D reconstruction methods and the development of deep learning related theories, the explicit deep learning 3D reconstruction method represented by MVSNet and the implicit 3D reconstruction method represented by NeRF have been gradually developed. At the same time, the dataset and evaluation indicators for 3D reconstruction were introduced. Finally, a summary of image based 3D reconstruction was provided.},
   author = {Yuandong Niu and Limin Liu and Fuyu Huang and Siyuan Huang and Shuangyou Chen},
   doi = {10.1051/jeos/2024018},
   issue = {1},
   journal = {Journal of the European Optical Society-Rapid Publications},
   pages = {18},
   publisher = {EDP Sciences},
   title = {{Overview of image-based 3D reconstruction technology}},
   volume = {20},
   year = {2024},
}
@article{Zhou_2024,
   abstract = {With the rapid development of 3D reconstruction, especially the emergence of algorithms such as NeRF and 3DGS, 3D reconstruction has become a popular research topic in recent years. 3D reconstruction technology provides crucial support for training extensive computer vision models and advancing the development of general artificial intelligence. With the development of deep learning and GPU technology, the demand for high-precision and high-efficiency 3D reconstruction information is increasing, especially in the fields of unmanned systems, human-computer interaction, virtual reality, and medicine. The rapid development of 3D reconstruction is becoming inevitable. This survey categorizes the various methods and technologies used in 3D reconstruction. It explores and classifies them based on three aspects: traditional static, dynamic, and machine learning. Furthermore, it compares and discusses these methods. At the end of the survey, which includes a detailed analysis of the trends and challenges in 3D reconstruction development, we aim to provide a comprehensive introduction for individuals who are currently engaged in or planning to conduct research on 3D reconstruction. Our goal is to help them gain a comprehensive understanding of the relevant knowledge related to 3D reconstruction.},
   author = {Linglong Zhou and Guoxin Wu and Yunbo Zuo and Xuanyu Chen and Hongle Hu},
   doi = {10.3390/s24072314},
   issn = {14248220},
   issue = {7},
   journal = {Sensors},
   keywords = {3DGS,NeRF,deep learning,dynamic 3D reconstruction,static 3D reconstruction},
   month = {4},
   pmid = {38610525},
   publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
   title = {{A Comprehensive Review of Vision-Based 3D Reconstruction Methods}},
   volume = {24},
   year = {2024},
}
@article{Varady_1997,
   abstract = {In many areas of industry, it is desirable to create geometric models of existing objects for which no such model is available. This paper reviews the process of reverse engineering of shapes. After identifying the purpose of reverse engineering and the main application areas, the most important algorithmic steps are outlined and various reconstruction strategies are presented. Pros and cons of various data acquisition techniques are described with related problems of boundary representation model construction. Specific issues addressed include characterization of geometric models and related surface representations , segmentation and surface fitting for simple and free-form shapes, multiple view combination and creating consistent and accurate B-rep models. The limitations of currently known solutions are also described, and we point out areas in which further work is required before reverse engineering of shape becomes a practical, widely-available engineering tool. 0 1997 Elsevier Science Ltd. All rights reserved.},
   author = {Tamas Varady and Ralph R Martin and Jordan Cox},
   doi = {https://doi.org/10.1016/S0010-4485(96)00054-1},
   issue = {4},
   journal = {Computer-Aided Design},
   keywords = {CAD,boundary models,geometric modelling,reverse engineering,scanning,segmentation,surface fitting},
   pages = {255-268},
   title = {Reverse engineering of geometric models-an introduction},
   volume = {29},
   year = {1997},
}
@inproceedings{Zhou_2024_2,
   abstract = {Exploring the capabilities of Neural Radiance Fields (NeRF) and Gaussian-based methods in the context of 3D scene reconstruction, this study contrasts these modern approaches with traditional Simultaneous Localization and Mapping (SLAM) systems. Utilizing datasets such as Replica and ScanNet, we assess performance based on tracking accuracy, mapping fidelity, and view synthesis. Findings reveal that NeRF excels in view synthesis, offering unique capabilities in generating new perspectives from existing data, albeit at slower processing speeds. Conversely, Gaussian-based methods provide rapid processing and significant expressiveness but lack comprehensive scene completion. Enhanced by global optimization and loop closure techniques, newer methods like NICE-SLAM and SplaTAM not only surpass older frameworks such as ORB-SLAM2 in terms of robustness but also demonstrate superior performance in dynamic and complex environments. This comparative analysis bridges theoretical research with practical implications, shedding light on future developments in robust 3D scene reconstruction across various real-world applications.},
   author = {Yiming Zhou and Zixuan Zeng and Andi Chen and Xiaofan Zhou and Haowei Ni and Shiyao Zhang and Panfeng Li and Liangxi Liu and Mengyao Zheng and Xupeng Chen},
   doi = {10.1109/DOCS63458.2024.10704527},
   booktitle = {Proceedings of the 2024 6th International Conference on Data-driven Optimization of Complex Systems (DOCS)},
   pages = {926-931},
   title = {Evaluating Modern Approaches in 3D Scene Reconstruction: NeRF vs Gaussian-Based Methods},
   url = {http://arxiv.org/abs/2408.04268 http://dx.doi.org/10.1109/DOCS63458.2024.10704527},
   year = {2024},
}
@article{Furukawa_2010,
   abstract = {This paper proposes a novel algorithm for multiview stereopsis that outputs a dense set of small rectangular patches covering the surfaces visible in the images. Stereopsis is implemented as a match, expand, and filter procedure, starting from a sparse set of matched keypoints, and repeatedly expanding these before using visibility constraints to filter away false matches. The keys to the performance of the proposed algorithm are effective techniques for enforcing local photometric consistency and global visibility constraints. Simple but effective methods are also proposed to turn the resulting patch model into a mesh which can be further refined by an algorithm that enforces both photometric consistency and regularization constraints. The proposed approach automatically detects and discards outliers and obstacles and does not require any initialization in the form of a visual hull, a bounding box, or valid depth ranges. We have tested our algorithm on various data sets including objects with fine surface details, deep concavities, and thin structures, outdoor scenes observed from a restricted set of viewpoints, and crowded scenes where moving obstacles appear in front of a static structure of interest. A quantitative evaluation on the Middlebury benchmark [CHECK END OF SENTENCE] shows that the proposed method outperforms all others submitted so far for four out of the six data sets. © 2010 IEEE.},
   author = {Yasutaka Furukawa and Jean Ponce},
   doi = {10.1109/TPAMI.2009.161},
   issn = {01628828},
   issue = {8},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   keywords = {3D/stereo scene analysis,Computer vision,Modeling and recovery of physical attributes,Motion,Shape.},
   pages = {1362-1376},
   pmid = {20558871},
   publisher = {IEEE Computer Society},
   title = {Accurate, dense, and robust multiview stereopsis},
   volume = {32},
   year = {2010},
}
@article{Meng_2024,
   abstract = {Camera, and associated with its objects within the field of view, localization could benefit many computer vision fields, such as autonomous driving, robot navigation, and augmented reality (AR). After decades of progress, camera localization, also called camera pose estimation could compute the 6DoF pose of objects for a camera in a given image, with respect to different images in a sequence or formats. Structure feature-based localization methods have achieved great success when integrated with image matching or with a coordinate regression stage. Absolute and relative pose regression methods using transfer learning can support end-to-end localization to directly regress a camera pose but achieve a less accurate performance. Despite the rapid development of multiple branches in this area, a comprehensive, in-depth and comparative analysis is lacking to summarize, classify and compare, structure feature-based and regression-based camera localization methods. Existing surveys either focus on larger SLAM (Simultaneous Localization and Mapping) systems or on only part of the camera localization method, lack detailed comparisons and descriptions of the methods or datasets used, neural network designs such as loss designs, and input formats, etc. In this survey, we first introduce specific application areas and the evaluation metrics for camera localization pose according to different sub-tasks (learning-based 2D-2D task, 2D-3D task, and 3D-3D task). Then, we review common methods for structure feature-based camera pose estimation approaches, absolute pose regression and relative pose regression approaches by critically modelling the methods to inspire further improvements in their algorithms such as loss functions, and neural network structures. Furthermore, we summarize what are the popular datasets used for camera localization and compare the quantitative and qualitative results of these methods with detailed performance metrics. Finally, we discuss future research possibilities and applications.},
   author = {Meng Xu and Youchen Wang and Bin Xu and Jun Zhang and Jian Ren and Zhao Huang and Stefan Poslad and Pengfei Xu},
   doi = {10.1016/j.neucom.2023.127125},
   issn = {18728286},
   journal = {Neurocomputing},
   keywords = {Absolute pose regression,Camera pose regression,Relative pose regression,Structure feature-based localization},
   month = {2},
   pages = {127125},
   publisher = {Elsevier B.V.},
   title = {A critical analysis of image-based camera pose estimation techniques},
   volume = {570},
   year = {2024},
}
@article{Gomes_2014,
   abstract = {3D reconstruction, refers to capturing and reproducing the shape and appearance of an arbitrary object or scene given depth and color information. This is a broad research area within the computer vision field involving many stages and still open problems. The digital preservation of cultural heritage is a specially challenging application of 3D reconstruction. Cultural heritage objects and sites greatly differ from each other and a maximized fidelity of the 3D reconstruction is a core requirement. The literature on this topic has substantially increased in the past years, mostly due to the variety of scenarios and the development of new depth sensing devices as well as techniques able to deal with this issue. In our search to develop a complete 3D reconstruction pipeline, we have comprehensively studied techniques related to this topic and divided the 3D digitization process in four major overviews: image acquisition, view registration, mesh integration and texture generation. We present the state-of-the-art approaches and challenges of each stage.},
   author = {Leonardo Gomes and Olga Regina Pereira Bellon and Luciano Silva},
   doi = {10.1016/j.patrec.2014.03.023},
   issn = {01678655},
   journal = {Pattern Recognition Letters},
   keywords = {3D reconstruction,Cultural heritage,Depth image,Digital preservation,Survey},
   month = {12},
   pages = {3-14},
   publisher = {Elsevier},
   title = {{3D reconstruction methods for digital preservation of cultural heritage: A survey}},
   volume = {50},
   year = {2014},
}
@article{Luo_2024,
   abstract = {Three-dimensional reconstruction is a key technology employed to represent virtual reality in the real world, which is valuable in computer vision. Large-scale 3D models have broad application prospects in the fields of smart cities, navigation, virtual tourism, disaster warning, and search-and-rescue missions. Unfortunately, most image-based studies currently prioritize the speed and accuracy of 3D reconstruction in indoor scenes. While there are some studies that address large-scale scenes, there has been a lack of systematic comprehensive efforts to bring together the advancements made in the field of 3D reconstruction in large-scale scenes. Hence, this paper presents a comprehensive overview of a 3D reconstruction technique that utilizes multi-view imagery from large-scale scenes. In this article, a comprehensive summary and analysis of vision-based 3D reconstruction technology for large-scale scenes are presented. The 3D reconstruction algorithms are extensively categorized into traditional and learning-based methods. Furthermore, these methods can be categorized based on whether the sensor actively illuminates objects with light sources, resulting in two categories: active and passive methods. Two active methods, namely, structured light and laser scanning, are briefly introduced. The focus then shifts to structure from motion (SfM), stereo matching, and multi-view stereo (MVS), encompassing both traditional and learning-based approaches. Additionally, a novel approach of neural-radiance-field-based 3D reconstruction is introduced. The workflow and improvements in large-scale scenes are elaborated upon. Subsequently, some well-known datasets and evaluation metrics for various 3D reconstruction tasks are introduced. Lastly, a summary of the challenges encountered in the application of 3D reconstruction technology in large-scale outdoor scenes is provided, along with predictions for future trends in development.},
   author = {Haitao Luo and Jinming Zhang and Xiongfei Liu and Lili Zhang and Junyi Liu},
   doi = {10.3390/rs16050773},
   issn = {20724292},
   issue = {5},
   journal = {Remote Sensing},
   keywords = {3D reconstruction,large-scale scene,remote sensing,review},
   month = {3},
   publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
   title = {Large-Scale 3D Reconstruction from Multi-View Imagery: A Comprehensive Review},
   volume = {16},
   year = {2024},
}
@article{Niezrecki_2010,
   author = {Christopher Niezrecki and Peter Avitabile and Christopher Warren and Pawan Pingle and Mark Helfrick},
   doi = {https://doi.org/10.1063/1.3455461},
   isbn = {9780735408029},
   journal = {AIP Conf. Proc.},
   pages = {219-232},
   publisher = {American Institute of Physics},
   title = {A Review of Digital Image Correlation Applied to Structural Dynamics},
   volume = {1253},
   year = {2010},
}

@article{Pan_2017,
   abstract = {Single-camera stereo-digital image correlation (stereo-DIC) techniques have gained increasing attentions and demonstrated excellent prospects in the experimental mechanics community owing to their prominent advantages of cost-effectiveness, compactness, and the avoidance of the complicated camera synchronization. Using additional optical devices, e.g. a diffraction grating, a bi-prism or a set of planar mirrors, pseudo stereo images of a test sample surface can be recorded with a single camera. By correlating these stereo images using DIC, full-field three-dimensional (3D) shape and deformation can be retrieved. This review comprehensively summarizes the historical development, methodologies, strengths and weaknesses of the diffraction grating-based, prism-based, four-mirror-adaptor-based single-camera stereo-DIC techniques, and the recently proposed novel full-frame single color camera-based stereo-DIC technique for full-field 3D shape and deformation measurement. The optical arrangements, principles and calibration procedures of these single-camera stereo-DIC techniques are described in detail. Since high-speed deformation measurement is efficiently achieved by combining the single-camera stereo-DIC with one high-speed camera, single-camera stereo-DIC techniques show great potential in impact engineering, vibration and other dynamic tests.},
   author = {Bing Pan and Li Ping Yu and Qian Bing Zhang},
   doi = {10.1007/s11431-017-9090-x},
   issn = {18691900},
   issue = {1},
   journal = {Science China Technological Sciences},
   keywords = {bi-prism,diffraction grating,four-mirror adapter,single-camera stereo-DIC},
   month = {1},
   pages = {2-20},
   publisher = {Springer Verlag},
   title = {Review of single-camera stereo-digital image correlation techniques for full-field 3D shape and deformation measurement},
   volume = {61},
   year = {2018},
}

@article{Reu2008,
   abstract = {Digital image correlation (DIC) is a method of using digital images to calculate two-dimensional displacement and deformation or for stereo systems three-dimensional shape, displacement, and deformation. While almost any imaging system can be used with DIC, there are some important challenges when working with the technique in high- and ultra-high-speed applications. This article discusses three of these challenges: camera sensor technology, camera frame rate, and camera motion mitigation. Potential solutions are treated via three demonstration experiments showing the successful application of high-speed DIC for dynamic events. The application and practice of DIC at high speeds, rather than the experimental results themselves, provide the main thrust of the discussion. © IMechE 2008.},
   author = {P. L. Reu and T. J. Miller},
   doi = {10.1243/03093247JSA414},
   issn = {03093247},
   issue = {8},
   journal = {Journal of Strain Analysis for Engineering Design},
   keywords = {Digital image correlation,High-speed imaging,Speckle correlation,Ultra-high-speed photography},
   pages = {673-688},
   title = {The application of high-speed digital image correlation},
   volume = {43},
   year = {2008},
}
@inproceedings{Lowe_1999,
   abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest-neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low-residual least-squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially-occluded images with a computation time of under 2 seconds.},
   author = {David G Lowe},
   doi = {10.1109/ICCV.1999.790410},
   booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
   pages = {1150-1157},
   title = {Object Recognition from Local Scale-Invariant Features},
   year = {1990},
}
@article{Viola_1997,
   abstract = {A new information-theoretic approach is presented for finding the pose of an object in an image. The technique does not require information about the surface properties of the object, besides its shape, and is robust with respect to variations of illumination. In our derivation few assumptions are made about the nature of the imaging process. As a result the algorithms are quite general and may foreseeably be used in a wide variety of imaging situations. Experiments are presented that demonstrate the approach registering magnetic resonance (MR) images, aligning a complex 3D object model to real scenes including clutter and occlusion, tracking a human head in a video sequence and aligning a view-based 2D object model to real images. The method is based on a formulation of the mutual information between the model and the image. As applied here the technique is intensity-based, rather than feature-based. It works well in domains where edge or gradient-magnitude based methods have difficulty, yet it is more robust than traditional correlation. Additionally, it has an efficient implementation that is based on stochastic approximation.},
   author = {Paul Viola and William M Wells Iii},
   doi = {https://doi.org/10.1023/A:1007958904918},
   issue = {2},
   journal = {International Journal of Computer Vision},
   pages = {137-154},
   publisher = {Kluwer Academic Publishers},
   title = {Alignment by Maximization of Mutual Information},
   volume = {9},
   year = {1997},
}
@article{Luo_1993,
   abstract = {Recently, digital-image-correlation techniques have been used to accurately determine two-dimensional in-plane displacements and strains. An extension of the two-dimensional method to the acquisition of accurate, three-dimensional surface-displacement data from a stereo pair of CCD cameras is presented in this paper. A pin-hole camera model is used to express the transformation relating three-dimensional world coordinates to two-dimensional computer-image coordinates by the use of camera extrinsic and intrinsic parameters. Accurate camera model parameters are obtained for each camera independently by (a) using several points which have three-dimensional world coordinates that are accurate within 0.001 mm and (b) using two-dimensional image-correlation methods that are accurate to within 0.05 pixels to obtain the computer-image coordinates of various object positions. A non-linear, least-squares method is used to select the optimal camera parameters such that the deviations between the measured and estimated image positions are minimized. Using multiple orientations of the cameras, the accuracy of the methodology is tested by performing translation tests. Using theoretical error estimates, error analyses are presented. To verify the methodology for actual tests both the displacement field for a cantilever beam and also the surface, three-dimensional displacement and strain fields for a 304L stainless-steel compact-tension specimen were experimentally obtained using stereo vision. Re-suits indicate that the three-dimensional measurement methodology , when combined with two-dimensional digital correlation for subpixel accuracy, is a viable tool for the accurate measurement of surface displacements and strains.},
   author = {P F Luo and Y J Chao and M A Sutton and W H Peters},
   doi = {https://doi.org/10.1007/BF02322488},
   issue = {33},
   journal = {Experimental Mechanics},
   title = {Accurate Measurement of Three-dimensional Deformations in Deformable and Rigid Bodies Using Computer Vision},
   year = {1993},
}
@article{DurandTexte_2020,
   abstract = {Increased interest has been witnessed for full-field techniques measuring vibrations. 3D vision methods coupled to two high-speed cameras have proven to be a valid solution to measure 3D displacements, notably with the Stereo Digital Image Correlation (SDIC) tools. The now conventional pseudo-stereo system with a single high-speed camera and a four-mirror adapter, generating two virtual cameras, may also be used, even if it is rather complex to operate and remains limited to small objects. In a logic of simplification of the protocol, the authors present here a set-up requiring a single high-speed camera and no mirrors, with the associated full-field single-axis vision method. The latter is logically designed to measure the vibrations of items whose displacements are locally along a single axis (usually normal to the surface). This paper reports firstly the results of the full-field measurement of the vibrations of a plate, validated by a comparison with those obtained with the four-mirror adapter set-up, and secondly the application to the full-field measurement of the vibrations of a tambourine. Thirdly, the conventional pseudo-stereo technique and the proposed vision method are compared and assessed, in order to establish their respective limits and potential complementarity. Finally, once the application of the method to plane objects is validated, measurements have been carried out on a non-planar object: a bent plate; the results obtained highlight the possibility of using the proposed approach for non-planar surfaces.},
   author = {Thomas Durand-Texte and Manuel Melon and Elisabeth Simonetto and Stéphane Durand and Marie Hélène Moulet},
   doi = {10.1016/j.jsv.2019.115012},
   issn = {10958568},
   journal = {Journal of Sound and Vibration},
   keywords = {Single high-speed camera,Vibration measurement,Vision method},
   month = {1},
   publisher = {Academic Press},
   title = {Single-camera single-axis vision method applied to measure vibrations},
   volume = {465},
   year = {2020},
}
@article{Pankow_2010,
   abstract = {We are concerned with the development of a three-dimensional (3D) full-field high-speed digital image correlation (DIC) measurement system using a single camera, specifically aimed at measuring large outofplane displacements. A system has been devised to record images at ultrahigh speeds using a single camera and a series of mirrors. These mirrors effectively converted a single camera into two virtual cameras that view a specimen surface from different angles and capture two images simultaneously. This pair of images enables one to perform DIC measurements to obtain 3D displacement fields at high framing rates. Bench testing along with results obtained using a shock wave blast test facility are used to show the validity of the method. © 2010 Optical Society of America.},
   author = {Mark Pankow and Brian Justusson and Anthony M. Waas},
   doi = {10.1364/AO.49.003418},
   issn = {15394522},
   issue = {17},
   journal = {Applied Optics},
   month = {6},
   pages = {3418-3427},
   pmid = {20539362},
   publisher = {OSA - The Optical Society},
   title = {Three-dimensional digital image correlation technique using single high-speed camera for measuring large out-of-plane displacements at high framing rates},
   volume = {49},
   year = {2010},
}
@article{Genovese_2013,
   abstract = {In this paper we present and test a Digital Image Correlation (DIC)-based single camera pseudo-stereo system that uses a biprism in front of the camera objective to split the scene into two equivalent lateral stereo views in the two halves of the sensor. Such optical arrangement simplifies image pairs matching and, more importantly, makes possible a compact set-up suitable for miniaturization. To correct the image distortion caused by the refraction through the biprism, a proper optimization-based procedure is used to map the 3D reconstruction error function over the entire measurement volume. The inverse of the volumetric distortion function is then applied to the double-image of a spherical sample placed in an arbitrary position to evaluate the shape reconstruction accuracy. Finally, the capability of the proposed system to accurately track deformation in real-time is tested via an inflation test on a circular latex membrane. © 2012 Elsevier Ltd.},
   author = {K. Genovese and L. Casaletto and J. A. Rayas and V. Flores and Amalia Martinez},
   doi = {10.1016/j.optlaseng.2012.10.001},
   issn = {01438166},
   issue = {3},
   journal = {Optics and Lasers in Engineering},
   keywords = {3D deformation measurement,Biprism,Digital image correlation,Pseudo-stereo system},
   pages = {278-285},
   publisher = {Elsevier Ltd},
   title = {Stereo-Digital Image Correlation (DIC) measurements with a single camera using a biprism},
   volume = {51},
   year = {2013},
}
@article{Xia_2012,
   abstract = {Digital Image Correlation (DIC) provides a full-field non-contact optical method for accurate deformation measurement of materials, devices and structures. The measurement of three-dimensional (3D) deformation using DIC in general requires imaging with two cameras and a 3D-DIC code. In the present work, a new experimental technique, namely, Diffraction Assisted Image Correlation (DAIC) for 3D displacement measurement using a single camera and 2D-DIC algorithm is presented. A transmission diffraction grating is placed between the specimen and the camera, resulting in multiple images which are then used to obtain apparent in-plane displacements using 2D-DIC. The true in-plane and out-of-plane displacements of the specimen are obtained from the apparent in-plane displacements and the diffraction angle of the grating. The validity and accuracy of the DAIC method are demonstrated through 3D displacement measurement of a small thin membrane. This technique provides new avenues for performing 3D deformation measurements at small length scales and/or dynamic loading conditions. © 2012 Society for Experimental Mechanics.},
   author = {S. Xia and A. Gdoutou and G. Ravichandran},
   doi = {10.1007/s11340-012-9687-0},
   issn = {00144851},
   issue = {5},
   journal = {Experimental Mechanics},
   keywords = {3D digital image correlation,Diffraction,Displacement,Membrane,Small scale},
   month = {6},
   pages = {755-765},
   title = {Diffraction Assisted Image Correlation: A Novel Method for Measuring Three-Dimensional Deformation using Two-Dimensional Digital Image Correlation},
   volume = {53},
   year = {2013},
}
@article{Yu_2017,
   abstract = {A low-cost, easy-to-implement single-camera high-speed stereo-digital image correlation (SCHS stereo-DIC) method using a four-mirror adapter is proposed for full-field 3D vibration measurement. With the aid of the four-mirror adapter, surface images of calibration target and test objects can be separately imaged onto two halves of the camera sensor through two different optical paths. These images can be further processed to retrieve the vibration responses on the specimen surface. To validate the effectiveness and accuracy of the proposed approach, dynamic parameters including natural frequencies, damping ratios and mode shapes of a rectangular cantilever plate were extracted from the directly measured vibration responses using the established system. The results reveal that the SCHS stereo-DIC is a simple, practical and effective technique for vibration measurements and dynamic parameters identification.},
   author = {Liping Yu and Bing Pan},
   doi = {10.1016/j.ymssp.2017.03.008},
   issn = {10961216},
   journal = {Mechanical Systems and Signal Processing},
   keywords = {Digital image correlation,Single high-speed camera,Vibration measurement},
   month = {9},
   pages = {374-383},
   publisher = {Academic Press},
   title = {Single-camera high-speed stereo-digital image correlation for full-field vibration measurement},
   volume = {94},
   year = {2017},
}
